<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-33108845-1']);
  _gaq.push(['_setDomainName', 'opencv.org']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Face Recognition with OpenCV &mdash; OpenCV 2.4.13.7 documentation</title>
    <link rel="stylesheet" href="../../../../_static/default.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../../../',
        VERSION:     '2.4.13.7',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../../_static/doctools.js"></script>
    <link rel="top" title="OpenCV 2.4.13.7 documentation" href="../../../../index.html" />
    <link rel="up" title="FaceRecognizer - Face Recognition with OpenCV" href="index.html" />
    <link rel="next" title="Gender Classification with OpenCV" href="tutorial/facerec_gender_classification.html" />
    <link rel="prev" title="FaceRecognizer" href="facerec_api.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="tutorial/facerec_gender_classification.html" title="Gender Classification with OpenCV"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="facerec_api.html" title="FaceRecognizer"
             accesskey="P">previous</a> |</li>
        <li><a href="../../../../index.html">OpenCV 2.4.13.7 documentation</a> &raquo;</li>
          <li><a href="../../../refman.html" >OpenCV API Reference</a> &raquo;</li>
          <li><a href="../contrib.html" >contrib. Contributed/Experimental Stuff</a> &raquo;</li>
          <li><a href="index.html" accesskey="U">FaceRecognizer - Face Recognition with OpenCV</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
  
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="face-recognition-with-opencv">
<h1><a class="toc-backref" href="#id27">Face Recognition with OpenCV</a><a class="headerlink" href="#face-recognition-with-opencv" title="Permalink to this headline">¶</a></h1>
<div class="contents topic" id="table-of-contents">
<p class="topic-title first">Table of Contents</p>
<ul class="simple">
<li><a class="reference internal" href="#face-recognition-with-opencv" id="id27">Face Recognition with OpenCV</a><ul>
<li><a class="reference internal" href="#introduction" id="id28">Introduction</a></li>
<li><a class="reference internal" href="#face-recognition" id="id29">Face Recognition</a></li>
<li><a class="reference internal" href="#face-database" id="id30">Face Database</a><ul>
<li><a class="reference internal" href="#preparing-the-data" id="id31">Preparing the data</a></li>
</ul>
</li>
<li><a class="reference internal" href="#eigenfaces" id="id32">Eigenfaces</a><ul>
<li><a class="reference internal" href="#algorithmic-description" id="id33">Algorithmic Description</a></li>
<li><a class="reference internal" href="#eigenfaces-in-opencv" id="id34">Eigenfaces in OpenCV</a></li>
</ul>
</li>
<li><a class="reference internal" href="#fisherfaces" id="id35">Fisherfaces</a><ul>
<li><a class="reference internal" href="#id16" id="id36">Algorithmic Description</a></li>
<li><a class="reference internal" href="#fisherfaces-in-opencv" id="id37">Fisherfaces in OpenCV</a></li>
</ul>
</li>
<li><a class="reference internal" href="#local-binary-patterns-histograms" id="id38">Local Binary Patterns Histograms</a><ul>
<li><a class="reference internal" href="#id22" id="id39">Algorithmic Description</a></li>
<li><a class="reference internal" href="#local-binary-patterns-histograms-in-opencv" id="id40">Local Binary Patterns Histograms in OpenCV</a></li>
</ul>
</li>
<li><a class="reference internal" href="#conclusion" id="id41">Conclusion</a></li>
<li><a class="reference internal" href="#credits" id="id42">Credits</a><ul>
<li><a class="reference internal" href="#the-database-of-faces" id="id43">The Database of Faces</a></li>
<li><a class="reference internal" href="#id25" id="id44">Yale Facedatabase A</a></li>
<li><a class="reference internal" href="#yale-facedatabase-b" id="id45">Yale Facedatabase B</a></li>
</ul>
</li>
<li><a class="reference internal" href="#literature" id="id46">Literature</a></li>
<li><a class="reference internal" href="#appendix" id="id47">Appendix</a><ul>
<li><a class="reference internal" href="#id26" id="id48">Creating the CSV File</a></li>
<li><a class="reference internal" href="#aligning-face-images" id="id49">Aligning Face Images</a></li>
<li><a class="reference internal" href="#csv-for-the-at-t-facedatabase" id="id50">CSV for the AT&amp;T Facedatabase</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="introduction">
<h2><a class="toc-backref" href="#id28">Introduction</a><a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="http://opencv.org">OpenCV (Open Source Computer Vision)</a> is a popular computer vision library started by <a class="reference external" href="http://www.intel.com">Intel</a> in 1999. The cross-platform library sets its focus on real-time image processing and includes patent-free implementations of the latest computer vision algorithms. In 2008 <a class="reference external" href="http://www.willowgarage.com">Willow Garage</a> took over support and OpenCV 2.3.1 now comes with a programming interface to C, C++, <a class="reference external" href="http://www.python.org">Python</a> and <a class="reference external" href="http://www.android.com">Android</a>. OpenCV is released under a BSD license so it is used in academic projects and commercial products alike.</p>
<p>OpenCV 2.4 now comes with the very new <a class="reference internal" href="facerec_api.html#FaceRecognizer : public Algorithm" title="class FaceRecognizer : public Algorithm"><code class="xref ocv ocv-class docutils literal"><span class="pre">FaceRecognizer</span></code></a> class for face recognition, so you can start experimenting with face recognition right away. This document is the guide I&#8217;ve wished for, when I was working myself into face recognition. It shows you how to perform face recognition with <a class="reference internal" href="facerec_api.html#FaceRecognizer : public Algorithm" title="class FaceRecognizer : public Algorithm"><code class="xref ocv ocv-class docutils literal"><span class="pre">FaceRecognizer</span></code></a> in OpenCV (with full source code listings) and gives you an introduction into the algorithms behind. I&#8217;ll also show how to create the visualizations you can find in many publications, because a lot of people asked for.</p>
<p>The currently available algorithms are:</p>
<ul class="simple">
<li>Eigenfaces (see <a class="reference internal" href="facerec_api.html#Ptr&lt;FaceRecognizer&gt; createEigenFaceRecognizer(int num_components , double threshold)" title="Ptr&lt;FaceRecognizer&gt; createEigenFaceRecognizer(int num_components , double threshold)"><code class="xref ocv ocv-func docutils literal"><span class="pre">createEigenFaceRecognizer()</span></code></a>)</li>
<li>Fisherfaces (see <a class="reference internal" href="facerec_api.html#Ptr&lt;FaceRecognizer&gt; createFisherFaceRecognizer(int num_components , double threshold)" title="Ptr&lt;FaceRecognizer&gt; createFisherFaceRecognizer(int num_components , double threshold)"><code class="xref ocv ocv-func docutils literal"><span class="pre">createFisherFaceRecognizer()</span></code></a>)</li>
<li>Local Binary Patterns Histograms (see <a class="reference internal" href="facerec_api.html#Ptr&lt;FaceRecognizer&gt; createLBPHFaceRecognizer(int radius, int neighbors, int grid_x, int grid_y, double threshold)" title="Ptr&lt;FaceRecognizer&gt; createLBPHFaceRecognizer(int radius, int neighbors, int grid_x, int grid_y, double threshold)"><code class="xref ocv ocv-func docutils literal"><span class="pre">createLBPHFaceRecognizer()</span></code></a>)</li>
</ul>
<p>You don&#8217;t need to copy and paste the source code examples from this page, because they are available in the <code class="docutils literal"><span class="pre">src</span></code> folder coming with this documentation. If you have built OpenCV with the samples turned on, chances are good you have them compiled already! Although it might be interesting for very advanced users, I&#8217;ve decided to leave the implementation details out as I am afraid they confuse new users.</p>
<p>All code in this document is released under the <a class="reference external" href="http://www.opensource.org/licenses/bsd-license">BSD license</a>, so feel free to use it for your projects.</p>
</div>
<div class="section" id="face-recognition">
<h2><a class="toc-backref" href="#id29">Face Recognition</a><a class="headerlink" href="#face-recognition" title="Permalink to this headline">¶</a></h2>
<p>Face recognition is an easy task for humans. Experiments in <a class="reference internal" href="#tu06" id="id1">[Tu06]</a> have shown, that even one to three day old babies are able to distinguish between known faces. So how hard could it be for a computer? It turns out we know little about human recognition to date. Are inner features (eyes, nose, mouth) or outer features (head shape, hairline) used for a successful face recognition? How do we analyze an image and how does the brain encode it? It was shown by <a class="reference external" href="http://en.wikipedia.org/wiki/David_H._Hubel">David Hubel</a> and <a class="reference external" href="http://en.wikipedia.org/wiki/Torsten_Wiesel">Torsten Wiesel</a>, that our brain has specialized nerve cells responding to specific local features of a scene, such as lines, edges, angles or movement. Since we don&#8217;t see the world as scattered pieces, our visual cortex must somehow combine the different sources of information into useful patterns. Automatic face recognition is all about extracting those meaningful features from an image, putting them into a useful representation and performing some kind of classification on them.</p>
<p>Face recognition based on the geometric features of a face is probably the most intuitive approach to face recognition. One of the first automated face recognition systems was described in <a class="reference internal" href="#kanade73" id="id2">[Kanade73]</a>: marker points (position of eyes, ears, nose, ...) were used to build a feature vector (distance between the points, angle between them, ...). The recognition was performed by calculating the euclidean distance between feature vectors of a probe and reference image. Such a method is robust against changes in illumination by its nature, but has a huge drawback: the accurate registration of the marker points is complicated, even with state of the art algorithms. Some of the latest work on geometric face recognition was carried out in <a class="reference internal" href="#bru92" id="id3">[Bru92]</a>. A 22-dimensional feature vector was used and experiments on large datasets have shown, that geometrical features alone my not carry enough information for face recognition.</p>
<p>The Eigenfaces method described in <a class="reference internal" href="#tp91" id="id4">[TP91]</a> took a holistic approach to face recognition: A facial image is a point from a high-dimensional image space and a lower-dimensional representation is found, where classification becomes easy. The lower-dimensional subspace is found with Principal Component Analysis, which identifies the axes with maximum variance. While this kind of transformation is optimal from a reconstruction standpoint, it doesn&#8217;t take any class labels into account. Imagine a situation where the variance is generated from external sources, let it be light. The axes with maximum variance do not necessarily contain any discriminative information at all, hence a classification becomes impossible. So a class-specific projection with a Linear Discriminant Analysis was applied to face recognition in <a class="reference internal" href="#bhk97" id="id5">[BHK97]</a>. The basic idea is to minimize the variance within a class, while maximizing the variance between the classes at the same time.</p>
<p>Recently various methods for a local feature extraction emerged. To avoid the high-dimensionality of the input data only local regions of an image are described, the extracted features are (hopefully) more robust against partial occlusion, illumation and small sample size. Algorithms used for a local feature extraction are Gabor Wavelets (<a class="reference internal" href="#wiskott97" id="id6">[Wiskott97]</a>), Discrete Cosinus Transform (<a class="reference internal" href="#messer06" id="id7">[Messer06]</a>) and Local Binary Patterns (<a class="reference internal" href="#ahp04" id="id8">[AHP04]</a>). It&#8217;s still an open research question what&#8217;s the best way to preserve spatial information when applying a local feature extraction, because spatial information is potentially useful information.</p>
</div>
<div class="section" id="face-database">
<h2><a class="toc-backref" href="#id30">Face Database</a><a class="headerlink" href="#face-database" title="Permalink to this headline">¶</a></h2>
<p>Let&#8217;s get some data to experiment with first. I don&#8217;t want to do a toy example here. We are doing face recognition, so you&#8217;ll need some face images! You can either create your own dataset or start with one of the available face databases, <a class="reference external" href="http://face-rec.org/databases">http://face-rec.org/databases/</a> gives you an up-to-date overview. Three interesting databases are (parts of the description are quoted from <a class="reference external" href="http://face-rec.org">http://face-rec.org</a>):</p>
<ul>
<li><p class="first"><a class="reference external" href="http://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html">AT&amp;T Facedatabase</a> The AT&amp;T Facedatabase, sometimes also referred to as <em>ORL Database of Faces</em>, contains ten different images of each of 40 distinct subjects. For some subjects, the images were taken at different times, varying the lighting, facial expressions (open / closed eyes, smiling / not smiling) and facial details (glasses / no glasses). All the images were taken against a dark homogeneous background with the subjects in an upright, frontal position (with tolerance for some side movement).</p>
</li>
<li><p class="first"><a class="reference external" href="http://vision.ucsd.edu/content/yale-face-database">Yale Facedatabase A</a>, also known as Yalefaces. The AT&amp;T Facedatabase is good for initial tests, but it&#8217;s a fairly easy database. The Eigenfaces method already has a 97% recognition rate on it, so you won&#8217;t see any great improvements with other algorithms. The Yale Facedatabase A (also known as Yalefaces) is a more appropriate dataset for initial experiments, because the recognition problem is harder. The database consists of 15 people (14 male, 1 female) each with 11 grayscale images sized <img class="math" src="../../../../_images/math/ad6dca18fe54d3a0af571326a227fb0bf8957ec7.png" alt="320 \times 243"/> pixel. There are changes in the light conditions (center light, left light, right light), facial expressions (happy, normal, sad, sleepy, surprised, wink) and glasses (glasses, no-glasses).</p>
<p>The original images are not cropped and aligned. Please look into the <a class="reference internal" href="#appendixft"><span>Appendix</span></a> for a Python script, that does the job for you.</p>
</li>
<li><p class="first"><a class="reference external" href="http://vision.ucsd.edu/~leekc/ExtYaleDatabase/ExtYaleB.html">Extended Yale Facedatabase B</a> The Extended Yale Facedatabase B contains 2414 images of 38 different people in its cropped version. The focus of this database is set on extracting features that are robust to illumination, the images have almost no variation in emotion/occlusion/... . I personally think, that this dataset is too large for the experiments I perform in this document. You better use the <a class="reference external" href="http://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html">AT&amp;T Facedatabase</a> for intial testing. A first version of the Yale Facedatabase B was used in <a class="reference internal" href="#bhk97" id="id10">[BHK97]</a> to see how the Eigenfaces and Fisherfaces method perform under heavy illumination changes. <a class="reference internal" href="#lee05" id="id11">[Lee05]</a> used the same setup to take 16128 images of 28 people. The Extended Yale Facedatabase B is the merge of the two databases, which is now known as Extended Yalefacedatabase B.</p>
</li>
</ul>
<div class="section" id="preparing-the-data">
<h3><a class="toc-backref" href="#id31">Preparing the data</a><a class="headerlink" href="#preparing-the-data" title="Permalink to this headline">¶</a></h3>
<p>Once we have acquired some data, we&#8217;ll need to read it in our program. In the demo applications I have decided to read the images from a very simple CSV file. Why? Because it&#8217;s the simplest platform-independent approach I can think of. However, if you know a simpler solution please ping me about it. Basically all the CSV file needs to contain are lines composed of a <code class="docutils literal"><span class="pre">filename</span></code> followed by a <code class="docutils literal"><span class="pre">;</span></code> followed by the <code class="docutils literal"><span class="pre">label</span></code> (as <em>integer number</em>), making up a line like this:</p>
<div class="highlight-none"><div class="highlight"><pre>/path/to/image.ext;0
</pre></div>
</div>
<p>Let&#8217;s dissect the line. <code class="docutils literal"><span class="pre">/path/to/image.ext</span></code> is the path to an image, probably something like this if you are in Windows: <code class="docutils literal"><span class="pre">C:/faces/person0/image0.jpg</span></code>. Then there is the separator <code class="docutils literal"><span class="pre">;</span></code> and finally we assign the label <code class="docutils literal"><span class="pre">0</span></code> to the image. Think of the label as the subject (the person) this image belongs to, so same subjects (persons) should have the same label.</p>
<p>Download the AT&amp;T Facedatabase from AT&amp;T Facedatabase and the corresponding CSV file from at.txt, which looks like this (file is without ... of course):</p>
<div class="highlight-none"><div class="highlight"><pre>./at/s1/1.pgm;0
./at/s1/2.pgm;0
...
./at/s2/1.pgm;1
./at/s2/2.pgm;1
...
./at/s40/1.pgm;39
./at/s40/2.pgm;39
</pre></div>
</div>
<p>Imagine I have extracted the files to <code class="docutils literal"><span class="pre">D:/data/at</span></code> and have downloaded the CSV file to <code class="docutils literal"><span class="pre">D:/data/at.txt</span></code>. Then you would simply need to Search &amp; Replace <code class="docutils literal"><span class="pre">./</span></code> with <code class="docutils literal"><span class="pre">D:/data/</span></code>. You can do that in an editor of your choice, every sufficiently advanced editor can do this. Once you have a CSV file with valid filenames and labels, you can run any of the demos by passing the path to the CSV file as parameter:</p>
<div class="highlight-none"><div class="highlight"><pre>facerec_demo.exe D:/data/at.txt
</pre></div>
</div>
<div class="section" id="creating-the-csv-file">
<h4>Creating the CSV File<a class="headerlink" href="#creating-the-csv-file" title="Permalink to this headline">¶</a></h4>
<p>You don&#8217;t really want to create the CSV file by hand. I have prepared you a little Python script <code class="docutils literal"><span class="pre">create_csv.py</span></code> (you find it at <code class="docutils literal"><span class="pre">src/create_csv.py</span></code> coming with this tutorial) that automatically creates you a CSV file. If you have your images in hierarchie like this (<code class="docutils literal"><span class="pre">/basepath/&lt;subject&gt;/&lt;image.ext&gt;</span></code>):</p>
<div class="highlight-none"><div class="highlight"><pre>philipp@mango:~/facerec/data/at$ tree
.
|-- s1
|   |-- 1.pgm
|   |-- ...
|   |-- 10.pgm
|-- s2
|   |-- 1.pgm
|   |-- ...
|   |-- 10.pgm
...
|-- s40
|   |-- 1.pgm
|   |-- ...
|   |-- 10.pgm
</pre></div>
</div>
<p>Then simply call create_csv.py with the path to the folder, just like this and you could save the output:</p>
<div class="highlight-none"><div class="highlight"><pre>philipp@mango:~/facerec/data$ python create_csv.py
at/s13/2.pgm;0
at/s13/7.pgm;0
at/s13/6.pgm;0
at/s13/9.pgm;0
at/s13/5.pgm;0
at/s13/3.pgm;0
at/s13/4.pgm;0
at/s13/10.pgm;0
at/s13/8.pgm;0
at/s13/1.pgm;0
at/s17/2.pgm;1
at/s17/7.pgm;1
at/s17/6.pgm;1
at/s17/9.pgm;1
at/s17/5.pgm;1
at/s17/3.pgm;1
[...]
</pre></div>
</div>
<p>Please see the <a class="reference internal" href="#appendixft"><span>Appendix</span></a> for additional informations.</p>
</div>
</div>
</div>
<div class="section" id="eigenfaces">
<h2><a class="toc-backref" href="#id32">Eigenfaces</a><a class="headerlink" href="#eigenfaces" title="Permalink to this headline">¶</a></h2>
<p>The problem with the image representation we are given is its high dimensionality. Two-dimensional <img class="math" src="../../../../_images/math/9ce1a76e441b519702d7cb5876a2e03e8236654e.png" alt="p \times q"/> grayscale images span a <img class="math" src="../../../../_images/math/363fc3130360b0b6dd6dbe991157ae1e490fcada.png" alt="m = pq"/>-dimensional vector space, so an image with <img class="math" src="../../../../_images/math/af46d78386af91fba6655611e43e069bf9c2bf46.png" alt="100 \times 100"/> pixels lies in a <img class="math" src="../../../../_images/math/55f53fab4f8d279610c7053fd7b73f563d837915.png" alt="10,000"/>-dimensional image space already. The question is: Are all dimensions equally useful for us? We can only make a decision if there&#8217;s any variance in data, so what we are looking for are the components that account for most of the information. The Principal Component Analysis (PCA) was independently proposed by <a class="reference external" href="http://en.wikipedia.org/wiki/Karl_Pearson">Karl Pearson</a> (1901) and <a class="reference external" href="http://en.wikipedia.org/wiki/Harold_Hotelling">Harold Hotelling</a> (1933) to turn a set of possibly correlated variables into a smaller set of uncorrelated variables. The idea is, that a high-dimensional dataset is often described by correlated variables and therefore only a few meaningful dimensions account for most of the information. The PCA method finds the directions with the greatest variance in the data, called principal components.</p>
<div class="section" id="algorithmic-description">
<h3><a class="toc-backref" href="#id33">Algorithmic Description</a><a class="headerlink" href="#algorithmic-description" title="Permalink to this headline">¶</a></h3>
<p>Let <img class="math" src="../../../../_images/math/29ed3c7d26511669d4e60027cb241fd3bf49c26e.png" alt="X = \{ x_{1}, x_{2}, \ldots, x_{n} \}"/> be a random vector with observations <img class="math" src="../../../../_images/math/bc340eea6eda5a3d09c3e5ac671a26fabcd6da81.png" alt="x_i \in R^{d}"/>.</p>
<ol class="arabic simple">
<li>Compute the mean <img class="math" src="../../../../_images/math/ec805c307200ba71431f930eed5f64e00233c713.png" alt="\mu"/></li>
</ol>
<blockquote>
<div><div class="math">
<p><img src="../../../../_images/math/3dbbce688326229d8abc6ce12eb5391124b5e885.png" alt="\mu = \frac{1}{n} \sum_{i=1}^{n} x_{i}"/></p>
</div></div></blockquote>
<ol class="arabic simple" start="2">
<li>Compute the the Covariance Matrix <cite>S</cite></li>
</ol>
<blockquote>
<div><div class="math">
<p><img src="../../../../_images/math/23a70f3bfb61f971a2f033473b3fd856bfa05501.png" alt="S = \frac{1}{n} \sum_{i=1}^{n} (x_{i} - \mu) (x_{i} - \mu)^{T}`"/></p>
</div></div></blockquote>
<ol class="arabic simple" start="3">
<li>Compute the eigenvalues <img class="math" src="../../../../_images/math/8f3440d17887f371d6db2cdaa2fe7411a06a0112.png" alt="\lambda_{i}"/> and eigenvectors <img class="math" src="../../../../_images/math/892866a1e920f8f99d654a53d4f4a7eab4f4c6b4.png" alt="v_{i}"/> of <img class="math" src="../../../../_images/math/f7cf4b4c05979af383976668be8e53268eb5c4b9.png" alt="S"/></li>
</ol>
<blockquote>
<div><div class="math">
<p><img src="../../../../_images/math/dbedf05bc27a3575cf0c1409f074a365d7eac253.png" alt="S v_{i} = \lambda_{i} v_{i}, i=1,2,\ldots,n"/></p>
</div></div></blockquote>
<ol class="arabic simple" start="4">
<li>Order the eigenvectors descending by their eigenvalue. The <img class="math" src="../../../../_images/math/b48130bd55bf7a75e095fda3d9f9ff1ac1b4ccef.png" alt="k"/> principal components are the eigenvectors corresponding to the <img class="math" src="../../../../_images/math/b48130bd55bf7a75e095fda3d9f9ff1ac1b4ccef.png" alt="k"/> largest eigenvalues.</li>
</ol>
<p>The <img class="math" src="../../../../_images/math/b48130bd55bf7a75e095fda3d9f9ff1ac1b4ccef.png" alt="k"/> principal components of the observed vector <img class="math" src="../../../../_images/math/275d1cfd2234a22c171bcf9ee37dd451fffd5e1b.png" alt="x"/> are then given by:</p>
<div class="math">
<p><img src="../../../../_images/math/d4d23f3f81624cd20e905781ed4567c12f668578.png" alt="y = W^{T} (x - \mu)"/></p>
</div><p>where <img class="math" src="../../../../_images/math/7bac14b3174e55cdfcde3c3065ffba51717dcfd2.png" alt="W = (v_{1}, v_{2}, \ldots, v_{k})"/>.</p>
<p>The reconstruction from the PCA basis is given by:</p>
<div class="math">
<p><img src="../../../../_images/math/f1c9c6f289405aa8696b8c71b7989e07b499f2b1.png" alt="x = W y + \mu"/></p>
</div><p>where <img class="math" src="../../../../_images/math/7bac14b3174e55cdfcde3c3065ffba51717dcfd2.png" alt="W = (v_{1}, v_{2}, \ldots, v_{k})"/>.</p>
<p>The Eigenfaces method then performs face recognition by:</p>
<ul class="simple">
<li>Projecting all training samples into the PCA subspace.</li>
<li>Projecting the query image into the PCA subspace.</li>
<li>Finding the nearest neighbor between the projected training images and the projected query image.</li>
</ul>
<p>Still there&#8217;s one problem left to solve. Imagine we are given <img class="math" src="../../../../_images/math/a1aec27cba5c3dc91f0e89568d887de7388aa41e.png" alt="400"/> images sized <img class="math" src="../../../../_images/math/af46d78386af91fba6655611e43e069bf9c2bf46.png" alt="100 \times 100"/> pixel. The Principal Component Analysis solves the covariance matrix <img class="math" src="../../../../_images/math/7e7ad3e44a41a9659c593da91a9ad838e41d41b3.png" alt="S = X X^{T}"/>, where <img class="math" src="../../../../_images/math/f3a45bb9e81371be81958d92dddda8659f761dc5.png" alt="{size}(X) = 10000 \times 400"/> in our example. You would end up with a <img class="math" src="../../../../_images/math/ddf59f6c1b2e0f0a113303be5fc278f26eb60c24.png" alt="10000 \times 10000"/> matrix, roughly <img class="math" src="../../../../_images/math/d28751aa58cfdbae03081a6ae4d07e58a144d790.png" alt="0.8 GB"/>. Solving this problem isn&#8217;t feasible, so we&#8217;ll need to apply a trick. From your linear algebra lessons you know that a <img class="math" src="../../../../_images/math/a5e458b86874a95eb35e61850bfd5c1a3166af38.png" alt="M \times N"/> matrix with <img class="math" src="../../../../_images/math/90ce635746f2cf06bd14d82270e801e0f762832a.png" alt="M &gt; N"/> can only have <img class="math" src="../../../../_images/math/39d8f4a2bd62eff3eebafd836ab92a5451425808.png" alt="N - 1"/> non-zero eigenvalues. So it&#8217;s possible to take the eigenvalue decomposition <img class="math" src="../../../../_images/math/bd011324cac3ac590fa96d96b59951475570960c.png" alt="S = X^{T} X"/> of size <img class="math" src="../../../../_images/math/5521726779e522304aea3deb933cfcdc54b2ce51.png" alt="N \times N"/> instead:</p>
<div class="math">
<p><img src="../../../../_images/math/a70b88b2b74cccfad3877a6950ce295d41f35483.png" alt="X^{T} X v_{i} = \lambda_{i} v{i}"/></p>
</div><p>and get the original eigenvectors of <img class="math" src="../../../../_images/math/7e7ad3e44a41a9659c593da91a9ad838e41d41b3.png" alt="S = X X^{T}"/> with a left multiplication of the data matrix:</p>
<div class="math">
<p><img src="../../../../_images/math/4a662fbb166aaf7cae7200108e91c7a4039b9e36.png" alt="X X^{T} (X v_{i}) = \lambda_{i} (X v_{i})"/></p>
</div><p>The resulting eigenvectors are orthogonal, to get orthonormal eigenvectors they need to be normalized to unit length. I don&#8217;t want to turn this into a publication, so please look into <a class="reference internal" href="#duda01" id="id12">[Duda01]</a> for the derivation and proof of the equations.</p>
</div>
<div class="section" id="eigenfaces-in-opencv">
<h3><a class="toc-backref" href="#id34">Eigenfaces in OpenCV</a><a class="headerlink" href="#eigenfaces-in-opencv" title="Permalink to this headline">¶</a></h3>
<p>For the first source code example, I&#8217;ll go through it with you. I am first giving you the whole source code listing, and after this we&#8217;ll look at the most important lines in detail. Please note: every source code listing is commented in detail, so you should have no problems following it.</p>
<div class="highlight-cpp"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>  1
  2
  3
  4
  5
  6
  7
  8
  9
 10
 11
 12
 13
 14
 15
 16
 17
 18
 19
 20
 21
 22
 23
 24
 25
 26
 27
 28
 29
 30
 31
 32
 33
 34
 35
 36
 37
 38
 39
 40
 41
 42
 43
 44
 45
 46
 47
 48
 49
 50
 51
 52
 53
 54
 55
 56
 57
 58
 59
 60
 61
 62
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193</pre></div></td><td class="code"><div class="highlight"><pre><span class="cm">/*</span>
<span class="cm"> * Copyright (c) 2011. Philipp Wagner &lt;bytefish[at]gmx[dot]de&gt;.</span>
<span class="cm"> * Released to public domain under terms of the BSD Simplified license.</span>
<span class="cm"> *</span>
<span class="cm"> * Redistribution and use in source and binary forms, with or without</span>
<span class="cm"> * modification, are permitted provided that the following conditions are met:</span>
<span class="cm"> *   * Redistributions of source code must retain the above copyright</span>
<span class="cm"> *     notice, this list of conditions and the following disclaimer.</span>
<span class="cm"> *   * Redistributions in binary form must reproduce the above copyright</span>
<span class="cm"> *     notice, this list of conditions and the following disclaimer in the</span>
<span class="cm"> *     documentation and/or other materials provided with the distribution.</span>
<span class="cm"> *   * Neither the name of the organization nor the names of its contributors</span>
<span class="cm"> *     may be used to endorse or promote products derived from this software</span>
<span class="cm"> *     without specific prior written permission.</span>
<span class="cm"> *</span>
<span class="cm"> *   See &lt;http://www.opensource.org/licenses/bsd-license&gt;</span>
<span class="cm"> */</span>

<span class="cp">#include</span> <span class="cpf">&quot;opencv2/core/core.hpp&quot;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&quot;opencv2/contrib/contrib.hpp&quot;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&quot;opencv2/highgui/highgui.hpp&quot;</span><span class="cp"></span>

<span class="cp">#include</span> <span class="cpf">&lt;iostream&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;fstream&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;sstream&gt;</span><span class="cp"></span>

<span class="k">using</span> <span class="k">namespace</span> <span class="n">cv</span><span class="p">;</span>
<span class="k">using</span> <span class="k">namespace</span> <span class="n">std</span><span class="p">;</span>

<span class="k">static</span> <span class="n">Mat</span> <span class="nf">norm_0_255</span><span class="p">(</span><span class="n">InputArray</span> <span class="n">_src</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">Mat</span> <span class="n">src</span> <span class="o">=</span> <span class="n">_src</span><span class="p">.</span><span class="n">getMat</span><span class="p">();</span>
    <span class="c1">// Create and return normalized image:</span>
    <span class="n">Mat</span> <span class="n">dst</span><span class="p">;</span>
    <span class="k">switch</span><span class="p">(</span><span class="n">src</span><span class="p">.</span><span class="n">channels</span><span class="p">())</span> <span class="p">{</span>
    <span class="k">case</span> <span class="mi">1</span><span class="o">:</span>
        <span class="n">cv</span><span class="o">::</span><span class="n">normalize</span><span class="p">(</span><span class="n">_src</span><span class="p">,</span> <span class="n">dst</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="n">NORM_MINMAX</span><span class="p">,</span> <span class="n">CV_8UC1</span><span class="p">);</span>
        <span class="k">break</span><span class="p">;</span>
    <span class="k">case</span> <span class="mi">3</span><span class="o">:</span>
        <span class="n">cv</span><span class="o">::</span><span class="n">normalize</span><span class="p">(</span><span class="n">_src</span><span class="p">,</span> <span class="n">dst</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="n">NORM_MINMAX</span><span class="p">,</span> <span class="n">CV_8UC3</span><span class="p">);</span>
        <span class="k">break</span><span class="p">;</span>
    <span class="k">default</span><span class="o">:</span>
        <span class="n">src</span><span class="p">.</span><span class="n">copyTo</span><span class="p">(</span><span class="n">dst</span><span class="p">);</span>
        <span class="k">break</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">dst</span><span class="p">;</span>
<span class="p">}</span>

<span class="k">static</span> <span class="kt">void</span> <span class="n">read_csv</span><span class="p">(</span><span class="k">const</span> <span class="n">string</span><span class="o">&amp;</span> <span class="n">filename</span><span class="p">,</span> <span class="n">vector</span><span class="o">&lt;</span><span class="n">Mat</span><span class="o">&gt;&amp;</span> <span class="n">images</span><span class="p">,</span> <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&amp;</span> <span class="n">labels</span><span class="p">,</span> <span class="kt">char</span> <span class="n">separator</span> <span class="o">=</span> <span class="sc">&#39;;&#39;</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">std</span><span class="o">::</span><span class="n">ifstream</span> <span class="n">file</span><span class="p">(</span><span class="n">filename</span><span class="p">.</span><span class="n">c_str</span><span class="p">(),</span> <span class="n">ifstream</span><span class="o">::</span><span class="n">in</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">file</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">string</span> <span class="n">error_message</span> <span class="o">=</span> <span class="s">&quot;No valid input file was given, please check the given filename.&quot;</span><span class="p">;</span>
        <span class="n">CV_Error</span><span class="p">(</span><span class="n">CV_StsBadArg</span><span class="p">,</span> <span class="n">error_message</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="n">string</span> <span class="n">line</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">classlabel</span><span class="p">;</span>
    <span class="k">while</span> <span class="p">(</span><span class="n">getline</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="n">line</span><span class="p">))</span> <span class="p">{</span>
        <span class="n">stringstream</span> <span class="n">liness</span><span class="p">(</span><span class="n">line</span><span class="p">);</span>
        <span class="n">getline</span><span class="p">(</span><span class="n">liness</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">separator</span><span class="p">);</span>
        <span class="n">getline</span><span class="p">(</span><span class="n">liness</span><span class="p">,</span> <span class="n">classlabel</span><span class="p">);</span>
        <span class="k">if</span><span class="p">(</span><span class="o">!</span><span class="n">path</span><span class="p">.</span><span class="n">empty</span><span class="p">()</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">classlabel</span><span class="p">.</span><span class="n">empty</span><span class="p">())</span> <span class="p">{</span>
            <span class="n">images</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">imread</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="mi">0</span><span class="p">));</span>
            <span class="n">labels</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">atoi</span><span class="p">(</span><span class="n">classlabel</span><span class="p">.</span><span class="n">c_str</span><span class="p">()));</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="kt">int</span> <span class="n">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">argv</span><span class="p">[])</span> <span class="p">{</span>
    <span class="c1">// Check for valid command line arguments, print usage</span>
    <span class="c1">// if no arguments were given.</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">argc</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;usage: &quot;</span> <span class="o">&lt;&lt;</span> <span class="n">argv</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;&lt;</span> <span class="s">&quot; &lt;csv.ext&gt; &lt;output_folder&gt; &quot;</span> <span class="o">&lt;&lt;</span> <span class="n">endl</span><span class="p">;</span>
        <span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="n">string</span> <span class="n">output_folder</span> <span class="o">=</span> <span class="s">&quot;.&quot;</span><span class="p">;</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">argc</span> <span class="o">==</span> <span class="mi">3</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">output_folder</span> <span class="o">=</span> <span class="n">string</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">2</span><span class="p">]);</span>
    <span class="p">}</span>
    <span class="c1">// Get the path to your CSV.</span>
    <span class="n">string</span> <span class="n">fn_csv</span> <span class="o">=</span> <span class="n">string</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>
    <span class="c1">// These vectors hold the images and corresponding labels.</span>
    <span class="n">vector</span><span class="o">&lt;</span><span class="n">Mat</span><span class="o">&gt;</span> <span class="n">images</span><span class="p">;</span>
    <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">labels</span><span class="p">;</span>
    <span class="c1">// Read in the data. This can fail if no valid</span>
    <span class="c1">// input filename is given.</span>
    <span class="k">try</span> <span class="p">{</span>
        <span class="n">read_csv</span><span class="p">(</span><span class="n">fn_csv</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">);</span>
    <span class="p">}</span> <span class="k">catch</span> <span class="p">(</span><span class="n">cv</span><span class="o">::</span><span class="n">Exception</span><span class="o">&amp;</span> <span class="n">e</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">cerr</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;Error opening file </span><span class="se">\&quot;</span><span class="s">&quot;</span> <span class="o">&lt;&lt;</span> <span class="n">fn_csv</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;</span><span class="se">\&quot;</span><span class="s">. Reason: &quot;</span> <span class="o">&lt;&lt;</span> <span class="n">e</span><span class="p">.</span><span class="n">msg</span> <span class="o">&lt;&lt;</span> <span class="n">endl</span><span class="p">;</span>
        <span class="c1">// nothing more we can do</span>
        <span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="c1">// Quit if there are not enough images for this demo.</span>
    <span class="k">if</span><span class="p">(</span><span class="n">images</span><span class="p">.</span><span class="n">size</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">string</span> <span class="n">error_message</span> <span class="o">=</span> <span class="s">&quot;This demo needs at least 2 images to work. Please add more images to your data set!&quot;</span><span class="p">;</span>
        <span class="n">CV_Error</span><span class="p">(</span><span class="n">CV_StsError</span><span class="p">,</span> <span class="n">error_message</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="c1">// Get the height from the first image. We&#39;ll need this</span>
    <span class="c1">// later in code to reshape the images to their original</span>
    <span class="c1">// size:</span>
    <span class="kt">int</span> <span class="n">height</span> <span class="o">=</span> <span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">rows</span><span class="p">;</span>
    <span class="c1">// The following lines simply get the last images from</span>
    <span class="c1">// your dataset and remove it from the vector. This is</span>
    <span class="c1">// done, so that the training data (which we learn the</span>
    <span class="c1">// cv::FaceRecognizer on) and the test data we test</span>
    <span class="c1">// the model with, do not overlap.</span>
    <span class="n">Mat</span> <span class="n">testSample</span> <span class="o">=</span> <span class="n">images</span><span class="p">[</span><span class="n">images</span><span class="p">.</span><span class="n">size</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">];</span>
    <span class="kt">int</span> <span class="n">testLabel</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">labels</span><span class="p">.</span><span class="n">size</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">];</span>
    <span class="n">images</span><span class="p">.</span><span class="n">pop_back</span><span class="p">();</span>
    <span class="n">labels</span><span class="p">.</span><span class="n">pop_back</span><span class="p">();</span>
    <span class="c1">// The following lines create an Eigenfaces model for</span>
    <span class="c1">// face recognition and train it with the images and</span>
    <span class="c1">// labels read from the given CSV file.</span>
    <span class="c1">// This here is a full PCA, if you just want to keep</span>
    <span class="c1">// 10 principal components (read Eigenfaces), then call</span>
    <span class="c1">// the factory method like this:</span>
    <span class="c1">//</span>
    <span class="c1">//      cv::createEigenFaceRecognizer(10);</span>
    <span class="c1">//</span>
    <span class="c1">// If you want to create a FaceRecognizer with a</span>
    <span class="c1">// confidence threshold (e.g. 123.0), call it with:</span>
    <span class="c1">//</span>
    <span class="c1">//      cv::createEigenFaceRecognizer(10, 123.0);</span>
    <span class="c1">//</span>
    <span class="c1">// If you want to use _all_ Eigenfaces and have a threshold,</span>
    <span class="c1">// then call the method like this:</span>
    <span class="c1">//</span>
    <span class="c1">//      cv::createEigenFaceRecognizer(0, 123.0);</span>
    <span class="c1">//</span>
    <span class="n">Ptr</span><span class="o">&lt;</span><span class="n">FaceRecognizer</span><span class="o">&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">createEigenFaceRecognizer</span><span class="p">();</span>
    <span class="n">model</span><span class="o">-&gt;</span><span class="n">train</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">);</span>
    <span class="c1">// The following line predicts the label of a given</span>
    <span class="c1">// test image:</span>
    <span class="kt">int</span> <span class="n">predictedLabel</span> <span class="o">=</span> <span class="n">model</span><span class="o">-&gt;</span><span class="n">predict</span><span class="p">(</span><span class="n">testSample</span><span class="p">);</span>
    <span class="c1">//</span>
    <span class="c1">// To get the confidence of a prediction call the model with:</span>
    <span class="c1">//</span>
    <span class="c1">//      int predictedLabel = -1;</span>
    <span class="c1">//      double confidence = 0.0;</span>
    <span class="c1">//      model-&gt;predict(testSample, predictedLabel, confidence);</span>
    <span class="c1">//</span>
    <span class="n">string</span> <span class="n">result_message</span> <span class="o">=</span> <span class="n">format</span><span class="p">(</span><span class="s">&quot;Predicted class = %d / Actual class = %d.&quot;</span><span class="p">,</span> <span class="n">predictedLabel</span><span class="p">,</span> <span class="n">testLabel</span><span class="p">);</span>
    <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">result_message</span> <span class="o">&lt;&lt;</span> <span class="n">endl</span><span class="p">;</span>
    <span class="c1">// Here is how to get the eigenvalues of this Eigenfaces model:</span>
    <span class="n">Mat</span> <span class="n">eigenvalues</span> <span class="o">=</span> <span class="n">model</span><span class="o">-&gt;</span><span class="n">getMat</span><span class="p">(</span><span class="s">&quot;eigenvalues&quot;</span><span class="p">);</span>
    <span class="c1">// And we can do the same to display the Eigenvectors (read Eigenfaces):</span>
    <span class="n">Mat</span> <span class="n">W</span> <span class="o">=</span> <span class="n">model</span><span class="o">-&gt;</span><span class="n">getMat</span><span class="p">(</span><span class="s">&quot;eigenvectors&quot;</span><span class="p">);</span>
    <span class="c1">// Get the sample mean from the training data</span>
    <span class="n">Mat</span> <span class="n">mean</span> <span class="o">=</span> <span class="n">model</span><span class="o">-&gt;</span><span class="n">getMat</span><span class="p">(</span><span class="s">&quot;mean&quot;</span><span class="p">);</span>
    <span class="c1">// Display or save:</span>
    <span class="k">if</span><span class="p">(</span><span class="n">argc</span> <span class="o">==</span> <span class="mi">2</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">imshow</span><span class="p">(</span><span class="s">&quot;mean&quot;</span><span class="p">,</span> <span class="n">norm_0_255</span><span class="p">(</span><span class="n">mean</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">rows</span><span class="p">)));</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
        <span class="n">imwrite</span><span class="p">(</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;%s/mean.png&quot;</span><span class="p">,</span> <span class="n">output_folder</span><span class="p">.</span><span class="n">c_str</span><span class="p">()),</span> <span class="n">norm_0_255</span><span class="p">(</span><span class="n">mean</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">rows</span><span class="p">)));</span>
    <span class="p">}</span>
    <span class="c1">// Display or save the Eigenfaces:</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">min</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">W</span><span class="p">.</span><span class="n">cols</span><span class="p">);</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">string</span> <span class="n">msg</span> <span class="o">=</span> <span class="n">format</span><span class="p">(</span><span class="s">&quot;Eigenvalue #%d = %.5f&quot;</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">eigenvalues</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="n">i</span><span class="p">));</span>
        <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">msg</span> <span class="o">&lt;&lt;</span> <span class="n">endl</span><span class="p">;</span>
        <span class="c1">// get eigenvector #i</span>
        <span class="n">Mat</span> <span class="n">ev</span> <span class="o">=</span> <span class="n">W</span><span class="p">.</span><span class="n">col</span><span class="p">(</span><span class="n">i</span><span class="p">).</span><span class="n">clone</span><span class="p">();</span>
        <span class="c1">// Reshape to original size &amp; normalize to [0...255] for imshow.</span>
        <span class="n">Mat</span> <span class="n">grayscale</span> <span class="o">=</span> <span class="n">norm_0_255</span><span class="p">(</span><span class="n">ev</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">height</span><span class="p">));</span>
        <span class="c1">// Show the image &amp; apply a Jet colormap for better sensing.</span>
        <span class="n">Mat</span> <span class="n">cgrayscale</span><span class="p">;</span>
        <span class="n">applyColorMap</span><span class="p">(</span><span class="n">grayscale</span><span class="p">,</span> <span class="n">cgrayscale</span><span class="p">,</span> <span class="n">COLORMAP_JET</span><span class="p">);</span>
        <span class="c1">// Display or save:</span>
        <span class="k">if</span><span class="p">(</span><span class="n">argc</span> <span class="o">==</span> <span class="mi">2</span><span class="p">)</span> <span class="p">{</span>
            <span class="n">imshow</span><span class="p">(</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;eigenface_%d&quot;</span><span class="p">,</span> <span class="n">i</span><span class="p">),</span> <span class="n">cgrayscale</span><span class="p">);</span>
        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
            <span class="n">imwrite</span><span class="p">(</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;%s/eigenface_%d.png&quot;</span><span class="p">,</span> <span class="n">output_folder</span><span class="p">.</span><span class="n">c_str</span><span class="p">(),</span> <span class="n">i</span><span class="p">),</span> <span class="n">norm_0_255</span><span class="p">(</span><span class="n">cgrayscale</span><span class="p">));</span>
        <span class="p">}</span>
    <span class="p">}</span>

    <span class="c1">// Display or save the image reconstruction at some predefined steps:</span>
    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">num_components</span> <span class="o">=</span> <span class="n">min</span><span class="p">(</span><span class="n">W</span><span class="p">.</span><span class="n">cols</span><span class="p">,</span> <span class="mi">10</span><span class="p">);</span> <span class="n">num_components</span> <span class="o">&lt;</span> <span class="n">min</span><span class="p">(</span><span class="n">W</span><span class="p">.</span><span class="n">cols</span><span class="p">,</span> <span class="mi">300</span><span class="p">);</span> <span class="n">num_components</span><span class="o">+=</span><span class="mi">15</span><span class="p">)</span> <span class="p">{</span>
        <span class="c1">// slice the eigenvectors from the model</span>
        <span class="n">Mat</span> <span class="n">evs</span> <span class="o">=</span> <span class="n">Mat</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">Range</span><span class="o">::</span><span class="n">all</span><span class="p">(),</span> <span class="n">Range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_components</span><span class="p">));</span>
        <span class="n">Mat</span> <span class="n">projection</span> <span class="o">=</span> <span class="n">subspaceProject</span><span class="p">(</span><span class="n">evs</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">));</span>
        <span class="n">Mat</span> <span class="n">reconstruction</span> <span class="o">=</span> <span class="n">subspaceReconstruct</span><span class="p">(</span><span class="n">evs</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">projection</span><span class="p">);</span>
        <span class="c1">// Normalize the result:</span>
        <span class="n">reconstruction</span> <span class="o">=</span> <span class="n">norm_0_255</span><span class="p">(</span><span class="n">reconstruction</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">rows</span><span class="p">));</span>
        <span class="c1">// Display or save:</span>
        <span class="k">if</span><span class="p">(</span><span class="n">argc</span> <span class="o">==</span> <span class="mi">2</span><span class="p">)</span> <span class="p">{</span>
            <span class="n">imshow</span><span class="p">(</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;eigenface_reconstruction_%d&quot;</span><span class="p">,</span> <span class="n">num_components</span><span class="p">),</span> <span class="n">reconstruction</span><span class="p">);</span>
        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
            <span class="n">imwrite</span><span class="p">(</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;%s/eigenface_reconstruction_%d.png&quot;</span><span class="p">,</span> <span class="n">output_folder</span><span class="p">.</span><span class="n">c_str</span><span class="p">(),</span> <span class="n">num_components</span><span class="p">),</span> <span class="n">reconstruction</span><span class="p">);</span>
        <span class="p">}</span>
    <span class="p">}</span>
    <span class="c1">// Display if we are not writing to an output folder:</span>
    <span class="k">if</span><span class="p">(</span><span class="n">argc</span> <span class="o">==</span> <span class="mi">2</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">waitKey</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</td></tr></table></div>
<p>The source code for this demo application is also available in the <code class="docutils literal"><span class="pre">src</span></code> folder coming with this documentation:</p>
<ul class="simple">
<li><a class="reference download internal" href="../../../../_downloads/facerec_eigenfaces.cpp" download=""><code class="xref download docutils literal"><span class="pre">src/facerec_eigenfaces.cpp</span></code></a></li>
</ul>
<p>I&#8217;ve used the jet colormap, so you can see how the grayscale values are distributed within the specific Eigenfaces. You can see, that the Eigenfaces do not only encode facial features, but also the illumination in the images (see the left light in Eigenface #4, right light in Eigenfaces #5):</p>
<img alt="../../../../_images/eigenfaces_opencv.png" class="align-center" src="../../../../_images/eigenfaces_opencv.png" />
<p>We&#8217;ve already seen, that we can reconstruct a face from its lower dimensional approximation. So let&#8217;s see how many Eigenfaces are needed for a good reconstruction. I&#8217;ll do a subplot with <img class="math" src="../../../../_images/math/ca5d5ccbc6b3c3de36ed98f32a9f8e67dd7e2f25.png" alt="10,30,\ldots,310"/> Eigenfaces:</p>
<div class="highlight-cpp"><div class="highlight"><pre><span class="c1">// Display or save the image reconstruction at some predefined steps:</span>
<span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">num_components</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span> <span class="n">num_components</span> <span class="o">&lt;</span> <span class="mi">300</span><span class="p">;</span> <span class="n">num_components</span><span class="o">+=</span><span class="mi">15</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// slice the eigenvectors from the model</span>
    <span class="n">Mat</span> <span class="n">evs</span> <span class="o">=</span> <span class="n">Mat</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">Range</span><span class="o">::</span><span class="n">all</span><span class="p">(),</span> <span class="n">Range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_components</span><span class="p">));</span>
    <span class="n">Mat</span> <span class="n">projection</span> <span class="o">=</span> <span class="n">subspaceProject</span><span class="p">(</span><span class="n">evs</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">));</span>
    <span class="n">Mat</span> <span class="n">reconstruction</span> <span class="o">=</span> <span class="n">subspaceReconstruct</span><span class="p">(</span><span class="n">evs</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">projection</span><span class="p">);</span>
    <span class="c1">// Normalize the result:</span>
    <span class="n">reconstruction</span> <span class="o">=</span> <span class="n">norm_0_255</span><span class="p">(</span><span class="n">reconstruction</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">rows</span><span class="p">));</span>
    <span class="c1">// Display or save:</span>
    <span class="k">if</span><span class="p">(</span><span class="n">argc</span> <span class="o">==</span> <span class="mi">2</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">imshow</span><span class="p">(</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;eigenface_reconstruction_%d&quot;</span><span class="p">,</span> <span class="n">num_components</span><span class="p">),</span> <span class="n">reconstruction</span><span class="p">);</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
        <span class="n">imwrite</span><span class="p">(</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;%s/eigenface_reconstruction_%d.png&quot;</span><span class="p">,</span> <span class="n">output_folder</span><span class="p">.</span><span class="n">c_str</span><span class="p">(),</span> <span class="n">num_components</span><span class="p">),</span> <span class="n">reconstruction</span><span class="p">);</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>10 Eigenvectors are obviously not sufficient for a good image reconstruction, 50 Eigenvectors may already be sufficient to encode important facial features. You&#8217;ll get a good reconstruction with approximately 300 Eigenvectors for the AT&amp;T Facedatabase. There are rule of thumbs how many Eigenfaces you should choose for a successful face recognition, but it heavily depends on the input data. <a class="reference internal" href="#zhao03" id="id13">[Zhao03]</a> is the perfect point to start researching for this:</p>
<img alt="../../../../_images/eigenface_reconstruction_opencv.png" class="align-center" src="../../../../_images/eigenface_reconstruction_opencv.png" />
</div>
</div>
<div class="section" id="fisherfaces">
<h2><a class="toc-backref" href="#id35">Fisherfaces</a><a class="headerlink" href="#fisherfaces" title="Permalink to this headline">¶</a></h2>
<p>The Principal Component Analysis (PCA), which is the core of the Eigenfaces method, finds a linear combination of features that maximizes the total variance in data. While this is clearly a powerful way to represent data, it doesn&#8217;t consider any classes and so a lot of discriminative information <em>may</em> be lost when throwing components away. Imagine a situation where the variance in your data is generated by an external source, let it be the light. The components identified by a PCA do not necessarily contain any discriminative information at all, so the projected samples are smeared together and a classification becomes impossible (see <a class="reference external" href="http://www.bytefish.de/wiki/pca_lda_with_gnu_octave">http://www.bytefish.de/wiki/pca_lda_with_gnu_octave</a> for an example).</p>
<p>The Linear Discriminant Analysis performs a class-specific dimensionality reduction and was invented by the great statistician <a class="reference external" href="http://en.wikipedia.org/wiki/Ronald_Fisher">Sir R. A. Fisher</a>. He successfully used it for classifying flowers in his 1936 paper <em>The use of multiple measurements in taxonomic problems</em> <a class="reference internal" href="#fisher36" id="id14">[Fisher36]</a>. In order to find the combination of features that separates best between classes the Linear Discriminant Analysis maximizes the ratio of between-classes to within-classes scatter, instead of maximizing the overall scatter. The idea is simple: same classes should cluster tightly together, while different classes are as far away as possible from each other in the lower-dimensional representation. This was also recognized by <a class="reference external" href="http://www.cs.columbia.edu/~belhumeur/">Belhumeur</a>, <a class="reference external" href="http://www.ece.ucsb.edu/~hespanha/">Hespanha</a> and <a class="reference external" href="http://cseweb.ucsd.edu/~kriegman/">Kriegman</a> and so they applied a Discriminant Analysis to face recognition in <a class="reference internal" href="#bhk97" id="id15">[BHK97]</a>.</p>
<div class="section" id="id16">
<h3><a class="toc-backref" href="#id36">Algorithmic Description</a><a class="headerlink" href="#id16" title="Permalink to this headline">¶</a></h3>
<p>Let <img class="math" src="../../../../_images/math/fafd29e009c7f1dad892ccedf94e8d48d8a94c45.png" alt="X"/> be a random vector with samples drawn from <img class="math" src="../../../../_images/math/b595412ef4afa9e0329c294b97d9aad5d67ceebb.png" alt="c"/> classes:</p>
<div class="math">
<p><img src="../../../../_images/math/18a6fcf31effcba883e2ab9edda8a41c69a55c1f.png" alt="\begin{align*}
    X &amp; = &amp; \{X_1,X_2,\ldots,X_c\} \\
    X_i &amp; = &amp; \{x_1, x_2, \ldots, x_n\}
\end{align*}"/></p>
</div><p>The scatter matrices <img class="math" src="../../../../_images/math/4922f5f1cb2756af69657134deb8dd9c59f9f87d.png" alt="S_{B}"/> and <cite>S_{W}</cite> are calculated as:</p>
<div class="math">
<p><img src="../../../../_images/math/47c5a42e0f497c2f6364c687f5d248f9a0c8bd78.png" alt="\begin{align*}
    S_{B} &amp; = &amp; \sum_{i=1}^{c} N_{i} (\mu_i - \mu)(\mu_i - \mu)^{T} \\
    S_{W} &amp; = &amp; \sum_{i=1}^{c} \sum_{x_{j} \in X_{i}} (x_j - \mu_i)(x_j - \mu_i)^{T}
\end{align*}"/></p>
</div><p>, where <img class="math" src="../../../../_images/math/ec805c307200ba71431f930eed5f64e00233c713.png" alt="\mu"/> is the total mean:</p>
<div class="math">
<p><img src="../../../../_images/math/b8ccd3cb61a7a760b25fb8c11b7c134c2c393785.png" alt="\mu = \frac{1}{N} \sum_{i=1}^{N} x_i"/></p>
</div><p>And <img class="math" src="../../../../_images/math/48b9ef9cc9bd8fd0160174b6a08fbdead50988e8.png" alt="\mu_i"/> is the mean of class <img class="math" src="../../../../_images/math/ffb3ccd5943c0855f40f525472f642ee41b0ba2e.png" alt="i \in \{1,\ldots,c\}"/>:</p>
<div class="math">
<p><img src="../../../../_images/math/3c376f49b70e2c4e3046f13d7d5d8dfdd4773fd4.png" alt="\mu_i = \frac{1}{|X_i|} \sum_{x_j \in X_i} x_j"/></p>
</div><p>Fisher&#8217;s classic algorithm now looks for a projection <img class="math" src="../../../../_images/math/0a5fb805f99a12f7e8154567e7624d50ad920d4f.png" alt="W"/>, that maximizes the class separability criterion:</p>
<div class="math">
<p><img src="../../../../_images/math/d22a48671704b1fa4babeef5b9a05cf2021f96ad.png" alt="W_{opt} = \operatorname{arg\,max}_{W} \frac{|W^T S_B W|}{|W^T S_W W|}"/></p>
</div><p>Following <a class="reference internal" href="#bhk97" id="id17">[BHK97]</a>, a solution for this optimization problem is given by solving the General Eigenvalue Problem:</p>
<div class="math">
<p><img src="../../../../_images/math/69ccbec81596acc25c3277538e050798cde7268c.png" alt="\begin{align*}
    S_{B} v_{i} &amp; = &amp; \lambda_{i} S_w v_{i} \nonumber \\
    S_{W}^{-1} S_{B} v_{i} &amp; = &amp; \lambda_{i} v_{i}
\end{align*}"/></p>
</div><p>There&#8217;s one problem left to solve: The rank of <img class="math" src="../../../../_images/math/85ad8500592fe7402b9de35d18a5e7156ef13bfa.png" alt="S_{W}"/> is at most <img class="math" src="../../../../_images/math/338f4beaefcc181763e69ec193efcd4a9a477137.png" alt="(N-c)"/>, with <img class="math" src="../../../../_images/math/b7fa5a60940a885027b1a7928d7b1d3f7431c8a2.png" alt="N"/> samples and <img class="math" src="../../../../_images/math/b595412ef4afa9e0329c294b97d9aad5d67ceebb.png" alt="c"/> classes. In pattern recognition problems the number of samples <img class="math" src="../../../../_images/math/b7fa5a60940a885027b1a7928d7b1d3f7431c8a2.png" alt="N"/> is almost always samller than the dimension of the input data (the number of pixels), so the scatter matrix <img class="math" src="../../../../_images/math/85ad8500592fe7402b9de35d18a5e7156ef13bfa.png" alt="S_{W}"/> becomes singular (see <a class="reference internal" href="#rj91" id="id18">[RJ91]</a>). In <a class="reference internal" href="#bhk97" id="id19">[BHK97]</a> this was solved by performing a Principal Component Analysis on the data and projecting the samples into the <img class="math" src="../../../../_images/math/338f4beaefcc181763e69ec193efcd4a9a477137.png" alt="(N-c)"/>-dimensional space. A Linear Discriminant Analysis was then performed on the reduced data, because <img class="math" src="../../../../_images/math/85ad8500592fe7402b9de35d18a5e7156ef13bfa.png" alt="S_{W}"/> isn&#8217;t singular anymore.</p>
<p>The optimization problem can then be rewritten as:</p>
<div class="math">
<p><img src="../../../../_images/math/cc618b0cec5e716a98d3917a8a482f4b05f40037.png" alt="\begin{align*}
    W_{pca} &amp; = &amp; \operatorname{arg\,max}_{W} |W^T S_T W| \\
    W_{fld} &amp; = &amp; \operatorname{arg\,max}_{W} \frac{|W^T W_{pca}^T S_{B} W_{pca} W|}{|W^T W_{pca}^T S_{W} W_{pca} W|}
\end{align*}"/></p>
</div><p>The transformation matrix <img class="math" src="../../../../_images/math/0a5fb805f99a12f7e8154567e7624d50ad920d4f.png" alt="W"/>, that projects a sample into the <img class="math" src="../../../../_images/math/35fdcf50da96b2684608c7a8c4bd4989aeecf342.png" alt="(c-1)"/>-dimensional space is then given by:</p>
<div class="math">
<p><img src="../../../../_images/math/875053f54d15e47eb04beb9337844c45cfe4a9f4.png" alt="W = W_{fld}^{T} W_{pca}^{T}"/></p>
</div></div>
<div class="section" id="fisherfaces-in-opencv">
<h3><a class="toc-backref" href="#id37">Fisherfaces in OpenCV</a><a class="headerlink" href="#fisherfaces-in-opencv" title="Permalink to this headline">¶</a></h3>
<div class="highlight-cpp"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>  1
  2
  3
  4
  5
  6
  7
  8
  9
 10
 11
 12
 13
 14
 15
 16
 17
 18
 19
 20
 21
 22
 23
 24
 25
 26
 27
 28
 29
 30
 31
 32
 33
 34
 35
 36
 37
 38
 39
 40
 41
 42
 43
 44
 45
 46
 47
 48
 49
 50
 51
 52
 53
 54
 55
 56
 57
 58
 59
 60
 61
 62
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191</pre></div></td><td class="code"><div class="highlight"><pre><span class="cm">/*</span>
<span class="cm"> * Copyright (c) 2011. Philipp Wagner &lt;bytefish[at]gmx[dot]de&gt;.</span>
<span class="cm"> * Released to public domain under terms of the BSD Simplified license.</span>
<span class="cm"> *</span>
<span class="cm"> * Redistribution and use in source and binary forms, with or without</span>
<span class="cm"> * modification, are permitted provided that the following conditions are met:</span>
<span class="cm"> *   * Redistributions of source code must retain the above copyright</span>
<span class="cm"> *     notice, this list of conditions and the following disclaimer.</span>
<span class="cm"> *   * Redistributions in binary form must reproduce the above copyright</span>
<span class="cm"> *     notice, this list of conditions and the following disclaimer in the</span>
<span class="cm"> *     documentation and/or other materials provided with the distribution.</span>
<span class="cm"> *   * Neither the name of the organization nor the names of its contributors</span>
<span class="cm"> *     may be used to endorse or promote products derived from this software</span>
<span class="cm"> *     without specific prior written permission.</span>
<span class="cm"> *</span>
<span class="cm"> *   See &lt;http://www.opensource.org/licenses/bsd-license&gt;</span>
<span class="cm"> */</span>

<span class="cp">#include</span> <span class="cpf">&quot;opencv2/core/core.hpp&quot;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&quot;opencv2/contrib/contrib.hpp&quot;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&quot;opencv2/highgui/highgui.hpp&quot;</span><span class="cp"></span>

<span class="cp">#include</span> <span class="cpf">&lt;iostream&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;fstream&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;sstream&gt;</span><span class="cp"></span>

<span class="k">using</span> <span class="k">namespace</span> <span class="n">cv</span><span class="p">;</span>
<span class="k">using</span> <span class="k">namespace</span> <span class="n">std</span><span class="p">;</span>

<span class="k">static</span> <span class="n">Mat</span> <span class="nf">norm_0_255</span><span class="p">(</span><span class="n">InputArray</span> <span class="n">_src</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">Mat</span> <span class="n">src</span> <span class="o">=</span> <span class="n">_src</span><span class="p">.</span><span class="n">getMat</span><span class="p">();</span>
    <span class="c1">// Create and return normalized image:</span>
    <span class="n">Mat</span> <span class="n">dst</span><span class="p">;</span>
    <span class="k">switch</span><span class="p">(</span><span class="n">src</span><span class="p">.</span><span class="n">channels</span><span class="p">())</span> <span class="p">{</span>
    <span class="k">case</span> <span class="mi">1</span><span class="o">:</span>
        <span class="n">cv</span><span class="o">::</span><span class="n">normalize</span><span class="p">(</span><span class="n">_src</span><span class="p">,</span> <span class="n">dst</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="n">NORM_MINMAX</span><span class="p">,</span> <span class="n">CV_8UC1</span><span class="p">);</span>
        <span class="k">break</span><span class="p">;</span>
    <span class="k">case</span> <span class="mi">3</span><span class="o">:</span>
        <span class="n">cv</span><span class="o">::</span><span class="n">normalize</span><span class="p">(</span><span class="n">_src</span><span class="p">,</span> <span class="n">dst</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="n">NORM_MINMAX</span><span class="p">,</span> <span class="n">CV_8UC3</span><span class="p">);</span>
        <span class="k">break</span><span class="p">;</span>
    <span class="k">default</span><span class="o">:</span>
        <span class="n">src</span><span class="p">.</span><span class="n">copyTo</span><span class="p">(</span><span class="n">dst</span><span class="p">);</span>
        <span class="k">break</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">dst</span><span class="p">;</span>
<span class="p">}</span>

<span class="k">static</span> <span class="kt">void</span> <span class="n">read_csv</span><span class="p">(</span><span class="k">const</span> <span class="n">string</span><span class="o">&amp;</span> <span class="n">filename</span><span class="p">,</span> <span class="n">vector</span><span class="o">&lt;</span><span class="n">Mat</span><span class="o">&gt;&amp;</span> <span class="n">images</span><span class="p">,</span> <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&amp;</span> <span class="n">labels</span><span class="p">,</span> <span class="kt">char</span> <span class="n">separator</span> <span class="o">=</span> <span class="sc">&#39;;&#39;</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">std</span><span class="o">::</span><span class="n">ifstream</span> <span class="n">file</span><span class="p">(</span><span class="n">filename</span><span class="p">.</span><span class="n">c_str</span><span class="p">(),</span> <span class="n">ifstream</span><span class="o">::</span><span class="n">in</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">file</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">string</span> <span class="n">error_message</span> <span class="o">=</span> <span class="s">&quot;No valid input file was given, please check the given filename.&quot;</span><span class="p">;</span>
        <span class="n">CV_Error</span><span class="p">(</span><span class="n">CV_StsBadArg</span><span class="p">,</span> <span class="n">error_message</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="n">string</span> <span class="n">line</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">classlabel</span><span class="p">;</span>
    <span class="k">while</span> <span class="p">(</span><span class="n">getline</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="n">line</span><span class="p">))</span> <span class="p">{</span>
        <span class="n">stringstream</span> <span class="n">liness</span><span class="p">(</span><span class="n">line</span><span class="p">);</span>
        <span class="n">getline</span><span class="p">(</span><span class="n">liness</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">separator</span><span class="p">);</span>
        <span class="n">getline</span><span class="p">(</span><span class="n">liness</span><span class="p">,</span> <span class="n">classlabel</span><span class="p">);</span>
        <span class="k">if</span><span class="p">(</span><span class="o">!</span><span class="n">path</span><span class="p">.</span><span class="n">empty</span><span class="p">()</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">classlabel</span><span class="p">.</span><span class="n">empty</span><span class="p">())</span> <span class="p">{</span>
            <span class="n">images</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">imread</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="mi">0</span><span class="p">));</span>
            <span class="n">labels</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">atoi</span><span class="p">(</span><span class="n">classlabel</span><span class="p">.</span><span class="n">c_str</span><span class="p">()));</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="kt">int</span> <span class="n">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">argv</span><span class="p">[])</span> <span class="p">{</span>
    <span class="c1">// Check for valid command line arguments, print usage</span>
    <span class="c1">// if no arguments were given.</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">argc</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;usage: &quot;</span> <span class="o">&lt;&lt;</span> <span class="n">argv</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;&lt;</span> <span class="s">&quot; &lt;csv.ext&gt; &lt;output_folder&gt; &quot;</span> <span class="o">&lt;&lt;</span> <span class="n">endl</span><span class="p">;</span>
        <span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="n">string</span> <span class="n">output_folder</span> <span class="o">=</span> <span class="s">&quot;.&quot;</span><span class="p">;</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">argc</span> <span class="o">==</span> <span class="mi">3</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">output_folder</span> <span class="o">=</span> <span class="n">string</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">2</span><span class="p">]);</span>
    <span class="p">}</span>
    <span class="c1">// Get the path to your CSV.</span>
    <span class="n">string</span> <span class="n">fn_csv</span> <span class="o">=</span> <span class="n">string</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>
    <span class="c1">// These vectors hold the images and corresponding labels.</span>
    <span class="n">vector</span><span class="o">&lt;</span><span class="n">Mat</span><span class="o">&gt;</span> <span class="n">images</span><span class="p">;</span>
    <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">labels</span><span class="p">;</span>
    <span class="c1">// Read in the data. This can fail if no valid</span>
    <span class="c1">// input filename is given.</span>
    <span class="k">try</span> <span class="p">{</span>
        <span class="n">read_csv</span><span class="p">(</span><span class="n">fn_csv</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">);</span>
    <span class="p">}</span> <span class="k">catch</span> <span class="p">(</span><span class="n">cv</span><span class="o">::</span><span class="n">Exception</span><span class="o">&amp;</span> <span class="n">e</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">cerr</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;Error opening file </span><span class="se">\&quot;</span><span class="s">&quot;</span> <span class="o">&lt;&lt;</span> <span class="n">fn_csv</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;</span><span class="se">\&quot;</span><span class="s">. Reason: &quot;</span> <span class="o">&lt;&lt;</span> <span class="n">e</span><span class="p">.</span><span class="n">msg</span> <span class="o">&lt;&lt;</span> <span class="n">endl</span><span class="p">;</span>
        <span class="c1">// nothing more we can do</span>
        <span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="c1">// Quit if there are not enough images for this demo.</span>
    <span class="k">if</span><span class="p">(</span><span class="n">images</span><span class="p">.</span><span class="n">size</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">string</span> <span class="n">error_message</span> <span class="o">=</span> <span class="s">&quot;This demo needs at least 2 images to work. Please add more images to your data set!&quot;</span><span class="p">;</span>
        <span class="n">CV_Error</span><span class="p">(</span><span class="n">CV_StsError</span><span class="p">,</span> <span class="n">error_message</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="c1">// Get the height from the first image. We&#39;ll need this</span>
    <span class="c1">// later in code to reshape the images to their original</span>
    <span class="c1">// size:</span>
    <span class="kt">int</span> <span class="n">height</span> <span class="o">=</span> <span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">rows</span><span class="p">;</span>
    <span class="c1">// The following lines simply get the last images from</span>
    <span class="c1">// your dataset and remove it from the vector. This is</span>
    <span class="c1">// done, so that the training data (which we learn the</span>
    <span class="c1">// cv::FaceRecognizer on) and the test data we test</span>
    <span class="c1">// the model with, do not overlap.</span>
    <span class="n">Mat</span> <span class="n">testSample</span> <span class="o">=</span> <span class="n">images</span><span class="p">[</span><span class="n">images</span><span class="p">.</span><span class="n">size</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">];</span>
    <span class="kt">int</span> <span class="n">testLabel</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">labels</span><span class="p">.</span><span class="n">size</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">];</span>
    <span class="n">images</span><span class="p">.</span><span class="n">pop_back</span><span class="p">();</span>
    <span class="n">labels</span><span class="p">.</span><span class="n">pop_back</span><span class="p">();</span>
    <span class="c1">// The following lines create an Fisherfaces model for</span>
    <span class="c1">// face recognition and train it with the images and</span>
    <span class="c1">// labels read from the given CSV file.</span>
    <span class="c1">// If you just want to keep 10 Fisherfaces, then call</span>
    <span class="c1">// the factory method like this:</span>
    <span class="c1">//</span>
    <span class="c1">//      cv::createFisherFaceRecognizer(10);</span>
    <span class="c1">//</span>
    <span class="c1">// However it is not useful to discard Fisherfaces! Please</span>
    <span class="c1">// always try to use _all_ available Fisherfaces for</span>
    <span class="c1">// classification.</span>
    <span class="c1">//</span>
    <span class="c1">// If you want to create a FaceRecognizer with a</span>
    <span class="c1">// confidence threshold (e.g. 123.0) and use _all_</span>
    <span class="c1">// Fisherfaces, then call it with:</span>
    <span class="c1">//</span>
    <span class="c1">//      cv::createFisherFaceRecognizer(0, 123.0);</span>
    <span class="c1">//</span>
    <span class="n">Ptr</span><span class="o">&lt;</span><span class="n">FaceRecognizer</span><span class="o">&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">createFisherFaceRecognizer</span><span class="p">();</span>
    <span class="n">model</span><span class="o">-&gt;</span><span class="n">train</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">);</span>
    <span class="c1">// The following line predicts the label of a given</span>
    <span class="c1">// test image:</span>
    <span class="kt">int</span> <span class="n">predictedLabel</span> <span class="o">=</span> <span class="n">model</span><span class="o">-&gt;</span><span class="n">predict</span><span class="p">(</span><span class="n">testSample</span><span class="p">);</span>
    <span class="c1">//</span>
    <span class="c1">// To get the confidence of a prediction call the model with:</span>
    <span class="c1">//</span>
    <span class="c1">//      int predictedLabel = -1;</span>
    <span class="c1">//      double confidence = 0.0;</span>
    <span class="c1">//      model-&gt;predict(testSample, predictedLabel, confidence);</span>
    <span class="c1">//</span>
    <span class="n">string</span> <span class="n">result_message</span> <span class="o">=</span> <span class="n">format</span><span class="p">(</span><span class="s">&quot;Predicted class = %d / Actual class = %d.&quot;</span><span class="p">,</span> <span class="n">predictedLabel</span><span class="p">,</span> <span class="n">testLabel</span><span class="p">);</span>
    <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">result_message</span> <span class="o">&lt;&lt;</span> <span class="n">endl</span><span class="p">;</span>
    <span class="c1">// Here is how to get the eigenvalues of this Eigenfaces model:</span>
    <span class="n">Mat</span> <span class="n">eigenvalues</span> <span class="o">=</span> <span class="n">model</span><span class="o">-&gt;</span><span class="n">getMat</span><span class="p">(</span><span class="s">&quot;eigenvalues&quot;</span><span class="p">);</span>
    <span class="c1">// And we can do the same to display the Eigenvectors (read Eigenfaces):</span>
    <span class="n">Mat</span> <span class="n">W</span> <span class="o">=</span> <span class="n">model</span><span class="o">-&gt;</span><span class="n">getMat</span><span class="p">(</span><span class="s">&quot;eigenvectors&quot;</span><span class="p">);</span>
    <span class="c1">// Get the sample mean from the training data</span>
    <span class="n">Mat</span> <span class="n">mean</span> <span class="o">=</span> <span class="n">model</span><span class="o">-&gt;</span><span class="n">getMat</span><span class="p">(</span><span class="s">&quot;mean&quot;</span><span class="p">);</span>
    <span class="c1">// Display or save:</span>
    <span class="k">if</span><span class="p">(</span><span class="n">argc</span> <span class="o">==</span> <span class="mi">2</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">imshow</span><span class="p">(</span><span class="s">&quot;mean&quot;</span><span class="p">,</span> <span class="n">norm_0_255</span><span class="p">(</span><span class="n">mean</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">rows</span><span class="p">)));</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
        <span class="n">imwrite</span><span class="p">(</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;%s/mean.png&quot;</span><span class="p">,</span> <span class="n">output_folder</span><span class="p">.</span><span class="n">c_str</span><span class="p">()),</span> <span class="n">norm_0_255</span><span class="p">(</span><span class="n">mean</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">rows</span><span class="p">)));</span>
    <span class="p">}</span>
    <span class="c1">// Display or save the first, at most 16 Fisherfaces:</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">min</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">W</span><span class="p">.</span><span class="n">cols</span><span class="p">);</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">string</span> <span class="n">msg</span> <span class="o">=</span> <span class="n">format</span><span class="p">(</span><span class="s">&quot;Eigenvalue #%d = %.5f&quot;</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">eigenvalues</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="n">i</span><span class="p">));</span>
        <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">msg</span> <span class="o">&lt;&lt;</span> <span class="n">endl</span><span class="p">;</span>
        <span class="c1">// get eigenvector #i</span>
        <span class="n">Mat</span> <span class="n">ev</span> <span class="o">=</span> <span class="n">W</span><span class="p">.</span><span class="n">col</span><span class="p">(</span><span class="n">i</span><span class="p">).</span><span class="n">clone</span><span class="p">();</span>
        <span class="c1">// Reshape to original size &amp; normalize to [0...255] for imshow.</span>
        <span class="n">Mat</span> <span class="n">grayscale</span> <span class="o">=</span> <span class="n">norm_0_255</span><span class="p">(</span><span class="n">ev</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">height</span><span class="p">));</span>
        <span class="c1">// Show the image &amp; apply a Bone colormap for better sensing.</span>
        <span class="n">Mat</span> <span class="n">cgrayscale</span><span class="p">;</span>
        <span class="n">applyColorMap</span><span class="p">(</span><span class="n">grayscale</span><span class="p">,</span> <span class="n">cgrayscale</span><span class="p">,</span> <span class="n">COLORMAP_BONE</span><span class="p">);</span>
        <span class="c1">// Display or save:</span>
        <span class="k">if</span><span class="p">(</span><span class="n">argc</span> <span class="o">==</span> <span class="mi">2</span><span class="p">)</span> <span class="p">{</span>
            <span class="n">imshow</span><span class="p">(</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;fisherface_%d&quot;</span><span class="p">,</span> <span class="n">i</span><span class="p">),</span> <span class="n">cgrayscale</span><span class="p">);</span>
        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
            <span class="n">imwrite</span><span class="p">(</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;%s/fisherface_%d.png&quot;</span><span class="p">,</span> <span class="n">output_folder</span><span class="p">.</span><span class="n">c_str</span><span class="p">(),</span> <span class="n">i</span><span class="p">),</span> <span class="n">norm_0_255</span><span class="p">(</span><span class="n">cgrayscale</span><span class="p">));</span>
        <span class="p">}</span>
    <span class="p">}</span>
    <span class="c1">// Display or save the image reconstruction at some predefined steps:</span>
    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">num_component</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">num_component</span> <span class="o">&lt;</span> <span class="n">min</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">W</span><span class="p">.</span><span class="n">cols</span><span class="p">);</span> <span class="n">num_component</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="c1">// Slice the Fisherface from the model:</span>
        <span class="n">Mat</span> <span class="n">ev</span> <span class="o">=</span> <span class="n">W</span><span class="p">.</span><span class="n">col</span><span class="p">(</span><span class="n">num_component</span><span class="p">);</span>
        <span class="n">Mat</span> <span class="n">projection</span> <span class="o">=</span> <span class="n">subspaceProject</span><span class="p">(</span><span class="n">ev</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">));</span>
        <span class="n">Mat</span> <span class="n">reconstruction</span> <span class="o">=</span> <span class="n">subspaceReconstruct</span><span class="p">(</span><span class="n">ev</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">projection</span><span class="p">);</span>
        <span class="c1">// Normalize the result:</span>
        <span class="n">reconstruction</span> <span class="o">=</span> <span class="n">norm_0_255</span><span class="p">(</span><span class="n">reconstruction</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">rows</span><span class="p">));</span>
        <span class="c1">// Display or save:</span>
        <span class="k">if</span><span class="p">(</span><span class="n">argc</span> <span class="o">==</span> <span class="mi">2</span><span class="p">)</span> <span class="p">{</span>
            <span class="n">imshow</span><span class="p">(</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;fisherface_reconstruction_%d&quot;</span><span class="p">,</span> <span class="n">num_component</span><span class="p">),</span> <span class="n">reconstruction</span><span class="p">);</span>
        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
            <span class="n">imwrite</span><span class="p">(</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;%s/fisherface_reconstruction_%d.png&quot;</span><span class="p">,</span> <span class="n">output_folder</span><span class="p">.</span><span class="n">c_str</span><span class="p">(),</span> <span class="n">num_component</span><span class="p">),</span> <span class="n">reconstruction</span><span class="p">);</span>
        <span class="p">}</span>
    <span class="p">}</span>
    <span class="c1">// Display if we are not writing to an output folder:</span>
    <span class="k">if</span><span class="p">(</span><span class="n">argc</span> <span class="o">==</span> <span class="mi">2</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">waitKey</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</td></tr></table></div>
<p>The source code for this demo application is also available in the <code class="docutils literal"><span class="pre">src</span></code> folder coming with this documentation:</p>
<ul class="simple">
<li><a class="reference download internal" href="../../../../_downloads/facerec_fisherfaces.cpp" download=""><code class="xref download docutils literal"><span class="pre">src/facerec_fisherfaces.cpp</span></code></a></li>
</ul>
<p>For this example I am going to use the Yale Facedatabase A, just because the plots are nicer. Each Fisherface has the same length as an original image, thus it can be displayed as an image. The demo shows (or saves) the first, at most 16 Fisherfaces:</p>
<img alt="../../../../_images/fisherfaces_opencv.png" class="align-center" src="../../../../_images/fisherfaces_opencv.png" />
<p>The Fisherfaces method learns a class-specific transformation matrix, so the they do not capture illumination as obviously as the Eigenfaces method. The Discriminant Analysis instead finds the facial features to discriminate between the persons. It&#8217;s important to mention, that the performance of the Fisherfaces heavily depends on the input data as well. Practically said: if you learn the Fisherfaces for well-illuminated pictures only and you try to recognize faces in bad-illuminated scenes, then method is likely to find the wrong components (just because those features may not be predominant on bad illuminated images). This is somewhat logical, since the method had no chance to learn the illumination.</p>
<p>The Fisherfaces allow a reconstruction of the projected image, just like the Eigenfaces did. But since we only identified the features to distinguish between subjects, you can&#8217;t expect a nice reconstruction of the original image. For the Fisherfaces method we&#8217;ll project the sample image onto each of the Fisherfaces instead. So you&#8217;ll have a nice visualization, which feature each of the Fisherfaces describes:</p>
<div class="highlight-cpp"><div class="highlight"><pre><span class="c1">// Display or save the image reconstruction at some predefined steps:</span>
<span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">num_component</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">num_component</span> <span class="o">&lt;</span> <span class="n">min</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">W</span><span class="p">.</span><span class="n">cols</span><span class="p">);</span> <span class="n">num_component</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// Slice the Fisherface from the model:</span>
    <span class="n">Mat</span> <span class="n">ev</span> <span class="o">=</span> <span class="n">W</span><span class="p">.</span><span class="n">col</span><span class="p">(</span><span class="n">num_component</span><span class="p">);</span>
    <span class="n">Mat</span> <span class="n">projection</span> <span class="o">=</span> <span class="n">subspaceProject</span><span class="p">(</span><span class="n">ev</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">));</span>
    <span class="n">Mat</span> <span class="n">reconstruction</span> <span class="o">=</span> <span class="n">subspaceReconstruct</span><span class="p">(</span><span class="n">ev</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">projection</span><span class="p">);</span>
    <span class="c1">// Normalize the result:</span>
    <span class="n">reconstruction</span> <span class="o">=</span> <span class="n">norm_0_255</span><span class="p">(</span><span class="n">reconstruction</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">rows</span><span class="p">));</span>
    <span class="c1">// Display or save:</span>
    <span class="k">if</span><span class="p">(</span><span class="n">argc</span> <span class="o">==</span> <span class="mi">2</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">imshow</span><span class="p">(</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;fisherface_reconstruction_%d&quot;</span><span class="p">,</span> <span class="n">num_component</span><span class="p">),</span> <span class="n">reconstruction</span><span class="p">);</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
        <span class="n">imwrite</span><span class="p">(</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;%s/fisherface_reconstruction_%d.png&quot;</span><span class="p">,</span> <span class="n">output_folder</span><span class="p">.</span><span class="n">c_str</span><span class="p">(),</span> <span class="n">num_component</span><span class="p">),</span> <span class="n">reconstruction</span><span class="p">);</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The differences may be subtle for the human eyes, but you should be able to see some differences:</p>
<img alt="../../../../_images/fisherface_reconstruction_opencv.png" class="align-center" src="../../../../_images/fisherface_reconstruction_opencv.png" />
</div>
</div>
<div class="section" id="local-binary-patterns-histograms">
<h2><a class="toc-backref" href="#id38">Local Binary Patterns Histograms</a><a class="headerlink" href="#local-binary-patterns-histograms" title="Permalink to this headline">¶</a></h2>
<p>Eigenfaces and Fisherfaces take a somewhat holistic approach to face recognition. You treat your data as a vector somewhere in a high-dimensional image space. We all know high-dimensionality is bad, so a lower-dimensional subspace is identified, where (probably) useful information is preserved. The Eigenfaces approach maximizes the total scatter, which can lead to problems if the variance is generated by an external source, because components with a maximum variance over all classes aren&#8217;t necessarily useful for classification (see <a class="reference external" href="http://www.bytefish.de/wiki/pca_lda_with_gnu_octave">http://www.bytefish.de/wiki/pca_lda_with_gnu_octave</a>). So to preserve some discriminative information we applied a Linear Discriminant Analysis and optimized as described in the Fisherfaces method. The Fisherfaces method worked great... at least for the constrained scenario we&#8217;ve assumed in our model.</p>
<p>Now real life isn&#8217;t perfect. You simply can&#8217;t guarantee perfect light settings in your images or 10 different images of a person. So what if there&#8217;s only one image for each person? Our covariance estimates for the subspace <em>may</em> be horribly wrong, so will the recognition. Remember the Eigenfaces method had a 96% recognition rate on the AT&amp;T Facedatabase? How many images do we actually need to get such useful estimates? Here are the Rank-1 recognition rates of the Eigenfaces and Fisherfaces method on the AT&amp;T Facedatabase, which is a fairly easy image database:</p>
<a class="reference internal image-reference" href="../../../../_images/at_database_small_sample_size.png"><img alt="../../../../_images/at_database_small_sample_size.png" class="align-center" src="../../../../_images/at_database_small_sample_size.png" /></a>
<p>So in order to get good recognition rates you&#8217;ll need at least 8(+-1) images for each person and the Fisherfaces method doesn&#8217;t really help here. The above experiment is a 10-fold cross validated result carried out with the facerec framework at: <a class="reference external" href="https://github.com/bytefish/facerec">https://github.com/bytefish/facerec</a>. This is not a publication, so I won&#8217;t back these figures with a deep mathematical analysis. Please have a look into <a class="reference internal" href="#km01" id="id21">[KM01]</a> for a detailed analysis of both methods, when it comes to small training datasets.</p>
<p>So some research concentrated on extracting local features from images. The idea is to not look at the whole image as a high-dimensional vector, but describe only local features of an object. The features you extract this way will have a low-dimensionality implicitly. A fine idea! But you&#8217;ll soon observe the image representation we are given doesn&#8217;t only suffer from illumination variations. Think of things like scale, translation or rotation in images - your local description has to be at least a bit robust against those things. Just like <a class="reference internal" href="../../../nonfree/doc/feature_detection.html#SIFT : public Feature2D" title="class SIFT : public Feature2D"><code class="xref ocv ocv-class docutils literal"><span class="pre">SIFT</span></code></a>, the Local Binary Patterns methodology has its roots in 2D texture analysis. The basic idea of Local Binary Patterns is to summarize the local structure in an image by comparing each pixel with its neighborhood. Take a pixel as center and threshold its neighbors against. If the intensity of the center pixel is greater-equal its neighbor, then denote it with 1 and 0 if not. You&#8217;ll end up with a binary number for each pixel, just like 11001111. So with 8 surrounding pixels you&#8217;ll end up with 2^8 possible combinations, called <em>Local Binary Patterns</em> or sometimes referred to as <em>LBP codes</em>. The first LBP operator described in literature actually used a fixed 3 x 3 neighborhood just like this:</p>
<a class="reference internal image-reference" href="../../../../_images/lbp.png"><img alt="../../../../_images/lbp.png" class="align-center" src="../../../../_images/lbp.png" /></a>
<div class="section" id="id22">
<h3><a class="toc-backref" href="#id39">Algorithmic Description</a><a class="headerlink" href="#id22" title="Permalink to this headline">¶</a></h3>
<p>A more formal description of the LBP operator can be given as:</p>
<div class="math">
<p><img src="../../../../_images/math/a7ae9f9ea8ccaafa6e247b7b216933be4ecdac96.png" alt="LBP(x_c, y_c) = \sum_{p=0}^{P-1} 2^p s(i_p - i_c)"/></p>
</div><p>, with <img class="math" src="../../../../_images/math/b79e2877f0118aacfb0036d8d227f1a425b51116.png" alt="(x_c, y_c)"/> as central pixel with intensity <img class="math" src="../../../../_images/math/c7647ea34b269909068505f78a6fb0a3a4822bd4.png" alt="i_c"/>; and <img class="math" src="../../../../_images/math/27433b91e73af9ef8b23933a940b3eaadc14442e.png" alt="i_n"/> being the intensity of the the neighbor pixel. <img class="math" src="../../../../_images/math/287d37d98a8184b185835553d75475a9cc7cf748.png" alt="s"/> is the sign function defined as:</p>
<div class="math">
<p><img src="../../../../_images/math/951c2f36012d781ade9de209e3f9d72bca7b7919.png" alt="\begin{equation}
s(x) =
\begin{cases}
1 &amp; \text{if $x \geq 0$}\\
0 &amp; \text{else}
\end{cases}
\end{equation}"/></p>
</div><p>This description enables you to capture very fine grained details in images. In fact the authors were able to compete with state of the art results for texture classification. Soon after the operator was published it was noted, that a fixed neighborhood fails to encode details differing in scale. So the operator was extended to use a variable neighborhood in <a class="reference internal" href="#ahp04" id="id23">[AHP04]</a>. The idea is to align an abritrary number of neighbors on a circle with a variable radius, which enables to capture the following neighborhoods:</p>
<a class="reference internal image-reference" href="../../../../_images/patterns.png"><img alt="../../../../_images/patterns.png" class="align-center" src="../../../../_images/patterns.png" /></a>
<p>For a given Point <img class="math" src="../../../../_images/math/bca3f111465b567adeab43c46331dee771a1ed7e.png" alt="(x_c,y_c)"/> the position of the neighbor <img class="math" src="../../../../_images/math/afab0b5621d8b3105de62d7d1e9a3e5f3850d9aa.png" alt="(x_p,y_p), p \in P"/> can be calculated by:</p>
<div class="math">
<p><img src="../../../../_images/math/dd2911a240e7d45a66c0c0ec08feadf473bbfe72.png" alt="\begin{align*}
x_{p} &amp; = &amp; x_c + R \cos({\frac{2\pi p}{P}})\\
y_{p} &amp; = &amp; y_c - R \sin({\frac{2\pi p}{P}})
\end{align*}"/></p>
</div><p>Where <img class="math" src="../../../../_images/math/8fa391da5431a5d6eaba1325c3e7cb3da22812b5.png" alt="R"/> is the radius of the circle and <img class="math" src="../../../../_images/math/09799091dd377d8002dcc397386afa9a7828bad6.png" alt="P"/> is the number of sample points.</p>
<p>The operator is an extension to the original LBP codes, so it&#8217;s sometimes called <em>Extended LBP</em> (also referred to as <em>Circular LBP</em>) . If a points coordinate on the circle doesn&#8217;t correspond to image coordinates, the point get&#8217;s interpolated. Computer science has a bunch of clever interpolation schemes, the OpenCV implementation does a bilinear interpolation:</p>
<div class="math">
<p><img src="../../../../_images/math/8e91162b3865994e6d9a9acca7494957c12f2b29.png" alt="\begin{align*}
f(x,y) \approx \begin{bmatrix}
    1-x &amp; x \end{bmatrix} \begin{bmatrix}
    f(0,0) &amp; f(0,1) \\
    f(1,0) &amp; f(1,1) \end{bmatrix} \begin{bmatrix}
    1-y \\
    y \end{bmatrix}.
\end{align*}"/></p>
</div><p>By definition the LBP operator is robust against monotonic gray scale transformations. We can easily verify this by looking at the LBP image of an artificially modified image (so you see what an LBP image looks like!):</p>
<a class="reference internal image-reference" href="../../../../_images/lbp_yale.jpg"><img alt="../../../../_images/lbp_yale.jpg" class="align-center" src="../../../../_images/lbp_yale.jpg" /></a>
<p>So what&#8217;s left to do is how to incorporate the spatial information in the face recognition model. The representation proposed by Ahonen et. al <a class="reference internal" href="#ahp04" id="id24">[AHP04]</a> is to divide the LBP image into <img class="math" src="../../../../_images/math/1869b83f9b79e056554e9fe569425472c8108995.png" alt="m"/> local regions and extract a histogram from each. The spatially enhanced feature vector is then obtained by concatenating the local histograms (<strong>not merging them</strong>). These histograms are called <em>Local Binary Patterns Histograms</em>.</p>
</div>
<div class="section" id="local-binary-patterns-histograms-in-opencv">
<h3><a class="toc-backref" href="#id40">Local Binary Patterns Histograms in OpenCV</a><a class="headerlink" href="#local-binary-patterns-histograms-in-opencv" title="Permalink to this headline">¶</a></h3>
<div class="highlight-cpp"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>  1
  2
  3
  4
  5
  6
  7
  8
  9
 10
 11
 12
 13
 14
 15
 16
 17
 18
 19
 20
 21
 22
 23
 24
 25
 26
 27
 28
 29
 30
 31
 32
 33
 34
 35
 36
 37
 38
 39
 40
 41
 42
 43
 44
 45
 46
 47
 48
 49
 50
 51
 52
 53
 54
 55
 56
 57
 58
 59
 60
 61
 62
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155</pre></div></td><td class="code"><div class="highlight"><pre><span class="cm">/*</span>
<span class="cm"> * Copyright (c) 2011. Philipp Wagner &lt;bytefish[at]gmx[dot]de&gt;.</span>
<span class="cm"> * Released to public domain under terms of the BSD Simplified license.</span>
<span class="cm"> *</span>
<span class="cm"> * Redistribution and use in source and binary forms, with or without</span>
<span class="cm"> * modification, are permitted provided that the following conditions are met:</span>
<span class="cm"> *   * Redistributions of source code must retain the above copyright</span>
<span class="cm"> *     notice, this list of conditions and the following disclaimer.</span>
<span class="cm"> *   * Redistributions in binary form must reproduce the above copyright</span>
<span class="cm"> *     notice, this list of conditions and the following disclaimer in the</span>
<span class="cm"> *     documentation and/or other materials provided with the distribution.</span>
<span class="cm"> *   * Neither the name of the organization nor the names of its contributors</span>
<span class="cm"> *     may be used to endorse or promote products derived from this software</span>
<span class="cm"> *     without specific prior written permission.</span>
<span class="cm"> *</span>
<span class="cm"> *   See &lt;http://www.opensource.org/licenses/bsd-license&gt;</span>
<span class="cm"> */</span>

<span class="cp">#include</span> <span class="cpf">&quot;opencv2/core/core.hpp&quot;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&quot;opencv2/contrib/contrib.hpp&quot;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&quot;opencv2/highgui/highgui.hpp&quot;</span><span class="cp"></span>

<span class="cp">#include</span> <span class="cpf">&lt;iostream&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;fstream&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;sstream&gt;</span><span class="cp"></span>

<span class="k">using</span> <span class="k">namespace</span> <span class="n">cv</span><span class="p">;</span>
<span class="k">using</span> <span class="k">namespace</span> <span class="n">std</span><span class="p">;</span>

<span class="k">static</span> <span class="kt">void</span> <span class="n">read_csv</span><span class="p">(</span><span class="k">const</span> <span class="n">string</span><span class="o">&amp;</span> <span class="n">filename</span><span class="p">,</span> <span class="n">vector</span><span class="o">&lt;</span><span class="n">Mat</span><span class="o">&gt;&amp;</span> <span class="n">images</span><span class="p">,</span> <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&amp;</span> <span class="n">labels</span><span class="p">,</span> <span class="kt">char</span> <span class="n">separator</span> <span class="o">=</span> <span class="sc">&#39;;&#39;</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">std</span><span class="o">::</span><span class="n">ifstream</span> <span class="n">file</span><span class="p">(</span><span class="n">filename</span><span class="p">.</span><span class="n">c_str</span><span class="p">(),</span> <span class="n">ifstream</span><span class="o">::</span><span class="n">in</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">file</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">string</span> <span class="n">error_message</span> <span class="o">=</span> <span class="s">&quot;No valid input file was given, please check the given filename.&quot;</span><span class="p">;</span>
        <span class="n">CV_Error</span><span class="p">(</span><span class="n">CV_StsBadArg</span><span class="p">,</span> <span class="n">error_message</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="n">string</span> <span class="n">line</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">classlabel</span><span class="p">;</span>
    <span class="k">while</span> <span class="p">(</span><span class="n">getline</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="n">line</span><span class="p">))</span> <span class="p">{</span>
        <span class="n">stringstream</span> <span class="n">liness</span><span class="p">(</span><span class="n">line</span><span class="p">);</span>
        <span class="n">getline</span><span class="p">(</span><span class="n">liness</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">separator</span><span class="p">);</span>
        <span class="n">getline</span><span class="p">(</span><span class="n">liness</span><span class="p">,</span> <span class="n">classlabel</span><span class="p">);</span>
        <span class="k">if</span><span class="p">(</span><span class="o">!</span><span class="n">path</span><span class="p">.</span><span class="n">empty</span><span class="p">()</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">classlabel</span><span class="p">.</span><span class="n">empty</span><span class="p">())</span> <span class="p">{</span>
            <span class="n">images</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">imread</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="mi">0</span><span class="p">));</span>
            <span class="n">labels</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">atoi</span><span class="p">(</span><span class="n">classlabel</span><span class="p">.</span><span class="n">c_str</span><span class="p">()));</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="kt">int</span> <span class="n">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">argv</span><span class="p">[])</span> <span class="p">{</span>
    <span class="c1">// Check for valid command line arguments, print usage</span>
    <span class="c1">// if no arguments were given.</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">argc</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;usage: &quot;</span> <span class="o">&lt;&lt;</span> <span class="n">argv</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;&lt;</span> <span class="s">&quot; &lt;csv.ext&gt;&quot;</span> <span class="o">&lt;&lt;</span> <span class="n">endl</span><span class="p">;</span>
        <span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="c1">// Get the path to your CSV.</span>
    <span class="n">string</span> <span class="n">fn_csv</span> <span class="o">=</span> <span class="n">string</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>
    <span class="c1">// These vectors hold the images and corresponding labels.</span>
    <span class="n">vector</span><span class="o">&lt;</span><span class="n">Mat</span><span class="o">&gt;</span> <span class="n">images</span><span class="p">;</span>
    <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">labels</span><span class="p">;</span>
    <span class="c1">// Read in the data. This can fail if no valid</span>
    <span class="c1">// input filename is given.</span>
    <span class="k">try</span> <span class="p">{</span>
        <span class="n">read_csv</span><span class="p">(</span><span class="n">fn_csv</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">);</span>
    <span class="p">}</span> <span class="k">catch</span> <span class="p">(</span><span class="n">cv</span><span class="o">::</span><span class="n">Exception</span><span class="o">&amp;</span> <span class="n">e</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">cerr</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;Error opening file </span><span class="se">\&quot;</span><span class="s">&quot;</span> <span class="o">&lt;&lt;</span> <span class="n">fn_csv</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;</span><span class="se">\&quot;</span><span class="s">. Reason: &quot;</span> <span class="o">&lt;&lt;</span> <span class="n">e</span><span class="p">.</span><span class="n">msg</span> <span class="o">&lt;&lt;</span> <span class="n">endl</span><span class="p">;</span>
        <span class="c1">// nothing more we can do</span>
        <span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="c1">// Quit if there are not enough images for this demo.</span>
    <span class="k">if</span><span class="p">(</span><span class="n">images</span><span class="p">.</span><span class="n">size</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">string</span> <span class="n">error_message</span> <span class="o">=</span> <span class="s">&quot;This demo needs at least 2 images to work. Please add more images to your data set!&quot;</span><span class="p">;</span>
        <span class="n">CV_Error</span><span class="p">(</span><span class="n">CV_StsError</span><span class="p">,</span> <span class="n">error_message</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="c1">// Get the height from the first image. We&#39;ll need this</span>
    <span class="c1">// later in code to reshape the images to their original</span>
    <span class="c1">// size:</span>
    <span class="kt">int</span> <span class="n">height</span> <span class="o">=</span> <span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">rows</span><span class="p">;</span>
    <span class="c1">// The following lines simply get the last images from</span>
    <span class="c1">// your dataset and remove it from the vector. This is</span>
    <span class="c1">// done, so that the training data (which we learn the</span>
    <span class="c1">// cv::FaceRecognizer on) and the test data we test</span>
    <span class="c1">// the model with, do not overlap.</span>
    <span class="n">Mat</span> <span class="n">testSample</span> <span class="o">=</span> <span class="n">images</span><span class="p">[</span><span class="n">images</span><span class="p">.</span><span class="n">size</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">];</span>
    <span class="kt">int</span> <span class="n">testLabel</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">labels</span><span class="p">.</span><span class="n">size</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">];</span>
    <span class="n">images</span><span class="p">.</span><span class="n">pop_back</span><span class="p">();</span>
    <span class="n">labels</span><span class="p">.</span><span class="n">pop_back</span><span class="p">();</span>
    <span class="c1">// The following lines create an LBPH model for</span>
    <span class="c1">// face recognition and train it with the images and</span>
    <span class="c1">// labels read from the given CSV file.</span>
    <span class="c1">//</span>
    <span class="c1">// The LBPHFaceRecognizer uses Extended Local Binary Patterns</span>
    <span class="c1">// (it&#39;s probably configurable with other operators at a later</span>
    <span class="c1">// point), and has the following default values</span>
    <span class="c1">//</span>
    <span class="c1">//      radius = 1</span>
    <span class="c1">//      neighbors = 8</span>
    <span class="c1">//      grid_x = 8</span>
    <span class="c1">//      grid_y = 8</span>
    <span class="c1">//</span>
    <span class="c1">// So if you want a LBPH FaceRecognizer using a radius of</span>
    <span class="c1">// 2 and 16 neighbors, call the factory method with:</span>
    <span class="c1">//</span>
    <span class="c1">//      cv::createLBPHFaceRecognizer(2, 16);</span>
    <span class="c1">//</span>
    <span class="c1">// And if you want a threshold (e.g. 123.0) call it with its default values:</span>
    <span class="c1">//</span>
    <span class="c1">//      cv::createLBPHFaceRecognizer(1,8,8,8,123.0)</span>
    <span class="c1">//</span>
    <span class="n">Ptr</span><span class="o">&lt;</span><span class="n">FaceRecognizer</span><span class="o">&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">createLBPHFaceRecognizer</span><span class="p">();</span>
    <span class="n">model</span><span class="o">-&gt;</span><span class="n">train</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">);</span>
    <span class="c1">// The following line predicts the label of a given</span>
    <span class="c1">// test image:</span>
    <span class="kt">int</span> <span class="n">predictedLabel</span> <span class="o">=</span> <span class="n">model</span><span class="o">-&gt;</span><span class="n">predict</span><span class="p">(</span><span class="n">testSample</span><span class="p">);</span>
    <span class="c1">//</span>
    <span class="c1">// To get the confidence of a prediction call the model with:</span>
    <span class="c1">//</span>
    <span class="c1">//      int predictedLabel = -1;</span>
    <span class="c1">//      double confidence = 0.0;</span>
    <span class="c1">//      model-&gt;predict(testSample, predictedLabel, confidence);</span>
    <span class="c1">//</span>
    <span class="n">string</span> <span class="n">result_message</span> <span class="o">=</span> <span class="n">format</span><span class="p">(</span><span class="s">&quot;Predicted class = %d / Actual class = %d.&quot;</span><span class="p">,</span> <span class="n">predictedLabel</span><span class="p">,</span> <span class="n">testLabel</span><span class="p">);</span>
    <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">result_message</span> <span class="o">&lt;&lt;</span> <span class="n">endl</span><span class="p">;</span>
    <span class="c1">// Sometimes you&#39;ll need to get/set internal model data,</span>
    <span class="c1">// which isn&#39;t exposed by the public cv::FaceRecognizer.</span>
    <span class="c1">// Since each cv::FaceRecognizer is derived from a</span>
    <span class="c1">// cv::Algorithm, you can query the data.</span>
    <span class="c1">//</span>
    <span class="c1">// First we&#39;ll use it to set the threshold of the FaceRecognizer</span>
    <span class="c1">// to 0.0 without retraining the model. This can be useful if</span>
    <span class="c1">// you are evaluating the model:</span>
    <span class="c1">//</span>
    <span class="n">model</span><span class="o">-&gt;</span><span class="n">set</span><span class="p">(</span><span class="s">&quot;threshold&quot;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">);</span>
    <span class="c1">// Now the threshold of this model is set to 0.0. A prediction</span>
    <span class="c1">// now returns -1, as it&#39;s impossible to have a distance below</span>
    <span class="c1">// it</span>
    <span class="n">predictedLabel</span> <span class="o">=</span> <span class="n">model</span><span class="o">-&gt;</span><span class="n">predict</span><span class="p">(</span><span class="n">testSample</span><span class="p">);</span>
    <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;Predicted class = &quot;</span> <span class="o">&lt;&lt;</span> <span class="n">predictedLabel</span> <span class="o">&lt;&lt;</span> <span class="n">endl</span><span class="p">;</span>
    <span class="c1">// Show some informations about the model, as there&#39;s no cool</span>
    <span class="c1">// Model data to display as in Eigenfaces/Fisherfaces.</span>
    <span class="c1">// Due to efficiency reasons the LBP images are not stored</span>
    <span class="c1">// within the model:</span>
    <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;Model Information:&quot;</span> <span class="o">&lt;&lt;</span> <span class="n">endl</span><span class="p">;</span>
    <span class="n">string</span> <span class="n">model_info</span> <span class="o">=</span> <span class="n">format</span><span class="p">(</span><span class="s">&quot;</span><span class="se">\t</span><span class="s">LBPH(radius=%i, neighbors=%i, grid_x=%i, grid_y=%i, threshold=%.2f)&quot;</span><span class="p">,</span>
            <span class="n">model</span><span class="o">-&gt;</span><span class="n">getInt</span><span class="p">(</span><span class="s">&quot;radius&quot;</span><span class="p">),</span>
            <span class="n">model</span><span class="o">-&gt;</span><span class="n">getInt</span><span class="p">(</span><span class="s">&quot;neighbors&quot;</span><span class="p">),</span>
            <span class="n">model</span><span class="o">-&gt;</span><span class="n">getInt</span><span class="p">(</span><span class="s">&quot;grid_x&quot;</span><span class="p">),</span>
            <span class="n">model</span><span class="o">-&gt;</span><span class="n">getInt</span><span class="p">(</span><span class="s">&quot;grid_y&quot;</span><span class="p">),</span>
            <span class="n">model</span><span class="o">-&gt;</span><span class="n">getDouble</span><span class="p">(</span><span class="s">&quot;threshold&quot;</span><span class="p">));</span>
    <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">model_info</span> <span class="o">&lt;&lt;</span> <span class="n">endl</span><span class="p">;</span>
    <span class="c1">// We could get the histograms for example:</span>
    <span class="n">vector</span><span class="o">&lt;</span><span class="n">Mat</span><span class="o">&gt;</span> <span class="n">histograms</span> <span class="o">=</span> <span class="n">model</span><span class="o">-&gt;</span><span class="n">getMatVector</span><span class="p">(</span><span class="s">&quot;histograms&quot;</span><span class="p">);</span>
    <span class="c1">// But should I really visualize it? Probably the length is interesting:</span>
    <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;Size of the histograms: &quot;</span> <span class="o">&lt;&lt;</span> <span class="n">histograms</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">total</span><span class="p">()</span> <span class="o">&lt;&lt;</span> <span class="n">endl</span><span class="p">;</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</td></tr></table></div>
<p>The source code for this demo application is also available in the <code class="docutils literal"><span class="pre">src</span></code> folder coming with this documentation:</p>
<ul class="simple">
<li><a class="reference download internal" href="../../../../_downloads/facerec_lbph.cpp" download=""><code class="xref download docutils literal"><span class="pre">src/facerec_lbph.cpp</span></code></a></li>
</ul>
</div>
</div>
<div class="section" id="conclusion">
<h2><a class="toc-backref" href="#id41">Conclusion</a><a class="headerlink" href="#conclusion" title="Permalink to this headline">¶</a></h2>
<p>You&#8217;ve learned how to use the new <a class="reference internal" href="facerec_api.html#FaceRecognizer : public Algorithm" title="class FaceRecognizer : public Algorithm"><code class="xref ocv ocv-class docutils literal"><span class="pre">FaceRecognizer</span></code></a> in real applications. After reading the document you also know how the algorithms work, so now it&#8217;s time for you to experiment with the available algorithms. Use them, improve them and let the OpenCV community participate!</p>
</div>
<div class="section" id="credits">
<h2><a class="toc-backref" href="#id42">Credits</a><a class="headerlink" href="#credits" title="Permalink to this headline">¶</a></h2>
<p>This document wouldn&#8217;t be possible without the kind permission to use the face images of the <em>AT&amp;T Database of Faces</em> and the <em>Yale Facedatabase A/B</em>.</p>
<div class="section" id="the-database-of-faces">
<h3><a class="toc-backref" href="#id43">The Database of Faces</a><a class="headerlink" href="#the-database-of-faces" title="Permalink to this headline">¶</a></h3>
<p>** Important: when using these images, please give credit to &#8220;AT&amp;T Laboratories, Cambridge.&#8221; **</p>
<p>The Database of Faces, formerly <em>The ORL Database of Faces</em>, contains a set of face images taken between April 1992 and April 1994. The database was used in the context of a face recognition project carried out in collaboration with the Speech, Vision and Robotics Group of the Cambridge University Engineering Department.</p>
<p>There are ten different images of each of 40 distinct subjects. For some subjects, the images were taken at different times, varying the lighting, facial expressions (open / closed eyes, smiling / not smiling) and facial details (glasses / no glasses). All the images were taken against a dark homogeneous background with the subjects in an upright, frontal position (with tolerance for some side movement).</p>
<p>The files are in PGM format. The size of each image is 92x112 pixels, with 256 grey levels per pixel. The images are organised in 40 directories (one for each subject), which have names of the form sX, where X indicates the subject number (between 1 and 40). In each of these directories, there are ten different images of that subject, which have names of the form Y.pgm, where Y is the image number for that subject (between 1 and 10).</p>
<p>A copy of the database can be retrieved from: <a class="reference external" href="http://www.cl.cam.ac.uk/research/dtg/attarchive/pub/data/att_faces.zip">http://www.cl.cam.ac.uk/research/dtg/attarchive/pub/data/att_faces.zip</a>.</p>
</div>
<div class="section" id="id25">
<h3><a class="toc-backref" href="#id44">Yale Facedatabase A</a><a class="headerlink" href="#id25" title="Permalink to this headline">¶</a></h3>
<p><em>With the permission of the authors I am allowed to show a small number of images (say subject 1 and all the variations) and all images such as Fisherfaces and Eigenfaces from either Yale Facedatabase A or the Yale Facedatabase B.</em></p>
<p>The Yale Face Database A (size 6.4MB) contains 165 grayscale images in GIF format of 15 individuals. There are 11 images per subject, one per different facial expression or configuration: center-light, w/glasses, happy, left-light, w/no glasses, normal, right-light, sad, sleepy, surprised, and wink. (Source: <a class="reference external" href="http://cvc.yale.edu/projects/yalefaces/yalefaces.html">http://cvc.yale.edu/projects/yalefaces/yalefaces.html</a>)</p>
</div>
<div class="section" id="yale-facedatabase-b">
<h3><a class="toc-backref" href="#id45">Yale Facedatabase B</a><a class="headerlink" href="#yale-facedatabase-b" title="Permalink to this headline">¶</a></h3>
<p><em>With the permission of the authors I am allowed to show a small number of images (say subject 1 and all the variations) and all images such as Fisherfaces and Eigenfaces from either Yale Facedatabase A or the Yale Facedatabase B.</em></p>
<p>The extended Yale Face Database B contains 16128 images of 28 human subjects under 9 poses and 64 illumination conditions. The data format of this database is the same as the Yale Face Database B. Please refer to the homepage of the Yale Face Database B (or one copy of this page) for more detailed information of the data format.</p>
<p>You are free to use the extended Yale Face Database B for research purposes. All publications which use this database should acknowledge the use of &#8220;the Exteded Yale Face Database B&#8221; and reference Athinodoros Georghiades, Peter Belhumeur, and David Kriegman&#8217;s paper, &#8220;From Few to Many: Illumination Cone Models for Face Recognition under Variable Lighting and Pose&#8221;, PAMI, 2001, <a class="reference external" href="http://vision.ucsd.edu/~leekc/ExtYaleDatabase/athosref.html">[bibtex]</a>.</p>
<p>The extended database as opposed to the original Yale Face Database B with 10 subjects was first reported by Kuang-Chih Lee, Jeffrey Ho, and David Kriegman in &#8220;Acquiring Linear Subspaces for Face Recognition under Variable Lighting, PAMI, May, 2005 <a class="reference external" href="http://vision.ucsd.edu/~leekc/papers/9pltsIEEE.pdf">[pdf]</a>.&#8221; All test image data used in the experiments are manually aligned, cropped, and then re-sized to 168x192 images. If you publish your experimental results with the cropped images, please reference the PAMI2005 paper as well. (Source: <a class="reference external" href="http://vision.ucsd.edu/~leekc/ExtYaleDatabase/ExtYaleB.html">http://vision.ucsd.edu/~leekc/ExtYaleDatabase/ExtYaleB.html</a>)</p>
</div>
</div>
<div class="section" id="literature">
<h2><a class="toc-backref" href="#id46">Literature</a><a class="headerlink" href="#literature" title="Permalink to this headline">¶</a></h2>
<table class="docutils citation" frame="void" id="ahp04" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[AHP04]</td><td><em>(<a class="fn-backref" href="#id8">1</a>, <a class="fn-backref" href="#id23">2</a>, <a class="fn-backref" href="#id24">3</a>)</em> Ahonen, T., Hadid, A., and Pietikainen, M. <em>Face Recognition with Local Binary Patterns.</em> Computer Vision - ECCV 2004 (2004), 469–481.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="bhk97" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[BHK97]</td><td><em>(<a class="fn-backref" href="#id5">1</a>, <a class="fn-backref" href="#id10">2</a>, <a class="fn-backref" href="#id15">3</a>, <a class="fn-backref" href="#id17">4</a>, <a class="fn-backref" href="#id19">5</a>)</em> Belhumeur, P. N., Hespanha, J., and Kriegman, D. <em>Eigenfaces vs. Fisherfaces: Recognition Using Class Specific Linear Projection.</em> IEEE Transactions on Pattern Analysis and Machine Intelligence 19, 7 (1997), 711–720.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="bru92" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id3">[Bru92]</a></td><td>Brunelli, R., Poggio, T. <em>Face Recognition through Geometrical Features.</em> European Conference on Computer Vision (ECCV) 1992, S. 792–800.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="duda01" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id12">[Duda01]</a></td><td>Duda, Richard O. and Hart, Peter E. and Stork, David G., <em>Pattern Classification</em> (2nd Edition) 2001.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="fisher36" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id14">[Fisher36]</a></td><td>Fisher, R. A. <em>The use of multiple measurements in taxonomic problems.</em> Annals Eugen. 7 (1936), 179–188.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="gbk01" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[GBK01]</td><td>Georghiades, A.S. and Belhumeur, P.N. and Kriegman, D.J., <em>From Few to Many: Illumination Cone Models for Face Recognition under Variable Lighting and Pose</em> IEEE Transactions on Pattern Analysis and Machine Intelligence 23, 6 (2001), 643-660.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="kanade73" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id2">[Kanade73]</a></td><td>Kanade, T. <em>Picture processing system by computer complex and recognition of human faces.</em> PhD thesis, Kyoto University, November 1973</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="km01" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id21">[KM01]</a></td><td>Martinez, A and Kak, A. <em>PCA versus LDA</em> IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 23, No.2, pp. 228-233, 2001.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="lee05" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id11">[Lee05]</a></td><td>Lee, K., Ho, J., Kriegman, D. <em>Acquiring Linear Subspaces for Face Recognition under Variable Lighting.</em> In: IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI) 27 (2005), Nr. 5</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="messer06" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id7">[Messer06]</a></td><td>Messer, K. et al. <em>Performance Characterisation of Face Recognition Algorithms and Their Sensitivity to Severe Illumination Changes.</em> In: In: ICB, 2006, S. 1–11.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="rj91" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id18">[RJ91]</a></td><td><ol class="first last upperalpha simple" start="19">
<li>Raudys and  A.K. Jain.  <em>Small  sample  size  effects in statistical  pattern  recognition: Recommendations for  practitioneers.</em> - IEEE Transactions on Pattern Analysis and Machine Intelligence 13, 3 (1991), 252-264.</li>
</ol>
</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="tan10" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Tan10]</td><td>Tan, X., and Triggs, B. <em>Enhanced local texture feature sets for face recognition under difficult lighting conditions.</em> IEEE Transactions on Image Processing 19 (2010), 1635–650.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="tp91" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id4">[TP91]</a></td><td>Turk, M., and Pentland, A. <em>Eigenfaces for recognition.</em> Journal of Cognitive Neuroscience 3 (1991), 71–86.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="tu06" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[Tu06]</a></td><td>Chiara Turati, Viola Macchi Cassia, F. S., and Leo, I. <em>Newborns face recognition: Role of inner and outer facial features. Child Development</em> 77, 2 (2006), 297–311.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="wiskott97" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id6">[Wiskott97]</a></td><td>Wiskott, L., Fellous, J., Krüger, N., Malsburg, C. <em>Face Recognition By Elastic Bunch Graph Matching.</em> IEEE Transactions on Pattern Analysis and Machine Intelligence 19 (1997), S. 775–779</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="zhao03" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id13">[Zhao03]</a></td><td>Zhao, W., Chellappa, R., Phillips, P., and Rosenfeld, A. Face recognition: A literature survey. ACM Computing Surveys (CSUR) 35, 4 (2003), 399–458.</td></tr>
</tbody>
</table>
</div>
<div class="section" id="appendix">
<span id="appendixft"></span><h2><a class="toc-backref" href="#id47">Appendix</a><a class="headerlink" href="#appendix" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id26">
<h3><a class="toc-backref" href="#id48">Creating the CSV File</a><a class="headerlink" href="#id26" title="Permalink to this headline">¶</a></h3>
<p>You don&#8217;t really want to create the CSV file by hand. I have prepared you a little Python script <code class="docutils literal"><span class="pre">create_csv.py</span></code> (you find it at <code class="docutils literal"><span class="pre">/src/create_csv.py</span></code> coming with this tutorial) that automatically creates you a CSV file. If you have your images in hierarchie like this (<code class="docutils literal"><span class="pre">/basepath/&lt;subject&gt;/&lt;image.ext&gt;</span></code>):</p>
<div class="highlight-none"><div class="highlight"><pre>philipp@mango:~/facerec/data/at$ tree
.
|-- s1
|   |-- 1.pgm
|   |-- ...
|   |-- 10.pgm
|-- s2
|   |-- 1.pgm
|   |-- ...
|   |-- 10.pgm
...
|-- s40
|   |-- 1.pgm
|   |-- ...
|   |-- 10.pgm
</pre></div>
</div>
<p>Then simply call <code class="docutils literal"><span class="pre">create_csv.py</span></code> with the path to the folder, just like this and you could save the output:</p>
<div class="highlight-none"><div class="highlight"><pre>philipp@mango:~/facerec/data$ python create_csv.py
at/s13/2.pgm;0
at/s13/7.pgm;0
at/s13/6.pgm;0
at/s13/9.pgm;0
at/s13/5.pgm;0
at/s13/3.pgm;0
at/s13/4.pgm;0
at/s13/10.pgm;0
at/s13/8.pgm;0
at/s13/1.pgm;0
at/s17/2.pgm;1
at/s17/7.pgm;1
at/s17/6.pgm;1
at/s17/9.pgm;1
at/s17/5.pgm;1
at/s17/3.pgm;1
[...]
</pre></div>
</div>
<p>Here is the script, if you can&#8217;t find it:</p>
<div class="highlight-python"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43</pre></div></td><td class="code"><div class="highlight"><pre><span class="ch">#!/usr/bin/env python</span>

<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">os.path</span>

<span class="c1"># This is a tiny script to help you creating a CSV file from a face</span>
<span class="c1"># database with a similar hierarchie:</span>
<span class="c1">#</span>
<span class="c1">#  philipp@mango:~/facerec/data/at$ tree</span>
<span class="c1">#  .</span>
<span class="c1">#  |-- README</span>
<span class="c1">#  |-- s1</span>
<span class="c1">#  |   |-- 1.pgm</span>
<span class="c1">#  |   |-- ...</span>
<span class="c1">#  |   |-- 10.pgm</span>
<span class="c1">#  |-- s2</span>
<span class="c1">#  |   |-- 1.pgm</span>
<span class="c1">#  |   |-- ...</span>
<span class="c1">#  |   |-- 10.pgm</span>
<span class="c1">#  ...</span>
<span class="c1">#  |-- s40</span>
<span class="c1">#  |   |-- 1.pgm</span>
<span class="c1">#  |   |-- ...</span>
<span class="c1">#  |   |-- 10.pgm</span>
<span class="c1">#</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">print</span> <span class="s2">&quot;usage: create_csv &lt;base_path&gt;&quot;</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">BASE_PATH</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">SEPARATOR</span><span class="o">=</span><span class="s2">&quot;;&quot;</span>

    <span class="n">label</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">dirname</span><span class="p">,</span> <span class="n">dirnames</span><span class="p">,</span> <span class="n">filenames</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">walk</span><span class="p">(</span><span class="n">BASE_PATH</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">subdirname</span> <span class="ow">in</span> <span class="n">dirnames</span><span class="p">:</span>
            <span class="n">subject_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dirname</span><span class="p">,</span> <span class="n">subdirname</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">filename</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">subject_path</span><span class="p">):</span>
                <span class="n">abs_path</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">%s</span><span class="s2">/</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">subject_path</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
                <span class="k">print</span> <span class="s2">&quot;</span><span class="si">%s%s%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">abs_path</span><span class="p">,</span> <span class="n">SEPARATOR</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
            <span class="n">label</span> <span class="o">=</span> <span class="n">label</span> <span class="o">+</span> <span class="mi">1</span>
</pre></div>
</td></tr></table></div>
</div>
<div class="section" id="aligning-face-images">
<h3><a class="toc-backref" href="#id49">Aligning Face Images</a><a class="headerlink" href="#aligning-face-images" title="Permalink to this headline">¶</a></h3>
<p>An accurate alignment of your image data is especially important in tasks like emotion detection, were you need as much detail as possible. Believe me... You don&#8217;t want to do this by hand. So I&#8217;ve prepared you a tiny Python script. The code is really easy to use. To scale, rotate and crop the face image you just need to call <em>CropFace(image, eye_left, eye_right, offset_pct, dest_sz)</em>, where:</p>
<ul class="simple">
<li><em>eye_left</em> is the position of the left eye</li>
<li><em>eye_right</em> is the position of the right eye</li>
<li><em>offset_pct</em> is the percent of the image you want to keep next to the eyes (horizontal, vertical direction)</li>
<li><em>dest_sz</em> is the size of the output image</li>
</ul>
<p>If you are using the same <em>offset_pct</em> and <em>dest_sz</em> for your images, they are all aligned at the eyes.</p>
<div class="highlight-python"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89</pre></div></td><td class="code"><div class="highlight"><pre><span class="ch">#!/usr/bin/env python</span>
<span class="c1"># Software License Agreement (BSD License)</span>
<span class="c1">#</span>
<span class="c1"># Copyright (c) 2012, Philipp Wagner</span>
<span class="c1"># All rights reserved.</span>
<span class="c1">#</span>
<span class="c1"># Redistribution and use in source and binary forms, with or without</span>
<span class="c1"># modification, are permitted provided that the following conditions</span>
<span class="c1"># are met:</span>
<span class="c1">#</span>
<span class="c1">#  * Redistributions of source code must retain the above copyright</span>
<span class="c1">#    notice, this list of conditions and the following disclaimer.</span>
<span class="c1">#  * Redistributions in binary form must reproduce the above</span>
<span class="c1">#    copyright notice, this list of conditions and the following</span>
<span class="c1">#    disclaimer in the documentation and/or other materials provided</span>
<span class="c1">#    with the distribution.</span>
<span class="c1">#  * Neither the name of the author nor the names of its</span>
<span class="c1">#    contributors may be used to endorse or promote products derived</span>
<span class="c1">#    from this software without specific prior written permission.</span>
<span class="c1">#</span>
<span class="c1"># THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS</span>
<span class="c1"># &quot;AS IS&quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT</span>
<span class="c1"># LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS</span>
<span class="c1"># FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE</span>
<span class="c1"># COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,</span>
<span class="c1"># INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,</span>
<span class="c1"># BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;</span>
<span class="c1"># LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER</span>
<span class="c1"># CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT</span>
<span class="c1"># LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN</span>
<span class="c1"># ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE</span>
<span class="c1"># POSSIBILITY OF SUCH DAMAGE.</span>

<span class="kn">import</span> <span class="nn">sys</span><span class="o">,</span> <span class="nn">math</span><span class="o">,</span> <span class="nn">Image</span>

<span class="k">def</span> <span class="nf">Distance</span><span class="p">(</span><span class="n">p1</span><span class="p">,</span><span class="n">p2</span><span class="p">):</span>
  <span class="n">dx</span> <span class="o">=</span> <span class="n">p2</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">p1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">dy</span> <span class="o">=</span> <span class="n">p2</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">p1</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
  <span class="k">return</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">dx</span><span class="o">*</span><span class="n">dx</span><span class="o">+</span><span class="n">dy</span><span class="o">*</span><span class="n">dy</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">ScaleRotateTranslate</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">angle</span><span class="p">,</span> <span class="n">center</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">new_center</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">scale</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">resample</span><span class="o">=</span><span class="n">Image</span><span class="o">.</span><span class="n">BICUBIC</span><span class="p">):</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">scale</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">center</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">image</span><span class="o">.</span><span class="n">rotate</span><span class="p">(</span><span class="n">angle</span><span class="o">=</span><span class="n">angle</span><span class="p">,</span> <span class="n">resample</span><span class="o">=</span><span class="n">resample</span><span class="p">)</span>
  <span class="n">nx</span><span class="p">,</span><span class="n">ny</span> <span class="o">=</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">center</span>
  <span class="n">sx</span><span class="o">=</span><span class="n">sy</span><span class="o">=</span><span class="mf">1.0</span>
  <span class="k">if</span> <span class="n">new_center</span><span class="p">:</span>
    <span class="p">(</span><span class="n">nx</span><span class="p">,</span><span class="n">ny</span><span class="p">)</span> <span class="o">=</span> <span class="n">new_center</span>
  <span class="k">if</span> <span class="n">scale</span><span class="p">:</span>
    <span class="p">(</span><span class="n">sx</span><span class="p">,</span><span class="n">sy</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="n">scale</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span>
  <span class="n">cosine</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">angle</span><span class="p">)</span>
  <span class="n">sine</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">angle</span><span class="p">)</span>
  <span class="n">a</span> <span class="o">=</span> <span class="n">cosine</span><span class="o">/</span><span class="n">sx</span>
  <span class="n">b</span> <span class="o">=</span> <span class="n">sine</span><span class="o">/</span><span class="n">sx</span>
  <span class="n">c</span> <span class="o">=</span> <span class="n">x</span><span class="o">-</span><span class="n">nx</span><span class="o">*</span><span class="n">a</span><span class="o">-</span><span class="n">ny</span><span class="o">*</span><span class="n">b</span>
  <span class="n">d</span> <span class="o">=</span> <span class="o">-</span><span class="n">sine</span><span class="o">/</span><span class="n">sy</span>
  <span class="n">e</span> <span class="o">=</span> <span class="n">cosine</span><span class="o">/</span><span class="n">sy</span>
  <span class="n">f</span> <span class="o">=</span> <span class="n">y</span><span class="o">-</span><span class="n">nx</span><span class="o">*</span><span class="n">d</span><span class="o">-</span><span class="n">ny</span><span class="o">*</span><span class="n">e</span>
  <span class="k">return</span> <span class="n">image</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">Image</span><span class="o">.</span><span class="n">AFFINE</span><span class="p">,</span> <span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">c</span><span class="p">,</span><span class="n">d</span><span class="p">,</span><span class="n">e</span><span class="p">,</span><span class="n">f</span><span class="p">),</span> <span class="n">resample</span><span class="o">=</span><span class="n">resample</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">CropFace</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">eye_left</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="n">eye_right</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="n">offset_pct</span><span class="o">=</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.2</span><span class="p">),</span> <span class="n">dest_sz</span> <span class="o">=</span> <span class="p">(</span><span class="mi">70</span><span class="p">,</span><span class="mi">70</span><span class="p">)):</span>
  <span class="c1"># calculate offsets in original image</span>
  <span class="n">offset_h</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">offset_pct</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">*</span><span class="n">dest_sz</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
  <span class="n">offset_v</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">offset_pct</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">*</span><span class="n">dest_sz</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
  <span class="c1"># get the direction</span>
  <span class="n">eye_direction</span> <span class="o">=</span> <span class="p">(</span><span class="n">eye_right</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">eye_left</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">eye_right</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">eye_left</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
  <span class="c1"># calc rotation angle in radians</span>
  <span class="n">rotation</span> <span class="o">=</span> <span class="o">-</span><span class="n">math</span><span class="o">.</span><span class="n">atan2</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">eye_direction</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span><span class="nb">float</span><span class="p">(</span><span class="n">eye_direction</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
  <span class="c1"># distance between them</span>
  <span class="n">dist</span> <span class="o">=</span> <span class="n">Distance</span><span class="p">(</span><span class="n">eye_left</span><span class="p">,</span> <span class="n">eye_right</span><span class="p">)</span>
  <span class="c1"># calculate the reference eye-width</span>
  <span class="n">reference</span> <span class="o">=</span> <span class="n">dest_sz</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mf">2.0</span><span class="o">*</span><span class="n">offset_h</span>
  <span class="c1"># scale factor</span>
  <span class="n">scale</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">dist</span><span class="p">)</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="n">reference</span><span class="p">)</span>
  <span class="c1"># rotate original around the left eye</span>
  <span class="n">image</span> <span class="o">=</span> <span class="n">ScaleRotateTranslate</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="n">eye_left</span><span class="p">,</span> <span class="n">angle</span><span class="o">=</span><span class="n">rotation</span><span class="p">)</span>
  <span class="c1"># crop the rotated image</span>
  <span class="n">crop_xy</span> <span class="o">=</span> <span class="p">(</span><span class="n">eye_left</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">scale</span><span class="o">*</span><span class="n">offset_h</span><span class="p">,</span> <span class="n">eye_left</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">scale</span><span class="o">*</span><span class="n">offset_v</span><span class="p">)</span>
  <span class="n">crop_size</span> <span class="o">=</span> <span class="p">(</span><span class="n">dest_sz</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">scale</span><span class="p">,</span> <span class="n">dest_sz</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">scale</span><span class="p">)</span>
  <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">crop</span><span class="p">((</span><span class="nb">int</span><span class="p">(</span><span class="n">crop_xy</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">int</span><span class="p">(</span><span class="n">crop_xy</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="nb">int</span><span class="p">(</span><span class="n">crop_xy</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="n">crop_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">int</span><span class="p">(</span><span class="n">crop_xy</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="n">crop_size</span><span class="p">[</span><span class="mi">1</span><span class="p">])))</span>
  <span class="c1"># resize it</span>
  <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">dest_sz</span><span class="p">,</span> <span class="n">Image</span><span class="o">.</span><span class="n">ANTIALIAS</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">image</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
  <span class="n">image</span> <span class="o">=</span>  <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&quot;arnie.jpg&quot;</span><span class="p">)</span>
  <span class="n">CropFace</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">eye_left</span><span class="o">=</span><span class="p">(</span><span class="mi">252</span><span class="p">,</span><span class="mi">364</span><span class="p">),</span> <span class="n">eye_right</span><span class="o">=</span><span class="p">(</span><span class="mi">420</span><span class="p">,</span><span class="mi">366</span><span class="p">),</span> <span class="n">offset_pct</span><span class="o">=</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.1</span><span class="p">),</span> <span class="n">dest_sz</span><span class="o">=</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span><span class="mi">200</span><span class="p">))</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;arnie_10_10_200_200.jpg&quot;</span><span class="p">)</span>
  <span class="n">CropFace</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">eye_left</span><span class="o">=</span><span class="p">(</span><span class="mi">252</span><span class="p">,</span><span class="mi">364</span><span class="p">),</span> <span class="n">eye_right</span><span class="o">=</span><span class="p">(</span><span class="mi">420</span><span class="p">,</span><span class="mi">366</span><span class="p">),</span> <span class="n">offset_pct</span><span class="o">=</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.2</span><span class="p">),</span> <span class="n">dest_sz</span><span class="o">=</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span><span class="mi">200</span><span class="p">))</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;arnie_20_20_200_200.jpg&quot;</span><span class="p">)</span>
  <span class="n">CropFace</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">eye_left</span><span class="o">=</span><span class="p">(</span><span class="mi">252</span><span class="p">,</span><span class="mi">364</span><span class="p">),</span> <span class="n">eye_right</span><span class="o">=</span><span class="p">(</span><span class="mi">420</span><span class="p">,</span><span class="mi">366</span><span class="p">),</span> <span class="n">offset_pct</span><span class="o">=</span><span class="p">(</span><span class="mf">0.3</span><span class="p">,</span><span class="mf">0.3</span><span class="p">),</span> <span class="n">dest_sz</span><span class="o">=</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span><span class="mi">200</span><span class="p">))</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;arnie_30_30_200_200.jpg&quot;</span><span class="p">)</span>
  <span class="n">CropFace</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">eye_left</span><span class="o">=</span><span class="p">(</span><span class="mi">252</span><span class="p">,</span><span class="mi">364</span><span class="p">),</span> <span class="n">eye_right</span><span class="o">=</span><span class="p">(</span><span class="mi">420</span><span class="p">,</span><span class="mi">366</span><span class="p">),</span> <span class="n">offset_pct</span><span class="o">=</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.2</span><span class="p">))</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;arnie_20_20_70_70.jpg&quot;</span><span class="p">)</span>
</pre></div>
</td></tr></table></div>
<p>Imagine we are given <a class="reference external" href="http://en.wikipedia.org/wiki/File:Arnold_Schwarzenegger_edit%28ws%29.jpg">this photo of Arnold Schwarzenegger</a>, which is under a Public Domain license. The (x,y)-position of the eyes is approximately <em>(252,364)</em> for the left and <em>(420,366)</em> for the right eye. Now you only need to define the horizontal offset, vertical offset and the size your scaled, rotated &amp; cropped face should have.</p>
<p>Here are some examples:</p>
<table border="1" class="docutils">
<colgroup>
<col width="30%" />
<col width="70%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Configuration</th>
<th class="head">Cropped, Scaled, Rotated Face</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>0.1 (10%), 0.1 (10%), (200,200)</td>
<td><img alt="../../../../_images/arnie_10_10_200_200.jpg" class="first last" src="../../../../_images/arnie_10_10_200_200.jpg" />
</td>
</tr>
<tr class="row-odd"><td>0.2 (20%), 0.2 (20%), (200,200)</td>
<td><img alt="../../../../_images/arnie_20_20_200_200.jpg" class="first last" src="../../../../_images/arnie_20_20_200_200.jpg" />
</td>
</tr>
<tr class="row-even"><td>0.3 (30%), 0.3 (30%), (200,200)</td>
<td><img alt="../../../../_images/arnie_30_30_200_200.jpg" class="first last" src="../../../../_images/arnie_30_30_200_200.jpg" />
</td>
</tr>
<tr class="row-odd"><td>0.2 (20%), 0.2 (20%), (70,70)</td>
<td><img alt="../../../../_images/arnie_20_20_70_70.jpg" class="first last" src="../../../../_images/arnie_20_20_70_70.jpg" />
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="csv-for-the-at-t-facedatabase">
<h3><a class="toc-backref" href="#id50">CSV for the AT&amp;T Facedatabase</a><a class="headerlink" href="#csv-for-the-at-t-facedatabase" title="Permalink to this headline">¶</a></h3>
<div class="highlight-none"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>  1
  2
  3
  4
  5
  6
  7
  8
  9
 10
 11
 12
 13
 14
 15
 16
 17
 18
 19
 20
 21
 22
 23
 24
 25
 26
 27
 28
 29
 30
 31
 32
 33
 34
 35
 36
 37
 38
 39
 40
 41
 42
 43
 44
 45
 46
 47
 48
 49
 50
 51
 52
 53
 54
 55
 56
 57
 58
 59
 60
 61
 62
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
378
379
380
381
382
383
384
385
386
387
388
389
390
391
392
393
394
395
396
397
398
399
400</pre></div></td><td class="code"><div class="highlight"><pre>/home/philipp/facerec/data/at/s13/2.pgm;12
/home/philipp/facerec/data/at/s13/7.pgm;12
/home/philipp/facerec/data/at/s13/6.pgm;12
/home/philipp/facerec/data/at/s13/9.pgm;12
/home/philipp/facerec/data/at/s13/5.pgm;12
/home/philipp/facerec/data/at/s13/3.pgm;12
/home/philipp/facerec/data/at/s13/4.pgm;12
/home/philipp/facerec/data/at/s13/10.pgm;12
/home/philipp/facerec/data/at/s13/8.pgm;12
/home/philipp/facerec/data/at/s13/1.pgm;12
/home/philipp/facerec/data/at/s17/2.pgm;16
/home/philipp/facerec/data/at/s17/7.pgm;16
/home/philipp/facerec/data/at/s17/6.pgm;16
/home/philipp/facerec/data/at/s17/9.pgm;16
/home/philipp/facerec/data/at/s17/5.pgm;16
/home/philipp/facerec/data/at/s17/3.pgm;16
/home/philipp/facerec/data/at/s17/4.pgm;16
/home/philipp/facerec/data/at/s17/10.pgm;16
/home/philipp/facerec/data/at/s17/8.pgm;16
/home/philipp/facerec/data/at/s17/1.pgm;16
/home/philipp/facerec/data/at/s32/2.pgm;31
/home/philipp/facerec/data/at/s32/7.pgm;31
/home/philipp/facerec/data/at/s32/6.pgm;31
/home/philipp/facerec/data/at/s32/9.pgm;31
/home/philipp/facerec/data/at/s32/5.pgm;31
/home/philipp/facerec/data/at/s32/3.pgm;31
/home/philipp/facerec/data/at/s32/4.pgm;31
/home/philipp/facerec/data/at/s32/10.pgm;31
/home/philipp/facerec/data/at/s32/8.pgm;31
/home/philipp/facerec/data/at/s32/1.pgm;31
/home/philipp/facerec/data/at/s10/2.pgm;9
/home/philipp/facerec/data/at/s10/7.pgm;9
/home/philipp/facerec/data/at/s10/6.pgm;9
/home/philipp/facerec/data/at/s10/9.pgm;9
/home/philipp/facerec/data/at/s10/5.pgm;9
/home/philipp/facerec/data/at/s10/3.pgm;9
/home/philipp/facerec/data/at/s10/4.pgm;9
/home/philipp/facerec/data/at/s10/10.pgm;9
/home/philipp/facerec/data/at/s10/8.pgm;9
/home/philipp/facerec/data/at/s10/1.pgm;9
/home/philipp/facerec/data/at/s27/2.pgm;26
/home/philipp/facerec/data/at/s27/7.pgm;26
/home/philipp/facerec/data/at/s27/6.pgm;26
/home/philipp/facerec/data/at/s27/9.pgm;26
/home/philipp/facerec/data/at/s27/5.pgm;26
/home/philipp/facerec/data/at/s27/3.pgm;26
/home/philipp/facerec/data/at/s27/4.pgm;26
/home/philipp/facerec/data/at/s27/10.pgm;26
/home/philipp/facerec/data/at/s27/8.pgm;26
/home/philipp/facerec/data/at/s27/1.pgm;26
/home/philipp/facerec/data/at/s5/2.pgm;4
/home/philipp/facerec/data/at/s5/7.pgm;4
/home/philipp/facerec/data/at/s5/6.pgm;4
/home/philipp/facerec/data/at/s5/9.pgm;4
/home/philipp/facerec/data/at/s5/5.pgm;4
/home/philipp/facerec/data/at/s5/3.pgm;4
/home/philipp/facerec/data/at/s5/4.pgm;4
/home/philipp/facerec/data/at/s5/10.pgm;4
/home/philipp/facerec/data/at/s5/8.pgm;4
/home/philipp/facerec/data/at/s5/1.pgm;4
/home/philipp/facerec/data/at/s20/2.pgm;19
/home/philipp/facerec/data/at/s20/7.pgm;19
/home/philipp/facerec/data/at/s20/6.pgm;19
/home/philipp/facerec/data/at/s20/9.pgm;19
/home/philipp/facerec/data/at/s20/5.pgm;19
/home/philipp/facerec/data/at/s20/3.pgm;19
/home/philipp/facerec/data/at/s20/4.pgm;19
/home/philipp/facerec/data/at/s20/10.pgm;19
/home/philipp/facerec/data/at/s20/8.pgm;19
/home/philipp/facerec/data/at/s20/1.pgm;19
/home/philipp/facerec/data/at/s30/2.pgm;29
/home/philipp/facerec/data/at/s30/7.pgm;29
/home/philipp/facerec/data/at/s30/6.pgm;29
/home/philipp/facerec/data/at/s30/9.pgm;29
/home/philipp/facerec/data/at/s30/5.pgm;29
/home/philipp/facerec/data/at/s30/3.pgm;29
/home/philipp/facerec/data/at/s30/4.pgm;29
/home/philipp/facerec/data/at/s30/10.pgm;29
/home/philipp/facerec/data/at/s30/8.pgm;29
/home/philipp/facerec/data/at/s30/1.pgm;29
/home/philipp/facerec/data/at/s39/2.pgm;38
/home/philipp/facerec/data/at/s39/7.pgm;38
/home/philipp/facerec/data/at/s39/6.pgm;38
/home/philipp/facerec/data/at/s39/9.pgm;38
/home/philipp/facerec/data/at/s39/5.pgm;38
/home/philipp/facerec/data/at/s39/3.pgm;38
/home/philipp/facerec/data/at/s39/4.pgm;38
/home/philipp/facerec/data/at/s39/10.pgm;38
/home/philipp/facerec/data/at/s39/8.pgm;38
/home/philipp/facerec/data/at/s39/1.pgm;38
/home/philipp/facerec/data/at/s35/2.pgm;34
/home/philipp/facerec/data/at/s35/7.pgm;34
/home/philipp/facerec/data/at/s35/6.pgm;34
/home/philipp/facerec/data/at/s35/9.pgm;34
/home/philipp/facerec/data/at/s35/5.pgm;34
/home/philipp/facerec/data/at/s35/3.pgm;34
/home/philipp/facerec/data/at/s35/4.pgm;34
/home/philipp/facerec/data/at/s35/10.pgm;34
/home/philipp/facerec/data/at/s35/8.pgm;34
/home/philipp/facerec/data/at/s35/1.pgm;34
/home/philipp/facerec/data/at/s23/2.pgm;22
/home/philipp/facerec/data/at/s23/7.pgm;22
/home/philipp/facerec/data/at/s23/6.pgm;22
/home/philipp/facerec/data/at/s23/9.pgm;22
/home/philipp/facerec/data/at/s23/5.pgm;22
/home/philipp/facerec/data/at/s23/3.pgm;22
/home/philipp/facerec/data/at/s23/4.pgm;22
/home/philipp/facerec/data/at/s23/10.pgm;22
/home/philipp/facerec/data/at/s23/8.pgm;22
/home/philipp/facerec/data/at/s23/1.pgm;22
/home/philipp/facerec/data/at/s4/2.pgm;3
/home/philipp/facerec/data/at/s4/7.pgm;3
/home/philipp/facerec/data/at/s4/6.pgm;3
/home/philipp/facerec/data/at/s4/9.pgm;3
/home/philipp/facerec/data/at/s4/5.pgm;3
/home/philipp/facerec/data/at/s4/3.pgm;3
/home/philipp/facerec/data/at/s4/4.pgm;3
/home/philipp/facerec/data/at/s4/10.pgm;3
/home/philipp/facerec/data/at/s4/8.pgm;3
/home/philipp/facerec/data/at/s4/1.pgm;3
/home/philipp/facerec/data/at/s9/2.pgm;8
/home/philipp/facerec/data/at/s9/7.pgm;8
/home/philipp/facerec/data/at/s9/6.pgm;8
/home/philipp/facerec/data/at/s9/9.pgm;8
/home/philipp/facerec/data/at/s9/5.pgm;8
/home/philipp/facerec/data/at/s9/3.pgm;8
/home/philipp/facerec/data/at/s9/4.pgm;8
/home/philipp/facerec/data/at/s9/10.pgm;8
/home/philipp/facerec/data/at/s9/8.pgm;8
/home/philipp/facerec/data/at/s9/1.pgm;8
/home/philipp/facerec/data/at/s37/2.pgm;36
/home/philipp/facerec/data/at/s37/7.pgm;36
/home/philipp/facerec/data/at/s37/6.pgm;36
/home/philipp/facerec/data/at/s37/9.pgm;36
/home/philipp/facerec/data/at/s37/5.pgm;36
/home/philipp/facerec/data/at/s37/3.pgm;36
/home/philipp/facerec/data/at/s37/4.pgm;36
/home/philipp/facerec/data/at/s37/10.pgm;36
/home/philipp/facerec/data/at/s37/8.pgm;36
/home/philipp/facerec/data/at/s37/1.pgm;36
/home/philipp/facerec/data/at/s24/2.pgm;23
/home/philipp/facerec/data/at/s24/7.pgm;23
/home/philipp/facerec/data/at/s24/6.pgm;23
/home/philipp/facerec/data/at/s24/9.pgm;23
/home/philipp/facerec/data/at/s24/5.pgm;23
/home/philipp/facerec/data/at/s24/3.pgm;23
/home/philipp/facerec/data/at/s24/4.pgm;23
/home/philipp/facerec/data/at/s24/10.pgm;23
/home/philipp/facerec/data/at/s24/8.pgm;23
/home/philipp/facerec/data/at/s24/1.pgm;23
/home/philipp/facerec/data/at/s19/2.pgm;18
/home/philipp/facerec/data/at/s19/7.pgm;18
/home/philipp/facerec/data/at/s19/6.pgm;18
/home/philipp/facerec/data/at/s19/9.pgm;18
/home/philipp/facerec/data/at/s19/5.pgm;18
/home/philipp/facerec/data/at/s19/3.pgm;18
/home/philipp/facerec/data/at/s19/4.pgm;18
/home/philipp/facerec/data/at/s19/10.pgm;18
/home/philipp/facerec/data/at/s19/8.pgm;18
/home/philipp/facerec/data/at/s19/1.pgm;18
/home/philipp/facerec/data/at/s8/2.pgm;7
/home/philipp/facerec/data/at/s8/7.pgm;7
/home/philipp/facerec/data/at/s8/6.pgm;7
/home/philipp/facerec/data/at/s8/9.pgm;7
/home/philipp/facerec/data/at/s8/5.pgm;7
/home/philipp/facerec/data/at/s8/3.pgm;7
/home/philipp/facerec/data/at/s8/4.pgm;7
/home/philipp/facerec/data/at/s8/10.pgm;7
/home/philipp/facerec/data/at/s8/8.pgm;7
/home/philipp/facerec/data/at/s8/1.pgm;7
/home/philipp/facerec/data/at/s21/2.pgm;20
/home/philipp/facerec/data/at/s21/7.pgm;20
/home/philipp/facerec/data/at/s21/6.pgm;20
/home/philipp/facerec/data/at/s21/9.pgm;20
/home/philipp/facerec/data/at/s21/5.pgm;20
/home/philipp/facerec/data/at/s21/3.pgm;20
/home/philipp/facerec/data/at/s21/4.pgm;20
/home/philipp/facerec/data/at/s21/10.pgm;20
/home/philipp/facerec/data/at/s21/8.pgm;20
/home/philipp/facerec/data/at/s21/1.pgm;20
/home/philipp/facerec/data/at/s1/2.pgm;0
/home/philipp/facerec/data/at/s1/7.pgm;0
/home/philipp/facerec/data/at/s1/6.pgm;0
/home/philipp/facerec/data/at/s1/9.pgm;0
/home/philipp/facerec/data/at/s1/5.pgm;0
/home/philipp/facerec/data/at/s1/3.pgm;0
/home/philipp/facerec/data/at/s1/4.pgm;0
/home/philipp/facerec/data/at/s1/10.pgm;0
/home/philipp/facerec/data/at/s1/8.pgm;0
/home/philipp/facerec/data/at/s1/1.pgm;0
/home/philipp/facerec/data/at/s7/2.pgm;6
/home/philipp/facerec/data/at/s7/7.pgm;6
/home/philipp/facerec/data/at/s7/6.pgm;6
/home/philipp/facerec/data/at/s7/9.pgm;6
/home/philipp/facerec/data/at/s7/5.pgm;6
/home/philipp/facerec/data/at/s7/3.pgm;6
/home/philipp/facerec/data/at/s7/4.pgm;6
/home/philipp/facerec/data/at/s7/10.pgm;6
/home/philipp/facerec/data/at/s7/8.pgm;6
/home/philipp/facerec/data/at/s7/1.pgm;6
/home/philipp/facerec/data/at/s16/2.pgm;15
/home/philipp/facerec/data/at/s16/7.pgm;15
/home/philipp/facerec/data/at/s16/6.pgm;15
/home/philipp/facerec/data/at/s16/9.pgm;15
/home/philipp/facerec/data/at/s16/5.pgm;15
/home/philipp/facerec/data/at/s16/3.pgm;15
/home/philipp/facerec/data/at/s16/4.pgm;15
/home/philipp/facerec/data/at/s16/10.pgm;15
/home/philipp/facerec/data/at/s16/8.pgm;15
/home/philipp/facerec/data/at/s16/1.pgm;15
/home/philipp/facerec/data/at/s36/2.pgm;35
/home/philipp/facerec/data/at/s36/7.pgm;35
/home/philipp/facerec/data/at/s36/6.pgm;35
/home/philipp/facerec/data/at/s36/9.pgm;35
/home/philipp/facerec/data/at/s36/5.pgm;35
/home/philipp/facerec/data/at/s36/3.pgm;35
/home/philipp/facerec/data/at/s36/4.pgm;35
/home/philipp/facerec/data/at/s36/10.pgm;35
/home/philipp/facerec/data/at/s36/8.pgm;35
/home/philipp/facerec/data/at/s36/1.pgm;35
/home/philipp/facerec/data/at/s25/2.pgm;24
/home/philipp/facerec/data/at/s25/7.pgm;24
/home/philipp/facerec/data/at/s25/6.pgm;24
/home/philipp/facerec/data/at/s25/9.pgm;24
/home/philipp/facerec/data/at/s25/5.pgm;24
/home/philipp/facerec/data/at/s25/3.pgm;24
/home/philipp/facerec/data/at/s25/4.pgm;24
/home/philipp/facerec/data/at/s25/10.pgm;24
/home/philipp/facerec/data/at/s25/8.pgm;24
/home/philipp/facerec/data/at/s25/1.pgm;24
/home/philipp/facerec/data/at/s14/2.pgm;13
/home/philipp/facerec/data/at/s14/7.pgm;13
/home/philipp/facerec/data/at/s14/6.pgm;13
/home/philipp/facerec/data/at/s14/9.pgm;13
/home/philipp/facerec/data/at/s14/5.pgm;13
/home/philipp/facerec/data/at/s14/3.pgm;13
/home/philipp/facerec/data/at/s14/4.pgm;13
/home/philipp/facerec/data/at/s14/10.pgm;13
/home/philipp/facerec/data/at/s14/8.pgm;13
/home/philipp/facerec/data/at/s14/1.pgm;13
/home/philipp/facerec/data/at/s34/2.pgm;33
/home/philipp/facerec/data/at/s34/7.pgm;33
/home/philipp/facerec/data/at/s34/6.pgm;33
/home/philipp/facerec/data/at/s34/9.pgm;33
/home/philipp/facerec/data/at/s34/5.pgm;33
/home/philipp/facerec/data/at/s34/3.pgm;33
/home/philipp/facerec/data/at/s34/4.pgm;33
/home/philipp/facerec/data/at/s34/10.pgm;33
/home/philipp/facerec/data/at/s34/8.pgm;33
/home/philipp/facerec/data/at/s34/1.pgm;33
/home/philipp/facerec/data/at/s11/2.pgm;10
/home/philipp/facerec/data/at/s11/7.pgm;10
/home/philipp/facerec/data/at/s11/6.pgm;10
/home/philipp/facerec/data/at/s11/9.pgm;10
/home/philipp/facerec/data/at/s11/5.pgm;10
/home/philipp/facerec/data/at/s11/3.pgm;10
/home/philipp/facerec/data/at/s11/4.pgm;10
/home/philipp/facerec/data/at/s11/10.pgm;10
/home/philipp/facerec/data/at/s11/8.pgm;10
/home/philipp/facerec/data/at/s11/1.pgm;10
/home/philipp/facerec/data/at/s26/2.pgm;25
/home/philipp/facerec/data/at/s26/7.pgm;25
/home/philipp/facerec/data/at/s26/6.pgm;25
/home/philipp/facerec/data/at/s26/9.pgm;25
/home/philipp/facerec/data/at/s26/5.pgm;25
/home/philipp/facerec/data/at/s26/3.pgm;25
/home/philipp/facerec/data/at/s26/4.pgm;25
/home/philipp/facerec/data/at/s26/10.pgm;25
/home/philipp/facerec/data/at/s26/8.pgm;25
/home/philipp/facerec/data/at/s26/1.pgm;25
/home/philipp/facerec/data/at/s18/2.pgm;17
/home/philipp/facerec/data/at/s18/7.pgm;17
/home/philipp/facerec/data/at/s18/6.pgm;17
/home/philipp/facerec/data/at/s18/9.pgm;17
/home/philipp/facerec/data/at/s18/5.pgm;17
/home/philipp/facerec/data/at/s18/3.pgm;17
/home/philipp/facerec/data/at/s18/4.pgm;17
/home/philipp/facerec/data/at/s18/10.pgm;17
/home/philipp/facerec/data/at/s18/8.pgm;17
/home/philipp/facerec/data/at/s18/1.pgm;17
/home/philipp/facerec/data/at/s29/2.pgm;28
/home/philipp/facerec/data/at/s29/7.pgm;28
/home/philipp/facerec/data/at/s29/6.pgm;28
/home/philipp/facerec/data/at/s29/9.pgm;28
/home/philipp/facerec/data/at/s29/5.pgm;28
/home/philipp/facerec/data/at/s29/3.pgm;28
/home/philipp/facerec/data/at/s29/4.pgm;28
/home/philipp/facerec/data/at/s29/10.pgm;28
/home/philipp/facerec/data/at/s29/8.pgm;28
/home/philipp/facerec/data/at/s29/1.pgm;28
/home/philipp/facerec/data/at/s33/2.pgm;32
/home/philipp/facerec/data/at/s33/7.pgm;32
/home/philipp/facerec/data/at/s33/6.pgm;32
/home/philipp/facerec/data/at/s33/9.pgm;32
/home/philipp/facerec/data/at/s33/5.pgm;32
/home/philipp/facerec/data/at/s33/3.pgm;32
/home/philipp/facerec/data/at/s33/4.pgm;32
/home/philipp/facerec/data/at/s33/10.pgm;32
/home/philipp/facerec/data/at/s33/8.pgm;32
/home/philipp/facerec/data/at/s33/1.pgm;32
/home/philipp/facerec/data/at/s12/2.pgm;11
/home/philipp/facerec/data/at/s12/7.pgm;11
/home/philipp/facerec/data/at/s12/6.pgm;11
/home/philipp/facerec/data/at/s12/9.pgm;11
/home/philipp/facerec/data/at/s12/5.pgm;11
/home/philipp/facerec/data/at/s12/3.pgm;11
/home/philipp/facerec/data/at/s12/4.pgm;11
/home/philipp/facerec/data/at/s12/10.pgm;11
/home/philipp/facerec/data/at/s12/8.pgm;11
/home/philipp/facerec/data/at/s12/1.pgm;11
/home/philipp/facerec/data/at/s6/2.pgm;5
/home/philipp/facerec/data/at/s6/7.pgm;5
/home/philipp/facerec/data/at/s6/6.pgm;5
/home/philipp/facerec/data/at/s6/9.pgm;5
/home/philipp/facerec/data/at/s6/5.pgm;5
/home/philipp/facerec/data/at/s6/3.pgm;5
/home/philipp/facerec/data/at/s6/4.pgm;5
/home/philipp/facerec/data/at/s6/10.pgm;5
/home/philipp/facerec/data/at/s6/8.pgm;5
/home/philipp/facerec/data/at/s6/1.pgm;5
/home/philipp/facerec/data/at/s22/2.pgm;21
/home/philipp/facerec/data/at/s22/7.pgm;21
/home/philipp/facerec/data/at/s22/6.pgm;21
/home/philipp/facerec/data/at/s22/9.pgm;21
/home/philipp/facerec/data/at/s22/5.pgm;21
/home/philipp/facerec/data/at/s22/3.pgm;21
/home/philipp/facerec/data/at/s22/4.pgm;21
/home/philipp/facerec/data/at/s22/10.pgm;21
/home/philipp/facerec/data/at/s22/8.pgm;21
/home/philipp/facerec/data/at/s22/1.pgm;21
/home/philipp/facerec/data/at/s15/2.pgm;14
/home/philipp/facerec/data/at/s15/7.pgm;14
/home/philipp/facerec/data/at/s15/6.pgm;14
/home/philipp/facerec/data/at/s15/9.pgm;14
/home/philipp/facerec/data/at/s15/5.pgm;14
/home/philipp/facerec/data/at/s15/3.pgm;14
/home/philipp/facerec/data/at/s15/4.pgm;14
/home/philipp/facerec/data/at/s15/10.pgm;14
/home/philipp/facerec/data/at/s15/8.pgm;14
/home/philipp/facerec/data/at/s15/1.pgm;14
/home/philipp/facerec/data/at/s2/2.pgm;1
/home/philipp/facerec/data/at/s2/7.pgm;1
/home/philipp/facerec/data/at/s2/6.pgm;1
/home/philipp/facerec/data/at/s2/9.pgm;1
/home/philipp/facerec/data/at/s2/5.pgm;1
/home/philipp/facerec/data/at/s2/3.pgm;1
/home/philipp/facerec/data/at/s2/4.pgm;1
/home/philipp/facerec/data/at/s2/10.pgm;1
/home/philipp/facerec/data/at/s2/8.pgm;1
/home/philipp/facerec/data/at/s2/1.pgm;1
/home/philipp/facerec/data/at/s31/2.pgm;30
/home/philipp/facerec/data/at/s31/7.pgm;30
/home/philipp/facerec/data/at/s31/6.pgm;30
/home/philipp/facerec/data/at/s31/9.pgm;30
/home/philipp/facerec/data/at/s31/5.pgm;30
/home/philipp/facerec/data/at/s31/3.pgm;30
/home/philipp/facerec/data/at/s31/4.pgm;30
/home/philipp/facerec/data/at/s31/10.pgm;30
/home/philipp/facerec/data/at/s31/8.pgm;30
/home/philipp/facerec/data/at/s31/1.pgm;30
/home/philipp/facerec/data/at/s28/2.pgm;27
/home/philipp/facerec/data/at/s28/7.pgm;27
/home/philipp/facerec/data/at/s28/6.pgm;27
/home/philipp/facerec/data/at/s28/9.pgm;27
/home/philipp/facerec/data/at/s28/5.pgm;27
/home/philipp/facerec/data/at/s28/3.pgm;27
/home/philipp/facerec/data/at/s28/4.pgm;27
/home/philipp/facerec/data/at/s28/10.pgm;27
/home/philipp/facerec/data/at/s28/8.pgm;27
/home/philipp/facerec/data/at/s28/1.pgm;27
/home/philipp/facerec/data/at/s40/2.pgm;39
/home/philipp/facerec/data/at/s40/7.pgm;39
/home/philipp/facerec/data/at/s40/6.pgm;39
/home/philipp/facerec/data/at/s40/9.pgm;39
/home/philipp/facerec/data/at/s40/5.pgm;39
/home/philipp/facerec/data/at/s40/3.pgm;39
/home/philipp/facerec/data/at/s40/4.pgm;39
/home/philipp/facerec/data/at/s40/10.pgm;39
/home/philipp/facerec/data/at/s40/8.pgm;39
/home/philipp/facerec/data/at/s40/1.pgm;39
/home/philipp/facerec/data/at/s3/2.pgm;2
/home/philipp/facerec/data/at/s3/7.pgm;2
/home/philipp/facerec/data/at/s3/6.pgm;2
/home/philipp/facerec/data/at/s3/9.pgm;2
/home/philipp/facerec/data/at/s3/5.pgm;2
/home/philipp/facerec/data/at/s3/3.pgm;2
/home/philipp/facerec/data/at/s3/4.pgm;2
/home/philipp/facerec/data/at/s3/10.pgm;2
/home/philipp/facerec/data/at/s3/8.pgm;2
/home/philipp/facerec/data/at/s3/1.pgm;2
/home/philipp/facerec/data/at/s38/2.pgm;37
/home/philipp/facerec/data/at/s38/7.pgm;37
/home/philipp/facerec/data/at/s38/6.pgm;37
/home/philipp/facerec/data/at/s38/9.pgm;37
/home/philipp/facerec/data/at/s38/5.pgm;37
/home/philipp/facerec/data/at/s38/3.pgm;37
/home/philipp/facerec/data/at/s38/4.pgm;37
/home/philipp/facerec/data/at/s38/10.pgm;37
/home/philipp/facerec/data/at/s38/8.pgm;37
/home/philipp/facerec/data/at/s38/1.pgm;37
</pre></div>
</td></tr></table></div>
</div>
</div>
</div>


          </div>
          <div class="feedback">
              <h2>Help and Feedback</h2>
              You did not find what you were looking for?
              <ul>
                  
                  
                  
                  <li>Ask a question on the <a href="http://answers.opencv.org">Q&A forum</a>.</li>
                  <li>If you think something is missing or wrong in the documentation,
                  please file a <a href="http://code.opencv.org">bug report</a>.</li>
              </ul>
          </div>
        </div>
      </div>

      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../../../../index.html">
              <img class="logo" src="../../../../_static/opencv-logo-white.png" alt="Logo"/>
            </a></p>
<div id="searchbox" style="display: none">
      <form class="search" action="../../../../search.html" method="get">
      <input type="text" name="q" size="18" />
      <input type="submit" value="Search" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
      </p>
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
  <h3><a href="../../../../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Face Recognition with OpenCV</a><ul>
<li><a class="reference internal" href="#introduction">Introduction</a></li>
<li><a class="reference internal" href="#face-recognition">Face Recognition</a></li>
<li><a class="reference internal" href="#face-database">Face Database</a><ul>
<li><a class="reference internal" href="#preparing-the-data">Preparing the data</a><ul>
<li><a class="reference internal" href="#creating-the-csv-file">Creating the CSV File</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#eigenfaces">Eigenfaces</a><ul>
<li><a class="reference internal" href="#algorithmic-description">Algorithmic Description</a></li>
<li><a class="reference internal" href="#eigenfaces-in-opencv">Eigenfaces in OpenCV</a></li>
</ul>
</li>
<li><a class="reference internal" href="#fisherfaces">Fisherfaces</a><ul>
<li><a class="reference internal" href="#id16">Algorithmic Description</a></li>
<li><a class="reference internal" href="#fisherfaces-in-opencv">Fisherfaces in OpenCV</a></li>
</ul>
</li>
<li><a class="reference internal" href="#local-binary-patterns-histograms">Local Binary Patterns Histograms</a><ul>
<li><a class="reference internal" href="#id22">Algorithmic Description</a></li>
<li><a class="reference internal" href="#local-binary-patterns-histograms-in-opencv">Local Binary Patterns Histograms in OpenCV</a></li>
</ul>
</li>
<li><a class="reference internal" href="#conclusion">Conclusion</a></li>
<li><a class="reference internal" href="#credits">Credits</a><ul>
<li><a class="reference internal" href="#the-database-of-faces">The Database of Faces</a></li>
<li><a class="reference internal" href="#id25">Yale Facedatabase A</a></li>
<li><a class="reference internal" href="#yale-facedatabase-b">Yale Facedatabase B</a></li>
</ul>
</li>
<li><a class="reference internal" href="#literature">Literature</a></li>
<li><a class="reference internal" href="#appendix">Appendix</a><ul>
<li><a class="reference internal" href="#id26">Creating the CSV File</a></li>
<li><a class="reference internal" href="#aligning-face-images">Aligning Face Images</a></li>
<li><a class="reference internal" href="#csv-for-the-at-t-facedatabase">CSV for the AT&amp;T Facedatabase</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="facerec_api.html"
                        title="previous chapter">FaceRecognizer</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="tutorial/facerec_gender_classification.html"
                        title="next chapter">Gender Classification with OpenCV</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../../../../_sources/modules/contrib/doc/facerec/facerec_tutorial.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="tutorial/facerec_gender_classification.html" title="Gender Classification with OpenCV"
             >next</a> |</li>
        <li class="right" >
          <a href="facerec_api.html" title="FaceRecognizer"
             >previous</a> |</li>
        <li><a href="../../../../index.html">OpenCV 2.4.13.7 documentation</a> &raquo;</li>
          <li><a href="../../../refman.html" >OpenCV API Reference</a> &raquo;</li>
          <li><a href="../contrib.html" >contrib. Contributed/Experimental Stuff</a> &raquo;</li>
          <li><a href="index.html" >FaceRecognizer - Face Recognition with OpenCV</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2011-2014, opencv dev team.
      Last updated on Jul 12, 2018.
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.3.6.
    </div>
  </body>
</html>