<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-33108845-1']);
  _gaq.push(['_setDomainName', 'opencv.org']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Feature Detection and Description &mdash; OpenCV 2.4.13.7 documentation</title>
    <link rel="stylesheet" href="../../../_static/default.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../../',
        VERSION:     '2.4.13.7',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../_static/doctools.js"></script>
    <link rel="top" title="OpenCV 2.4.13.7 documentation" href="../../../index.html" />
    <link rel="up" title="nonfree. Non-free functionality" href="nonfree.html" />
    <link rel="next" title="contrib. Contributed/Experimental Stuff" href="../../contrib/doc/contrib.html" />
    <link rel="prev" title="nonfree. Non-free functionality" href="nonfree.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../contrib/doc/contrib.html" title="contrib. Contributed/Experimental Stuff"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="nonfree.html" title="nonfree. Non-free functionality"
             accesskey="P">previous</a> |</li>
        <li><a href="../../../index.html">OpenCV 2.4.13.7 documentation</a> &raquo;</li>
          <li><a href="../../refman.html" >OpenCV API Reference</a> &raquo;</li>
          <li><a href="nonfree.html" accesskey="U">nonfree. Non-free functionality</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
  
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="feature-detection-and-description">
<h1>Feature Detection and Description<a class="headerlink" href="#feature-detection-and-description" title="Permalink to this headline">¶</a></h1>
<div class="section" id="sift">
<h2>SIFT<a class="headerlink" href="#sift" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="SIFT : public Feature2D">
<em class="property">class </em><code class="descname">SIFT</code> : <em class="property">public</em> <code class="descname">Feature2D</code><a class="headerlink" href="#SIFT : public Feature2D" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<p>Class for extracting keypoints and computing descriptors using the Scale Invariant Feature Transform (SIFT) algorithm by D. Lowe <a class="reference internal" href="#lowe04" id="id1">[Lowe04]</a>.</p>
<table class="docutils citation" frame="void" id="lowe04" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[Lowe04]</a></td><td>Lowe, D. G., “Distinctive Image Features from Scale-Invariant Keypoints”, International Journal of Computer Vision, 60, 2, pp. 91-110, 2004.</td></tr>
</tbody>
</table>
</div>
<div class="section" id="sift-sift">
<h2>SIFT::SIFT<a class="headerlink" href="#sift-sift" title="Permalink to this headline">¶</a></h2>
<p>The SIFT constructors.</p>
<dl class="function">
<dt id="SIFT::SIFT(int nfeatures, int nOctaveLayers, double contrastThreshold, double edgeThreshold, double sigma)">
<strong>C++:</strong><code class="descname"> </code> <code class="descclassname">SIFT::</code><code class="descname">SIFT</code><span class="sig-paren">(</span>int <strong>nfeatures</strong>=0, int <strong>nOctaveLayers</strong>=3, double <strong>contrastThreshold</strong>=0.04, double <strong>edgeThreshold</strong>=10, double <strong>sigma</strong>=1.6<span class="sig-paren">)</span><a class="headerlink" href="#SIFT::SIFT(int nfeatures, int nOctaveLayers, double contrastThreshold, double edgeThreshold, double sigma)" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>nfeatures</strong> &#8211; The number of best features to retain. The features are ranked by their scores (measured in SIFT algorithm as the local contrast)</li>
<li><strong>nOctaveLayers</strong> &#8211; The number of layers in each octave. 3 is the value used in D. Lowe paper. The number of octaves is computed automatically from the image resolution.</li>
<li><strong>contrastThreshold</strong> &#8211; The contrast threshold used to filter out weak features in semi-uniform (low-contrast) regions. The larger the threshold, the less features are produced by the detector.</li>
<li><strong>edgeThreshold</strong> &#8211; The threshold used to filter out edge-like features. Note that the its meaning is different from the contrastThreshold, i.e. the larger the <code class="docutils literal"><span class="pre">edgeThreshold</span></code>, the less features are filtered out (more features are retained).</li>
<li><strong>sigma</strong> &#8211; The sigma of the Gaussian applied to the input image at the octave #0. If your image is captured with a weak camera with soft lenses, you might want to reduce the number.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="sift-operator">
<h2>SIFT::operator ()<a class="headerlink" href="#sift-operator" title="Permalink to this headline">¶</a></h2>
<p>Extract features and computes their descriptors using SIFT algorithm</p>
<dl class="function">
<dt id="void SIFT::operator()(InputArray img, InputArray mask, vector&lt;KeyPoint&gt;&amp; keypoints, OutputArray descriptors, bool useProvidedKeypoints)">
<strong>C++:</strong><code class="descname"> </code>void <code class="descclassname">SIFT::</code><code class="descname">operator()</code><span class="sig-paren">(</span>InputArray <strong>img</strong>, InputArray <strong>mask</strong>, vector&lt;KeyPoint&gt;&amp; <strong>keypoints</strong>, OutputArray <strong>descriptors</strong>, bool <strong>useProvidedKeypoints</strong>=false<span class="sig-paren">)</span><a class="headerlink" href="#void SIFT::operator()(InputArray img, InputArray mask, vector<KeyPoint>& keypoints, OutputArray descriptors, bool useProvidedKeypoints)" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>img</strong> &#8211; Input 8-bit grayscale image</li>
<li><strong>mask</strong> &#8211; Optional input mask that marks the regions where we should detect features.</li>
<li><strong>keypoints</strong> &#8211; The input/output vector of keypoints</li>
<li><strong>descriptors</strong> &#8211; The output matrix of descriptors. Pass <code class="docutils literal"><span class="pre">cv::noArray()</span></code> if you do not need them.</li>
<li><strong>useProvidedKeypoints</strong> &#8211; Boolean flag. If it is true, the keypoint detector is not run. Instead, the provided vector of keypoints is used and the algorithm just computes their descriptors.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="surf">
<h2>SURF<a class="headerlink" href="#surf" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="SURF : public Feature2D">
<em class="property">class </em><code class="descname">SURF</code> : <em class="property">public</em> <code class="descname">Feature2D</code><a class="headerlink" href="#SURF : public Feature2D" title="Permalink to this definition">¶</a></dt>
<dd><p>Class for extracting Speeded Up Robust Features from an image <a class="reference internal" href="#bay06" id="id2">[Bay06]</a>. The class is derived from <code class="docutils literal"><span class="pre">CvSURFParams</span></code> structure, which specifies the algorithm parameters:</p>
<dl class="member">
<dt id="int extended">
int <code class="descname">extended</code><a class="headerlink" href="#int extended" title="Permalink to this definition">¶</a></dt>
<dd><ul class="simple">
<li>0 means that the basic descriptors (64 elements each) shall be computed</li>
<li>1 means that the extended descriptors (128 elements each) shall be computed</li>
</ul>
</dd></dl>

<dl class="member">
<dt id="int upright">
int <code class="descname">upright</code><a class="headerlink" href="#int upright" title="Permalink to this definition">¶</a></dt>
<dd><ul class="simple">
<li>0 means that detector computes orientation of each feature.</li>
<li>1 means that the orientation is not computed (which is much, much faster). For example, if you match images from a stereo pair, or do image stitching, the matched features likely have very similar angles, and you can speed up feature extraction by setting <code class="docutils literal"><span class="pre">upright=1</span></code>.</li>
</ul>
</dd></dl>

<dl class="member">
<dt id="double hessianThreshold">
double <code class="descname">hessianThreshold</code><a class="headerlink" href="#double hessianThreshold" title="Permalink to this definition">¶</a></dt>
<dd><p>Threshold for the keypoint detector. Only features, whose hessian is larger than <code class="docutils literal"><span class="pre">hessianThreshold</span></code> are retained by the detector. Therefore, the larger the value, the less keypoints you will get. A good default value could be from 300 to 500, depending from the image contrast.</p>
</dd></dl>

<dl class="member">
<dt id="int nOctaves">
int <code class="descname">nOctaves</code><a class="headerlink" href="#int nOctaves" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of a gaussian pyramid octaves that the detector uses. It is set to 4 by default. If you want to get very large features, use the larger value. If you want just small features, decrease it.</p>
</dd></dl>

<dl class="member">
<dt id="int nOctaveLayers">
int <code class="descname">nOctaveLayers</code><a class="headerlink" href="#int nOctaveLayers" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of images within each octave of a gaussian pyramid. It is set to 2 by default.</p>
</dd></dl>

</dd></dl>

<table class="docutils citation" frame="void" id="bay06" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id2">[Bay06]</a></td><td>Bay, H. and Tuytelaars, T. and Van Gool, L. &#8220;SURF: Speeded Up Robust Features&#8221;, 9th European Conference on Computer Vision, 2006</td></tr>
</tbody>
</table>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<ul class="last simple">
<li>An example using the SURF feature detector can be found at opencv_source_code/samples/cpp/generic_descriptor_match.cpp</li>
<li>Another example using the SURF feature detector, extractor and matcher can be found at opencv_source_code/samples/cpp/matcher_simple.cpp</li>
</ul>
</div>
</div>
<div class="section" id="surf-surf">
<h2>SURF::SURF<a class="headerlink" href="#surf-surf" title="Permalink to this headline">¶</a></h2>
<p>The SURF extractor constructors.</p>
<dl class="function">
<dt id="SURF::SURF()">
<strong>C++:</strong><code class="descname"> </code> <code class="descclassname">SURF::</code><code class="descname">SURF</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#SURF::SURF()" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="SURF::SURF(double hessianThreshold, int nOctaves, int nOctaveLayers, bool extended, bool upright)">
<strong>C++:</strong><code class="descname"> </code> <code class="descclassname">SURF::</code><code class="descname">SURF</code><span class="sig-paren">(</span>double <strong>hessianThreshold</strong>, int <strong>nOctaves</strong>=4, int <strong>nOctaveLayers</strong>=2, bool <strong>extended</strong>=true, bool <strong>upright</strong>=false <span class="sig-paren">)</span><a class="headerlink" href="#SURF::SURF(double hessianThreshold, int nOctaves, int nOctaveLayers, bool extended, bool upright)" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="pyfunction">
<dt id="cv2.SURF">
<strong>Python:</strong><code class="descname"> </code><code class="descclassname">cv2.</code><code class="descname">SURF</code><span class="sig-paren">(</span><span class="optional">[</span>hessianThreshold<span class="optional">[</span>, nOctaves<span class="optional">[</span>, nOctaveLayers<span class="optional">[</span>, extended<span class="optional">[</span>, upright<span class="optional">]</span><span class="optional">]</span><span class="optional">]</span><span class="optional">]</span><span class="optional">]</span><span class="sig-paren">)</span> &rarr; &lt;SURF object&gt;<a class="headerlink" href="#cv2.SURF" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>hessianThreshold</strong> &#8211; Threshold for hessian keypoint detector used in SURF.</li>
<li><strong>nOctaves</strong> &#8211; Number of pyramid octaves the keypoint detector will use.</li>
<li><strong>nOctaveLayers</strong> &#8211; Number of octave layers within each octave.</li>
<li><strong>extended</strong> &#8211; Extended descriptor flag (true - use extended 128-element descriptors; false - use 64-element descriptors).</li>
<li><strong>upright</strong> &#8211; Up-right or rotated features flag (true - do not compute orientation of features; false - compute orientation).</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="surf-operator">
<h2>SURF::operator()<a class="headerlink" href="#surf-operator" title="Permalink to this headline">¶</a></h2>
<p>Detects keypoints and computes SURF descriptors for them.</p>
<dl class="function">
<dt id="void SURF::operator()(InputArray img, InputArray mask, vector&lt;KeyPoint&gt;&amp; keypoints) const">
<strong>C++:</strong><code class="descname"> </code>void <code class="descclassname">SURF::</code><code class="descname">operator()</code><span class="sig-paren">(</span>InputArray <strong>img</strong>, InputArray <strong>mask</strong>, vector&lt;KeyPoint&gt;&amp; <strong>keypoints</strong><span class="sig-paren">)</span><code class="descclassname"> const</code><a class="headerlink" href="#void SURF::operator()(InputArray img, InputArray mask, vector<KeyPoint>& keypoints) const" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="void SURF::operator()(InputArray img, InputArray mask, vector&lt;KeyPoint&gt;&amp; keypoints, OutputArray descriptors, bool useProvidedKeypoints)">
<strong>C++:</strong><code class="descname"> </code>void <code class="descclassname">SURF::</code><code class="descname">operator()</code><span class="sig-paren">(</span>InputArray <strong>img</strong>, InputArray <strong>mask</strong>, vector&lt;KeyPoint&gt;&amp; <strong>keypoints</strong>, OutputArray <strong>descriptors</strong>, bool <strong>useProvidedKeypoints</strong>=false<span class="sig-paren">)</span><a class="headerlink" href="#void SURF::operator()(InputArray img, InputArray mask, vector<KeyPoint>& keypoints, OutputArray descriptors, bool useProvidedKeypoints)" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="pyfunction">
<dt id="cv2.SURF.detect">
<strong>Python:</strong><code class="descname"> </code><code class="descclassname">cv2.SURF.</code><code class="descname">detect</code><span class="sig-paren">(</span>image<span class="optional">[</span>, mask<span class="optional">]</span><span class="sig-paren">)</span> &rarr; keypoints<a class="headerlink" href="#cv2.SURF.detect" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="pyfunction">
<dt id="cv2.SURF.detectAndCompute">
<strong>Python:</strong><code class="descname"> </code><code class="descclassname">cv2.SURF.</code><code class="descname">detectAndCompute</code><span class="sig-paren">(</span>image, mask<span class="optional">[</span>, descriptors<span class="optional">[</span>, useProvidedKeypoints<span class="optional">]</span><span class="optional">]</span><span class="sig-paren">)</span> &rarr; keypoints, descriptors<a class="headerlink" href="#cv2.SURF.detectAndCompute" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="cfunction">
<dt id="void cvExtractSURF(const CvArr* image, const CvArr* mask, CvSeq** keypoints, CvSeq** descriptors, CvMemStorage* storage, CvSURFParams params)">
<strong>C:</strong><code class="descname"> </code>void <code class="descname">cvExtractSURF</code><span class="sig-paren">(</span>const CvArr* <strong>image</strong>, const CvArr* <strong>mask</strong>, CvSeq** <strong>keypoints</strong>, CvSeq** <strong>descriptors</strong>, CvMemStorage* <strong>storage</strong>, CvSURFParams <strong>params</strong><span class="sig-paren">)</span><a class="headerlink" href="#void cvExtractSURF(const CvArr* image, const CvArr* mask, CvSeq** keypoints, CvSeq** descriptors, CvMemStorage* storage, CvSURFParams params)" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="pyoldfunction">
<dt id="cv.ExtractSURF">
<strong>Python:</strong><code class="descname"> </code><code class="descclassname">cv.</code><code class="descname">ExtractSURF</code><span class="sig-paren">(</span>image, mask, storage, params)-&gt; (keypoints, descriptors<span class="sig-paren">)</span><a class="headerlink" href="#cv.ExtractSURF" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>image</strong> &#8211; Input 8-bit grayscale image</li>
<li><strong>mask</strong> &#8211; Optional input mask that marks the regions where we should detect features.</li>
<li><strong>keypoints</strong> &#8211; The input/output vector of keypoints</li>
<li><strong>descriptors</strong> &#8211; The output matrix of descriptors. Pass <code class="docutils literal"><span class="pre">cv::noArray()</span></code> if you do not need them.</li>
<li><strong>useProvidedKeypoints</strong> &#8211; Boolean flag. If it is true, the keypoint detector is not run. Instead, the provided vector of keypoints is used and the algorithm just computes their descriptors.</li>
<li><strong>storage</strong> &#8211; Memory storage for the output keypoints and descriptors in OpenCV 1.x API.</li>
<li><strong>params</strong> &#8211; SURF algorithm parameters in OpenCV 1.x API.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<p>The function is parallelized with the TBB library.</p>
<p>If you are using the C version, make sure you call <code class="docutils literal"><span class="pre">cv::initModule_nonfree()</span></code> from <code class="docutils literal"><span class="pre">nonfree/nonfree.hpp</span></code>.</p>
</div>
<div class="section" id="gpu-surf-gpu">
<h2>gpu::SURF_GPU<a class="headerlink" href="#gpu-surf-gpu" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="gpu::SURF_GPU">
<em class="property">class </em><code class="descclassname">gpu::</code><code class="descname">SURF_GPU</code><a class="headerlink" href="#gpu::SURF_GPU" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<p>Class used for extracting Speeded Up Robust Features (SURF) from an image.</p>
<div class="highlight-python"><div class="highlight"><pre>class SURF_GPU
{
public:
    enum KeypointLayout
    {
        X_ROW = 0,
        Y_ROW,
        LAPLACIAN_ROW,
        OCTAVE_ROW,
        SIZE_ROW,
        ANGLE_ROW,
        HESSIAN_ROW,
        ROWS_COUNT
    };

    //! the default constructor
    SURF_GPU();
    //! the full constructor taking all the necessary parameters
    explicit SURF_GPU(double _hessianThreshold, int _nOctaves=4,
         int _nOctaveLayers=2, bool _extended=false, float _keypointsRatio=0.01f);

    //! returns the descriptor size in float&#39;s (64 or 128)
    int descriptorSize() const;

    //! upload host keypoints to device memory
    void uploadKeypoints(const vector&lt;KeyPoint&gt;&amp; keypoints,
        GpuMat&amp; keypointsGPU);
    //! download keypoints from device to host memory
    void downloadKeypoints(const GpuMat&amp; keypointsGPU,
        vector&lt;KeyPoint&gt;&amp; keypoints);

    //! download descriptors from device to host memory
    void downloadDescriptors(const GpuMat&amp; descriptorsGPU,
        vector&lt;float&gt;&amp; descriptors);

    void operator()(const GpuMat&amp; img, const GpuMat&amp; mask,
        GpuMat&amp; keypoints);

    void operator()(const GpuMat&amp; img, const GpuMat&amp; mask,
        GpuMat&amp; keypoints, GpuMat&amp; descriptors,
        bool useProvidedKeypoints = false,
        bool calcOrientation = true);

    void operator()(const GpuMat&amp; img, const GpuMat&amp; mask,
        std::vector&lt;KeyPoint&gt;&amp; keypoints);

    void operator()(const GpuMat&amp; img, const GpuMat&amp; mask,
        std::vector&lt;KeyPoint&gt;&amp; keypoints, GpuMat&amp; descriptors,
        bool useProvidedKeypoints = false,
        bool calcOrientation = true);

    void operator()(const GpuMat&amp; img, const GpuMat&amp; mask,
        std::vector&lt;KeyPoint&gt;&amp; keypoints,
        std::vector&lt;float&gt;&amp; descriptors,
        bool useProvidedKeypoints = false,
        bool calcOrientation = true);

    void releaseMemory();

    // SURF parameters
    double hessianThreshold;
    int nOctaves;
    int nOctaveLayers;
    bool extended;
    bool upright;

    //! max keypoints = keypointsRatio * img.size().area()
    float keypointsRatio;

    GpuMat sum, mask1, maskSum, intBuffer;

    GpuMat det, trace;

    GpuMat maxPosBuffer;
};
</pre></div>
</div>
<p>The class <code class="docutils literal"><span class="pre">SURF_GPU</span></code> implements Speeded Up Robust Features descriptor. There is a fast multi-scale Hessian keypoint detector that can be used to find the keypoints (which is the default option). But the descriptors can also be computed for the user-specified keypoints. Only 8-bit grayscale images are supported.</p>
<p>The class <code class="docutils literal"><span class="pre">SURF_GPU</span></code> can store results in the GPU and CPU memory. It provides functions to convert results between CPU and GPU version ( <code class="docutils literal"><span class="pre">uploadKeypoints</span></code>, <code class="docutils literal"><span class="pre">downloadKeypoints</span></code>, <code class="docutils literal"><span class="pre">downloadDescriptors</span></code> ). The format of CPU results is the same as <code class="docutils literal"><span class="pre">SURF</span></code> results. GPU results are stored in <code class="docutils literal"><span class="pre">GpuMat</span></code>. The <code class="docutils literal"><span class="pre">keypoints</span></code> matrix is <img class="math" src="../../../_images/math/8751b70edb8d3b203d842bc56667a5526dcdfab1.png" alt="\texttt{nFeatures} \times 7"/> matrix with the <code class="docutils literal"><span class="pre">CV_32FC1</span></code> type.</p>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">keypoints.ptr&lt;float&gt;(X_ROW)[i]</span></code> contains x coordinate of the i-th feature.</li>
<li><code class="docutils literal"><span class="pre">keypoints.ptr&lt;float&gt;(Y_ROW)[i]</span></code> contains y coordinate of the i-th feature.</li>
<li><code class="docutils literal"><span class="pre">keypoints.ptr&lt;float&gt;(LAPLACIAN_ROW)[i]</span></code>  contains the laplacian sign of the i-th feature.</li>
<li><code class="docutils literal"><span class="pre">keypoints.ptr&lt;float&gt;(OCTAVE_ROW)[i]</span></code> contains the octave of the i-th feature.</li>
<li><code class="docutils literal"><span class="pre">keypoints.ptr&lt;float&gt;(SIZE_ROW)[i]</span></code> contains the size of the i-th feature.</li>
<li><code class="docutils literal"><span class="pre">keypoints.ptr&lt;float&gt;(ANGLE_ROW)[i]</span></code> contain orientation of the i-th feature.</li>
<li><code class="docutils literal"><span class="pre">keypoints.ptr&lt;float&gt;(HESSIAN_ROW)[i]</span></code> contains the response of the i-th feature.</li>
</ul>
<p>The <code class="docutils literal"><span class="pre">descriptors</span></code> matrix is <img class="math" src="../../../_images/math/93325a9a1014934ae52792d8ccc1347b3f79828a.png" alt="\texttt{nFeatures} \times \texttt{descriptorSize}"/> matrix with the <code class="docutils literal"><span class="pre">CV_32FC1</span></code> type.</p>
<p>The class <code class="docutils literal"><span class="pre">SURF_GPU</span></code> uses some buffers and provides access to it. All buffers can be safely released between function calls.</p>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<p class="last"><a class="reference internal" href="#SURF : public Feature2D" title="class SURF : public Feature2D"><code class="xref ocv ocv-class docutils literal"><span class="pre">SURF</span></code></a></p>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<ul class="last simple">
<li>An example for using the SURF keypoint matcher on GPU can be found at opencv_source_code/samples/gpu/surf_keypoint_matcher.cpp</li>
</ul>
</div>
</div>
<div class="section" id="ocl-surf-ocl">
<h2>ocl::SURF_OCL<a class="headerlink" href="#ocl-surf-ocl" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="ocl::SURF_OCL : public Feature2D">
<em class="property">class </em><code class="descclassname">ocl::</code><code class="descname">SURF_OCL</code> : <em class="property">public</em> <code class="descname">Feature2D</code><a class="headerlink" href="#ocl::SURF_OCL : public Feature2D" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<p>Class used for extracting Speeded Up Robust Features (SURF) from an image.</p>
<div class="highlight-python"><div class="highlight"><pre>class SURF_OCL
{
public:
    enum KeypointLayout
    {
        X_ROW = 0,
        Y_ROW,
        LAPLACIAN_ROW,
        OCTAVE_ROW,
        SIZE_ROW,
        ANGLE_ROW,
        HESSIAN_ROW,
        ROWS_COUNT
    };

    //! the default constructor
    SURF_OCL();
    //! the full constructor taking all the necessary parameters
    explicit SURF_OCL(double _hessianThreshold, int _nOctaves=4,
         int _nOctaveLayers=2, bool _extended=false, float _keypointsRatio=0.01f, bool _upright = false);

    //! returns the descriptor size in float&#39;s (64 or 128)
    int descriptorSize() const;

    //! upload host keypoints to device memory
    void uploadKeypoints(const vector&lt;KeyPoint&gt;&amp; keypoints,
        oclMat&amp; keypointsocl);
    //! download keypoints from device to host memory
    void downloadKeypoints(const oclMat&amp; keypointsocl,
        vector&lt;KeyPoint&gt;&amp; keypoints);

    //! download descriptors from device to host memory
    void downloadDescriptors(const oclMat&amp; descriptorsocl,
        vector&lt;float&gt;&amp; descriptors);

    void operator()(const oclMat&amp; img, const oclMat&amp; mask,
        oclMat&amp; keypoints);

    void operator()(const oclMat&amp; img, const oclMat&amp; mask,
        oclMat&amp; keypoints, oclMat&amp; descriptors,
        bool useProvidedKeypoints = false);

    void operator()(const oclMat&amp; img, const oclMat&amp; mask,
        std::vector&lt;KeyPoint&gt;&amp; keypoints);

    void operator()(const oclMat&amp; img, const oclMat&amp; mask,
        std::vector&lt;KeyPoint&gt;&amp; keypoints, oclMat&amp; descriptors,
        bool useProvidedKeypoints = false);

    void operator()(const oclMat&amp; img, const oclMat&amp; mask,
        std::vector&lt;KeyPoint&gt;&amp; keypoints,
        std::vector&lt;float&gt;&amp; descriptors,
        bool useProvidedKeypoints = false);

    void releaseMemory();

    // SURF parameters
    double hessianThreshold;
    int nOctaves;
    int nOctaveLayers;
    bool extended;
    bool upright;

    //! max keypoints = min(keypointsRatio * img.size().area(), 65535)
    float keypointsRatio;

    oclMat sum, mask1, maskSum, intBuffer;

    oclMat det, trace;

    oclMat maxPosBuffer;
};
</pre></div>
</div>
<p>The class <code class="docutils literal"><span class="pre">SURF_OCL</span></code> implements Speeded Up Robust Features descriptor. There is a fast multi-scale Hessian keypoint detector that can be used to find the keypoints (which is the default option). But the descriptors can also be computed for the user-specified keypoints. Only 8-bit grayscale images are supported.</p>
<p>The class <code class="docutils literal"><span class="pre">SURF_OCL</span></code> can store results in the GPU and CPU memory. It provides functions to convert results between CPU and GPU version ( <code class="docutils literal"><span class="pre">uploadKeypoints</span></code>, <code class="docutils literal"><span class="pre">downloadKeypoints</span></code>, <code class="docutils literal"><span class="pre">downloadDescriptors</span></code> ). The format of CPU results is the same as <code class="docutils literal"><span class="pre">SURF</span></code> results. GPU results are stored in <code class="docutils literal"><span class="pre">oclMat</span></code>. The <code class="docutils literal"><span class="pre">keypoints</span></code> matrix is <img class="math" src="../../../_images/math/8751b70edb8d3b203d842bc56667a5526dcdfab1.png" alt="\texttt{nFeatures} \times 7"/> matrix with the <code class="docutils literal"><span class="pre">CV_32FC1</span></code> type.</p>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">keypoints.ptr&lt;float&gt;(X_ROW)[i]</span></code> contains x coordinate of the i-th feature.</li>
<li><code class="docutils literal"><span class="pre">keypoints.ptr&lt;float&gt;(Y_ROW)[i]</span></code> contains y coordinate of the i-th feature.</li>
<li><code class="docutils literal"><span class="pre">keypoints.ptr&lt;float&gt;(LAPLACIAN_ROW)[i]</span></code>  contains the laplacian sign of the i-th feature.</li>
<li><code class="docutils literal"><span class="pre">keypoints.ptr&lt;float&gt;(OCTAVE_ROW)[i]</span></code> contains the octave of the i-th feature.</li>
<li><code class="docutils literal"><span class="pre">keypoints.ptr&lt;float&gt;(SIZE_ROW)[i]</span></code> contains the size of the i-th feature.</li>
<li><code class="docutils literal"><span class="pre">keypoints.ptr&lt;float&gt;(ANGLE_ROW)[i]</span></code> contain orientation of the i-th feature.</li>
<li><code class="docutils literal"><span class="pre">keypoints.ptr&lt;float&gt;(HESSIAN_ROW)[i]</span></code> contains the response of the i-th feature.</li>
</ul>
<p>The <code class="docutils literal"><span class="pre">descriptors</span></code> matrix is <img class="math" src="../../../_images/math/93325a9a1014934ae52792d8ccc1347b3f79828a.png" alt="\texttt{nFeatures} \times \texttt{descriptorSize}"/> matrix with the <code class="docutils literal"><span class="pre">CV_32FC1</span></code> type.</p>
<p>The class <code class="docutils literal"><span class="pre">SURF_OCL</span></code> uses some buffers and provides access to it. All buffers can be safely released between function calls.</p>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<p class="last"><a class="reference internal" href="#SURF : public Feature2D" title="class SURF : public Feature2D"><code class="xref ocv ocv-class docutils literal"><span class="pre">SURF</span></code></a></p>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<ul class="last simple">
<li>OCL : An example of the SURF detector can be found at opencv_source_code/samples/ocl/surf_matcher.cpp</li>
</ul>
</div>
</div>
</div>


          </div>
          <div class="feedback">
              <h2>Help and Feedback</h2>
              You did not find what you were looking for?
              <ul>
                  
                  
                  
                  <li>Ask a question on the <a href="http://answers.opencv.org">Q&A forum</a>.</li>
                  <li>If you think something is missing or wrong in the documentation,
                  please file a <a href="http://code.opencv.org">bug report</a>.</li>
              </ul>
          </div>
        </div>
      </div>

      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../../../index.html">
              <img class="logo" src="../../../_static/opencv-logo-white.png" alt="Logo"/>
            </a></p>
<div id="searchbox" style="display: none">
      <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" size="18" />
      <input type="submit" value="Search" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
      </p>
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
  <h3><a href="../../../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Feature Detection and Description</a><ul>
<li><a class="reference internal" href="#sift">SIFT</a></li>
<li><a class="reference internal" href="#sift-sift">SIFT::SIFT</a></li>
<li><a class="reference internal" href="#sift-operator">SIFT::operator ()</a></li>
<li><a class="reference internal" href="#surf">SURF</a></li>
<li><a class="reference internal" href="#surf-surf">SURF::SURF</a></li>
<li><a class="reference internal" href="#surf-operator">SURF::operator()</a></li>
<li><a class="reference internal" href="#gpu-surf-gpu">gpu::SURF_GPU</a></li>
<li><a class="reference internal" href="#ocl-surf-ocl">ocl::SURF_OCL</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="nonfree.html"
                        title="previous chapter">nonfree. Non-free functionality</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="../../contrib/doc/contrib.html"
                        title="next chapter">contrib. Contributed/Experimental Stuff</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../../../_sources/modules/nonfree/doc/feature_detection.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../contrib/doc/contrib.html" title="contrib. Contributed/Experimental Stuff"
             >next</a> |</li>
        <li class="right" >
          <a href="nonfree.html" title="nonfree. Non-free functionality"
             >previous</a> |</li>
        <li><a href="../../../index.html">OpenCV 2.4.13.7 documentation</a> &raquo;</li>
          <li><a href="../../refman.html" >OpenCV API Reference</a> &raquo;</li>
          <li><a href="nonfree.html" >nonfree. Non-free functionality</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2011-2014, opencv dev team.
      Last updated on Jul 12, 2018.
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.3.6.
    </div>
  </body>
</html>