<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-33108845-1']);
  _gaq.push(['_setDomainName', 'opencv.org']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Neural Networks &mdash; OpenCV 2.4.13.7 documentation</title>
    <link rel="stylesheet" href="../../../_static/default.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../../',
        VERSION:     '2.4.13.7',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../_static/doctools.js"></script>
    <link rel="top" title="OpenCV 2.4.13.7 documentation" href="../../../index.html" />
    <link rel="up" title="ml. Machine Learning" href="ml.html" />
    <link rel="next" title="MLData" href="mldata.html" />
    <link rel="prev" title="Expectation Maximization" href="expectation_maximization.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="mldata.html" title="MLData"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="expectation_maximization.html" title="Expectation Maximization"
             accesskey="P">previous</a> |</li>
        <li><a href="../../../index.html">OpenCV 2.4.13.7 documentation</a> &raquo;</li>
          <li><a href="../../refman.html" >OpenCV API Reference</a> &raquo;</li>
          <li><a href="ml.html" accesskey="U">ml. Machine Learning</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
  
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="neural-networks">
<h1>Neural Networks<a class="headerlink" href="#neural-networks" title="Permalink to this headline">¶</a></h1>
<p>ML implements feed-forward artificial neural networks or, more particularly, multi-layer perceptrons (MLP), the most commonly used type of neural networks. MLP consists of the input layer, output layer, and one or more hidden layers. Each layer of MLP includes one or more neurons directionally linked with the neurons from the previous and the next layer. The example below represents a 3-layer perceptron with three inputs, two outputs, and the hidden layer including five neurons:</p>
<img alt="../../../_images/mlp.png" src="../../../_images/mlp.png" />
<p>All the neurons in MLP are similar. Each of them has several input links (it takes the output values from several neurons in the previous layer as input) and several output links (it passes the response to several neurons in the next layer). The values retrieved from the previous layer are summed up with certain weights, individual for each neuron, plus the bias term. The sum is transformed using the activation function
<img class="math" src="../../../_images/math/43f689f93c9323831e76724aedb37ece0f77722a.png" alt="f"/> that may be also different for different neurons.</p>
<img alt="../../../_images/neuron_model.png" src="../../../_images/neuron_model.png" />
<p>In other words, given the outputs
<img class="math" src="../../../_images/math/2b7eea09325cebc20c2e667c1885ee81bfd58ef9.png" alt="x_j"/> of the layer
<img class="math" src="../../../_images/math/95984a3ee1c7b534830cfc6a19a5410d83ea85fe.png" alt="n"/> , the outputs
<img class="math" src="../../../_images/math/85cd5a132f06fbaca76c8f7d258c621287cb2242.png" alt="y_i"/> of the layer
<img class="math" src="../../../_images/math/535c4b2a6a72a13edd966730cbf67e39437fffd5.png" alt="n+1"/> are computed as:</p>
<div class="math">
<p><img src="../../../_images/math/61b6d35fb68dc62f0ddeb3a2938fb8f55a184d19.png" alt="u_i =  \sum _j (w^{n+1}_{i,j}*x_j) + w^{n+1}_{i,bias}"/></p>
</div><div class="math">
<p><img src="../../../_images/math/00a53d749bd65d0720abb85aa8ce5d6edae5bdee.png" alt="y_i = f(u_i)"/></p>
</div><p>Different activation functions may be used. ML implements three standard functions:</p>
<ul>
<li><p class="first">Identity function ( <code class="docutils literal"><span class="pre">CvANN_MLP::IDENTITY</span></code>     ):
<img class="math" src="../../../_images/math/667a8593928fa9c39319a7504d26973208ebf789.png" alt="f(x)=x"/></p>
</li>
<li><p class="first">Symmetrical sigmoid ( <code class="docutils literal"><span class="pre">CvANN_MLP::SIGMOID_SYM</span></code>     ):
<img class="math" src="../../../_images/math/dd62e12b6e5451b8f6dc30d279c89a6c79eece6a.png" alt="f(x)=\beta*(1-e^{-\alpha x})/(1+e^{-\alpha x}"/>     ), which is the default choice for MLP. The standard sigmoid with
<img class="math" src="../../../_images/math/7764ed119f7d4e17f090db46c5615a2e239121d0.png" alt="\beta =1, \alpha =1"/>     is shown below:</p>
<img alt="../../../_images/sigmoid_bipolar.png" src="../../../_images/sigmoid_bipolar.png" />
</li>
<li><p class="first">Gaussian function ( <code class="docutils literal"><span class="pre">CvANN_MLP::GAUSSIAN</span></code>     ):
<img class="math" src="../../../_images/math/eb79a37a9339e0d19bd9e5b39244e9300f2eda76.png" alt="f(x)=\beta e^{-\alpha x*x}"/>     , which is not completely supported at the moment.</p>
</li>
</ul>
<p>In ML, all the neurons have the same activation functions, with the same free parameters (
<img class="math" src="../../../_images/math/3f6714dcd6e1955edc48687b1d18a11807217a56.png" alt="\alpha, \beta"/> ) that are specified by user and are not altered by the training algorithms.</p>
<p>So, the whole trained network works as follows:</p>
<ol class="arabic simple">
<li>Take the feature vector as input. The vector size is equal to the size of the input layer.</li>
<li>Pass values as input to the first hidden layer.</li>
<li>Compute outputs of the hidden layer using the weights and the activation functions.</li>
<li>Pass outputs further downstream until you compute the output layer.</li>
</ol>
<p>So, to compute the network, you need to know all the
weights
<img class="math" src="../../../_images/math/60552971a13f20c4a2c1c250b9802b5ea34827f4.png" alt="w^{n+1)}_{i,j}"/> . The weights are computed by the training
algorithm. The algorithm takes a training set, multiple input vectors
with the corresponding output vectors, and iteratively adjusts the
weights to enable the network to give the desired response to the
provided input vectors.</p>
<p>The larger the network size (the number of hidden layers and their sizes) is,
the more the potential network flexibility is. The error on the
training set could be made arbitrarily small. But at the same time the
learned network also &#8220;learns&#8221; the noise present in the training set,
so the error on the test set usually starts increasing after the network
size reaches a limit. Besides, the larger networks are trained much
longer than the smaller ones, so it is reasonable to pre-process the data,
using
<a class="reference internal" href="../../core/doc/operations_on_arrays.html#PCA&amp; PCA::operator()(InputArray data, InputArray mean, int flags, int maxComponents)" title="PCA&amp; PCA::operator()(InputArray data, InputArray mean, int flags, int maxComponents)"><code class="xref ocv ocv-funcx docutils literal"><span class="pre">PCA::operator()</span></code></a> or similar technique, and train a smaller network
on only essential features.</p>
<p>Another MLP feature is an inability to handle categorical
data as is. However, there is a workaround. If a certain feature in the
input or output (in case of <code class="docutils literal"><span class="pre">n</span></code> -class classifier for
<img class="math" src="../../../_images/math/c563956fcf0d4f5c71ad68097b6a1c9df1d5b84e.png" alt="n&gt;2"/> ) layer is categorical and can take
<img class="math" src="../../../_images/math/cc5090e68452e97438093e770d7381fc6247a300.png" alt="M&gt;2"/> different values, it makes sense to represent it as a binary tuple of <code class="docutils literal"><span class="pre">M</span></code> elements, where the <code class="docutils literal"><span class="pre">i</span></code> -th element is 1 if and only if the
feature is equal to the <code class="docutils literal"><span class="pre">i</span></code> -th value out of <code class="docutils literal"><span class="pre">M</span></code> possible. It
increases the size of the input/output layer but speeds up the
training algorithm convergence and at the same time enables &#8220;fuzzy&#8221; values
of such variables, that is, a tuple of probabilities instead of a fixed value.</p>
<p>ML implements two algorithms for training MLP&#8217;s. The first algorithm is a classical
random sequential back-propagation algorithm.
The second (default) one is a batch RPROP algorithm.</p>
<table class="docutils citation" frame="void" id="backpropwikipedia" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[BackPropWikipedia]</td><td><a class="reference external" href="http://en.wikipedia.org/wiki/Backpropagation">http://en.wikipedia.org/wiki/Backpropagation</a>. Wikipedia article about the back-propagation algorithm.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="lecun98" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[LeCun98]</td><td><ol class="first last upperalpha simple" start="25">
<li>LeCun, L. Bottou, G.B. Orr and K.-R. Muller, <em>Efficient backprop</em>, in Neural Networks&#8212;Tricks of the Trade, Springer Lecture Notes in Computer Sciences 1524, pp.5-50, 1998.</li>
</ol>
</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="rprop93" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[RPROP93]</a></td><td><ol class="first last upperalpha simple" start="13">
<li>Riedmiller and H. Braun, <em>A Direct Adaptive Method for Faster Backpropagation Learning: The RPROP Algorithm</em>, Proc. ICNN, San Francisco (1993).</li>
</ol>
</td></tr>
</tbody>
</table>
<div class="section" id="cvann-mlp-trainparams">
<h2>CvANN_MLP_TrainParams<a class="headerlink" href="#cvann-mlp-trainparams" title="Permalink to this headline">¶</a></h2>
<dl class="struct">
<dt id="CvANN_MLP_TrainParams">
<em class="property">struct </em><code class="descname">CvANN_MLP_TrainParams</code><a class="headerlink" href="#CvANN_MLP_TrainParams" title="Permalink to this definition">¶</a></dt>
<dd><p>Parameters of the MLP training algorithm. You can initialize the structure by a constructor or the individual parameters can be adjusted after the structure is created.</p>
<p>The back-propagation algorithm parameters:</p>
<dl class="member">
<dt id="double bp_dw_scale">
double <code class="descname">bp_dw_scale</code><a class="headerlink" href="#double bp_dw_scale" title="Permalink to this definition">¶</a></dt>
<dd><p>Strength of the weight gradient term. The recommended value is about 0.1.</p>
</dd></dl>

<dl class="member">
<dt id="double bp_moment_scale">
double <code class="descname">bp_moment_scale</code><a class="headerlink" href="#double bp_moment_scale" title="Permalink to this definition">¶</a></dt>
<dd><p>Strength of the momentum term (the difference between weights on the 2 previous iterations). This parameter provides some inertia to smooth the random fluctuations of the weights. It can vary from 0 (the feature is disabled) to 1 and beyond. The value 0.1 or so is good enough</p>
</dd></dl>

<p>The RPROP algorithm parameters (see <a class="reference internal" href="#rprop93" id="id1">[RPROP93]</a> for details):</p>
<dl class="member">
<dt id="double rp_dw0">
double <code class="descname">rp_dw0</code><a class="headerlink" href="#double rp_dw0" title="Permalink to this definition">¶</a></dt>
<dd><p>Initial value <img class="math" src="../../../_images/math/908dc3057b04dc4e7fa758bbb4589b2cb0a5cfc5.png" alt="\Delta_0"/> of update-values <img class="math" src="../../../_images/math/0908dfab9eb0e9f9dc98df0724ece1881d88cbb9.png" alt="\Delta_{ij}"/>.</p>
</dd></dl>

<dl class="member">
<dt id="double rp_dw_plus">
double <code class="descname">rp_dw_plus</code><a class="headerlink" href="#double rp_dw_plus" title="Permalink to this definition">¶</a></dt>
<dd><p>Increase factor <img class="math" src="../../../_images/math/131bab3fbfa446ddfeb90a926b3ba963243bb91b.png" alt="\eta^+"/>. It must be &gt;1.</p>
</dd></dl>

<dl class="member">
<dt id="double rp_dw_minus">
double <code class="descname">rp_dw_minus</code><a class="headerlink" href="#double rp_dw_minus" title="Permalink to this definition">¶</a></dt>
<dd><p>Decrease factor <img class="math" src="../../../_images/math/11d7ca912819415566eb8fa455be88a2ef1ac93c.png" alt="\eta^-"/>. It must be &lt;1.</p>
</dd></dl>

<dl class="member">
<dt id="double rp_dw_min">
double <code class="descname">rp_dw_min</code><a class="headerlink" href="#double rp_dw_min" title="Permalink to this definition">¶</a></dt>
<dd><p>Update-values lower limit <img class="math" src="../../../_images/math/494f2136c557c5992070db8f9c1cd2daf751995a.png" alt="\Delta_{min}"/>. It must be positive.</p>
</dd></dl>

<dl class="member">
<dt id="double rp_dw_max">
double <code class="descname">rp_dw_max</code><a class="headerlink" href="#double rp_dw_max" title="Permalink to this definition">¶</a></dt>
<dd><p>Update-values upper limit <img class="math" src="../../../_images/math/cf86648d3b8042894a2c2a9bb8db51f1e6ab9d75.png" alt="\Delta_{max}"/>. It must be &gt;1.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="cvann-mlp-trainparams-cvann-mlp-trainparams">
<h2>CvANN_MLP_TrainParams::CvANN_MLP_TrainParams<a class="headerlink" href="#cvann-mlp-trainparams-cvann-mlp-trainparams" title="Permalink to this headline">¶</a></h2>
<p>The constructors.</p>
<dl class="function">
<dt id="CvANN_MLP_TrainParams::CvANN_MLP_TrainParams()">
<strong>C++:</strong><code class="descname"> </code> <code class="descclassname">CvANN_MLP_TrainParams::</code><code class="descname">CvANN_MLP_TrainParams</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#CvANN_MLP_TrainParams::CvANN_MLP_TrainParams()" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="CvANN_MLP_TrainParams::CvANN_MLP_TrainParams(CvTermCriteria term_crit, int train_method, double param1, double param2)">
<strong>C++:</strong><code class="descname"> </code> <code class="descclassname">CvANN_MLP_TrainParams::</code><code class="descname">CvANN_MLP_TrainParams</code><span class="sig-paren">(</span>CvTermCriteria <strong>term_crit</strong>, int <strong>train_method</strong>, double <strong>param1</strong>, double <strong>param2</strong>=0 <span class="sig-paren">)</span><a class="headerlink" href="#CvANN_MLP_TrainParams::CvANN_MLP_TrainParams(CvTermCriteria term_crit, int train_method, double param1, double param2)" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>term_crit</strong> &#8211; Termination criteria of the training algorithm. You can specify the maximum number of iterations (<code class="docutils literal"><span class="pre">max_iter</span></code>) and/or how much the error could change between the iterations to make the algorithm continue (<code class="docutils literal"><span class="pre">epsilon</span></code>).</li>
<li><strong>train_method</strong> &#8211; <p>Training method of the MLP. Possible values are:</p>
<ul>
<li><strong>CvANN_MLP_TrainParams::BACKPROP</strong> The back-propagation algorithm.</li>
<li><strong>CvANN_MLP_TrainParams::RPROP</strong> The RPROP algorithm.</li>
</ul>
</li>
<li><strong>param1</strong> &#8211; Parameter of the training method. It is <code class="docutils literal"><span class="pre">rp_dw0</span></code> for <code class="docutils literal"><span class="pre">RPROP</span></code> and <code class="docutils literal"><span class="pre">bp_dw_scale</span></code> for <code class="docutils literal"><span class="pre">BACKPROP</span></code>.</li>
<li><strong>param2</strong> &#8211; Parameter of the training method. It is <code class="docutils literal"><span class="pre">rp_dw_min</span></code> for <code class="docutils literal"><span class="pre">RPROP</span></code> and <code class="docutils literal"><span class="pre">bp_moment_scale</span></code> for <code class="docutils literal"><span class="pre">BACKPROP</span></code>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<p>By default the RPROP algorithm is used:</p>
<div class="highlight-cpp"><div class="highlight"><pre><span class="n">CvANN_MLP_TrainParams</span><span class="o">::</span><span class="n">CvANN_MLP_TrainParams</span><span class="p">()</span>
<span class="p">{</span>
    <span class="n">term_crit</span> <span class="o">=</span> <span class="n">cvTermCriteria</span><span class="p">(</span> <span class="n">CV_TERMCRIT_ITER</span> <span class="o">+</span> <span class="n">CV_TERMCRIT_EPS</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mf">0.01</span> <span class="p">);</span>
    <span class="n">train_method</span> <span class="o">=</span> <span class="n">RPROP</span><span class="p">;</span>
    <span class="n">bp_dw_scale</span> <span class="o">=</span> <span class="n">bp_moment_scale</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">;</span>
    <span class="n">rp_dw0</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">;</span> <span class="n">rp_dw_plus</span> <span class="o">=</span> <span class="mf">1.2</span><span class="p">;</span> <span class="n">rp_dw_minus</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">;</span>
    <span class="n">rp_dw_min</span> <span class="o">=</span> <span class="n">FLT_EPSILON</span><span class="p">;</span> <span class="n">rp_dw_max</span> <span class="o">=</span> <span class="mf">50.</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="cvann-mlp">
<h2>CvANN_MLP<a class="headerlink" href="#cvann-mlp" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="CvANN_MLP : public CvStatModel">
<em class="property">class </em><code class="descname">CvANN_MLP</code> : <em class="property">public</em> <code class="descname">CvStatModel</code><a class="headerlink" href="#CvANN_MLP : public CvStatModel" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<p>MLP model.</p>
<p>Unlike many other models in ML that are constructed and trained at once, in the MLP model these steps are separated. First, a network with the specified topology is created using the non-default constructor or the method <a class="reference internal" href="#void CvANN_MLP::create(const Mat&amp; layerSizes, int activateFunc, double fparam1, double fparam2)" title="void CvANN_MLP::create(const Mat&amp; layerSizes, int activateFunc, double fparam1, double fparam2)"><code class="xref ocv ocv-func docutils literal"><span class="pre">CvANN_MLP::create()</span></code></a>. All the weights are set to zeros. Then, the network is trained using a set of input and output vectors. The training procedure can be repeated more than once, that is, the weights can be adjusted based on the new training data.</p>
</div>
<div class="section" id="cvann-mlp-cvann-mlp">
<h2>CvANN_MLP::CvANN_MLP<a class="headerlink" href="#cvann-mlp-cvann-mlp" title="Permalink to this headline">¶</a></h2>
<p>The constructors.</p>
<dl class="function">
<dt id="CvANN_MLP::CvANN_MLP()">
<strong>C++:</strong><code class="descname"> </code> <code class="descclassname">CvANN_MLP::</code><code class="descname">CvANN_MLP</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#CvANN_MLP::CvANN_MLP()" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="CvANN_MLP::CvANN_MLP(const CvMat* layerSizes, int activateFunc, double fparam1, double fparam2)">
<strong>C++:</strong><code class="descname"> </code> <code class="descclassname">CvANN_MLP::</code><code class="descname">CvANN_MLP</code><span class="sig-paren">(</span>const CvMat* <strong>layerSizes</strong>, int <strong>activateFunc</strong>=CvANN_MLP::SIGMOID_SYM, double <strong>fparam1</strong>=0, double <strong>fparam2</strong>=0 <span class="sig-paren">)</span><a class="headerlink" href="#CvANN_MLP::CvANN_MLP(const CvMat* layerSizes, int activateFunc, double fparam1, double fparam2)" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="pyfunction">
<dt id="cv2.ANN_MLP">
<strong>Python:</strong><code class="descname"> </code><code class="descclassname">cv2.</code><code class="descname">ANN_MLP</code><span class="sig-paren">(</span><span class="optional">[</span>layerSizes<span class="optional">[</span>, activateFunc<span class="optional">[</span>, fparam1<span class="optional">[</span>, fparam2<span class="optional">]</span><span class="optional">]</span><span class="optional">]</span><span class="optional">]</span><span class="sig-paren">)</span> &rarr; &lt;ANN_MLP object&gt;<a class="headerlink" href="#cv2.ANN_MLP" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<p>The advanced constructor allows to create MLP with the specified topology. See <a class="reference internal" href="#void CvANN_MLP::create(const Mat&amp; layerSizes, int activateFunc, double fparam1, double fparam2)" title="void CvANN_MLP::create(const Mat&amp; layerSizes, int activateFunc, double fparam1, double fparam2)"><code class="xref ocv ocv-func docutils literal"><span class="pre">CvANN_MLP::create()</span></code></a> for details.</p>
</div>
<div class="section" id="cvann-mlp-create">
<h2>CvANN_MLP::create<a class="headerlink" href="#cvann-mlp-create" title="Permalink to this headline">¶</a></h2>
<p>Constructs MLP with the specified topology.</p>
<dl class="function">
<dt id="void CvANN_MLP::create(const Mat&amp; layerSizes, int activateFunc, double fparam1, double fparam2)">
<strong>C++:</strong><code class="descname"> </code>void <code class="descclassname">CvANN_MLP::</code><code class="descname">create</code><span class="sig-paren">(</span>const Mat&amp; <strong>layerSizes</strong>, int <strong>activateFunc</strong>=CvANN_MLP::SIGMOID_SYM, double <strong>fparam1</strong>=0, double <strong>fparam2</strong>=0 <span class="sig-paren">)</span><a class="headerlink" href="#void CvANN_MLP::create(const Mat& layerSizes, int activateFunc, double fparam1, double fparam2)" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="void CvANN_MLP::create(const CvMat* layerSizes, int activateFunc, double fparam1, double fparam2)">
<strong>C++:</strong><code class="descname"> </code>void <code class="descclassname">CvANN_MLP::</code><code class="descname">create</code><span class="sig-paren">(</span>const CvMat* <strong>layerSizes</strong>, int <strong>activateFunc</strong>=CvANN_MLP::SIGMOID_SYM, double <strong>fparam1</strong>=0, double <strong>fparam2</strong>=0 <span class="sig-paren">)</span><a class="headerlink" href="#void CvANN_MLP::create(const CvMat* layerSizes, int activateFunc, double fparam1, double fparam2)" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="pyfunction">
<dt id="cv2.ANN_MLP.create">
<strong>Python:</strong><code class="descname"> </code><code class="descclassname">cv2.ANN_MLP.</code><code class="descname">create</code><span class="sig-paren">(</span>layerSizes<span class="optional">[</span>, activateFunc<span class="optional">[</span>, fparam1<span class="optional">[</span>, fparam2<span class="optional">]</span><span class="optional">]</span><span class="optional">]</span><span class="sig-paren">)</span> &rarr; None<a class="headerlink" href="#cv2.ANN_MLP.create" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>layerSizes</strong> &#8211; Integer vector specifying the number of neurons in each layer including the input and output layers.</li>
<li><strong>activateFunc</strong> &#8211; Parameter specifying the activation function for each neuron: one of  <code class="docutils literal"><span class="pre">CvANN_MLP::IDENTITY</span></code>, <code class="docutils literal"><span class="pre">CvANN_MLP::SIGMOID_SYM</span></code>, and <code class="docutils literal"><span class="pre">CvANN_MLP::GAUSSIAN</span></code>.</li>
<li><strong>fparam1</strong> &#8211; Free parameter of the activation function, <img class="math" src="../../../_images/math/69777408db155ee0fca9cc9dee60a269df6d1f96.png" alt="\alpha"/>. See the formulas in the introduction section.</li>
<li><strong>fparam2</strong> &#8211; Free parameter of the activation function, <img class="math" src="../../../_images/math/247b5ce2e487d3610db5ce3e3d8cc882c38ab8db.png" alt="\beta"/>. See the formulas in the introduction section.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<p>The method creates an MLP network with the specified topology and assigns the same activation function to all the neurons.</p>
</div>
<div class="section" id="cvann-mlp-train">
<h2>CvANN_MLP::train<a class="headerlink" href="#cvann-mlp-train" title="Permalink to this headline">¶</a></h2>
<p>Trains/updates MLP.</p>
<dl class="function">
<dt id="int CvANN_MLP::train(const Mat&amp; inputs, const Mat&amp; outputs, const Mat&amp; sampleWeights, const Mat&amp; sampleIdx, CvANN_MLP_TrainParams params , int flags)">
<strong>C++:</strong><code class="descname"> </code>int <code class="descclassname">CvANN_MLP::</code><code class="descname">train</code><span class="sig-paren">(</span>const Mat&amp; <strong>inputs</strong>, const Mat&amp; <strong>outputs</strong>, const Mat&amp; <strong>sampleWeights</strong>, const Mat&amp; <strong>sampleIdx</strong>=Mat(), CvANN_MLP_TrainParams <strong>params</strong>=CvANN_MLP_TrainParams(), int <strong>flags</strong>=0 <span class="sig-paren">)</span><a class="headerlink" href="#int CvANN_MLP::train(const Mat& inputs, const Mat& outputs, const Mat& sampleWeights, const Mat& sampleIdx, CvANN_MLP_TrainParams params , int flags)" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="int CvANN_MLP::train(const CvMat* inputs, const CvMat* outputs, const CvMat* sampleWeights, const CvMat* sampleIdx, CvANN_MLP_TrainParams params , int flags)">
<strong>C++:</strong><code class="descname"> </code>int <code class="descclassname">CvANN_MLP::</code><code class="descname">train</code><span class="sig-paren">(</span>const CvMat* <strong>inputs</strong>, const CvMat* <strong>outputs</strong>, const CvMat* <strong>sampleWeights</strong>, const CvMat* <strong>sampleIdx</strong>=0, CvANN_MLP_TrainParams <strong>params</strong>=CvANN_MLP_TrainParams(), int <strong>flags</strong>=0 <span class="sig-paren">)</span><a class="headerlink" href="#int CvANN_MLP::train(const CvMat* inputs, const CvMat* outputs, const CvMat* sampleWeights, const CvMat* sampleIdx, CvANN_MLP_TrainParams params , int flags)" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="pyfunction">
<dt id="cv2.ANN_MLP.train">
<strong>Python:</strong><code class="descname"> </code><code class="descclassname">cv2.ANN_MLP.</code><code class="descname">train</code><span class="sig-paren">(</span>inputs, outputs, sampleWeights<span class="optional">[</span>, sampleIdx<span class="optional">[</span>, params<span class="optional">[</span>, flags<span class="optional">]</span><span class="optional">]</span><span class="optional">]</span><span class="sig-paren">)</span> &rarr; retval<a class="headerlink" href="#cv2.ANN_MLP.train" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>inputs</strong> &#8211; Floating-point matrix of input vectors, one vector per row.</li>
<li><strong>outputs</strong> &#8211; Floating-point matrix of the corresponding output vectors, one vector per row.</li>
<li><strong>sampleWeights</strong> &#8211; (RPROP only) Optional floating-point vector of weights for each sample. Some samples may be more important than others for training. You may want to raise the weight of certain classes to find the right balance between hit-rate and false-alarm rate, and so on.</li>
<li><strong>sampleIdx</strong> &#8211; Optional integer vector indicating the samples (rows of <code class="docutils literal"><span class="pre">inputs</span></code> and <code class="docutils literal"><span class="pre">outputs</span></code>) that are taken into account.</li>
<li><strong>params</strong> &#8211; Training parameters. See the <code class="xref ocv ocv-class docutils literal"><span class="pre">CvANN_MLP_TrainParams</span></code> description.</li>
<li><strong>flags</strong> &#8211; <p>Various parameters to control the training algorithm. A combination of the following parameters is possible:</p>
<ul>
<li><strong>UPDATE_WEIGHTS</strong> Algorithm updates the network weights, rather than computes them from scratch. In the latter case the weights are initialized using the Nguyen-Widrow algorithm.</li>
<li><strong>NO_INPUT_SCALE</strong> Algorithm does not normalize the input vectors. If this flag is not set, the training algorithm normalizes each input feature independently, shifting its mean value to 0 and making the standard deviation equal to 1. If the network is assumed to be updated frequently, the new training data could be much different from original one. In this case, you should take care of proper normalization.</li>
<li><strong>NO_OUTPUT_SCALE</strong> Algorithm does not normalize the output vectors. If the flag is not set, the training algorithm normalizes each output feature independently, by transforming it to the certain range depending on the used activation function.</li>
</ul>
</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<p>This method applies the specified training algorithm to computing/adjusting the network weights. It returns the number of done iterations.</p>
<p>The RPROP training algorithm is parallelized with the TBB library.</p>
<p>If you are using the default <code class="docutils literal"><span class="pre">cvANN_MLP::SIGMOID_SYM</span></code> activation function then the output should be in the range [-1,1], instead of [0,1], for optimal results.</p>
</div>
<div class="section" id="cvann-mlp-predict">
<h2>CvANN_MLP::predict<a class="headerlink" href="#cvann-mlp-predict" title="Permalink to this headline">¶</a></h2>
<p>Predicts responses for input samples.</p>
<dl class="function">
<dt id="float CvANN_MLP::predict(const Mat&amp; inputs, Mat&amp; outputs) const">
<strong>C++:</strong><code class="descname"> </code>float <code class="descclassname">CvANN_MLP::</code><code class="descname">predict</code><span class="sig-paren">(</span>const Mat&amp; <strong>inputs</strong>, Mat&amp; <strong>outputs</strong><span class="sig-paren">)</span><code class="descclassname"> const</code><a class="headerlink" href="#float CvANN_MLP::predict(const Mat& inputs, Mat& outputs) const" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="float CvANN_MLP::predict(const CvMat* inputs, CvMat* outputs) const">
<strong>C++:</strong><code class="descname"> </code>float <code class="descclassname">CvANN_MLP::</code><code class="descname">predict</code><span class="sig-paren">(</span>const CvMat* <strong>inputs</strong>, CvMat* <strong>outputs</strong><span class="sig-paren">)</span><code class="descclassname"> const</code><a class="headerlink" href="#float CvANN_MLP::predict(const CvMat* inputs, CvMat* outputs) const" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="pyfunction">
<dt id="cv2.ANN_MLP.predict">
<strong>Python:</strong><code class="descname"> </code><code class="descclassname">cv2.ANN_MLP.</code><code class="descname">predict</code><span class="sig-paren">(</span>inputs<span class="optional">[</span>, outputs<span class="optional">]</span><span class="sig-paren">)</span> &rarr; retval, outputs<a class="headerlink" href="#cv2.ANN_MLP.predict" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>inputs</strong> &#8211; Input samples.</li>
<li><strong>outputs</strong> &#8211; Predicted responses for corresponding samples.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<p>The method returns a dummy value which should be ignored.</p>
<p>If you are using the default <code class="docutils literal"><span class="pre">cvANN_MLP::SIGMOID_SYM</span></code> activation function with the default parameter values fparam1=0 and fparam2=0 then the function used is y = 1.7159*tanh(2/3 * x), so the output will range from [-1.7159, 1.7159], instead of [0,1].</p>
</div>
<div class="section" id="cvann-mlp-get-layer-count">
<h2>CvANN_MLP::get_layer_count<a class="headerlink" href="#cvann-mlp-get-layer-count" title="Permalink to this headline">¶</a></h2>
<p>Returns the number of layers in the MLP.</p>
<dl class="function">
<dt id="int CvANN_MLP::get_layer_count()">
<strong>C++:</strong><code class="descname"> </code>int <code class="descclassname">CvANN_MLP::</code><code class="descname">get_layer_count</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#int CvANN_MLP::get_layer_count()" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="cvann-mlp-get-layer-sizes">
<h2>CvANN_MLP::get_layer_sizes<a class="headerlink" href="#cvann-mlp-get-layer-sizes" title="Permalink to this headline">¶</a></h2>
<p>Returns numbers of neurons in each layer of the MLP.</p>
<dl class="function">
<dt id="const CvMat* CvANN_MLP::get_layer_sizes()">
<strong>C++:</strong><code class="descname"> </code>const CvMat* <code class="descclassname">CvANN_MLP::</code><code class="descname">get_layer_sizes</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#const CvMat* CvANN_MLP::get_layer_sizes()" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<p>The method returns the integer vector specifying the number of neurons in each layer including the input and output layers of the MLP.</p>
</div>
<div class="section" id="cvann-mlp-get-weights">
<h2>CvANN_MLP::get_weights<a class="headerlink" href="#cvann-mlp-get-weights" title="Permalink to this headline">¶</a></h2>
<p>Returns neurons weights of the particular layer.</p>
<dl class="function">
<dt id="double* CvANN_MLP::get_weights(int layer)">
<strong>C++:</strong><code class="descname"> </code>double* <code class="descclassname">CvANN_MLP::</code><code class="descname">get_weights</code><span class="sig-paren">(</span>int <strong>layer</strong><span class="sig-paren">)</span><a class="headerlink" href="#double* CvANN_MLP::get_weights(int layer)" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>layer</strong> &#8211; Index of the particular layer.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
</div>


          </div>
          <div class="feedback">
              <h2>Help and Feedback</h2>
              You did not find what you were looking for?
              <ul>
                  
                  
                  
                  <li>Ask a question on the <a href="http://answers.opencv.org">Q&A forum</a>.</li>
                  <li>If you think something is missing or wrong in the documentation,
                  please file a <a href="http://code.opencv.org">bug report</a>.</li>
              </ul>
          </div>
        </div>
      </div>

      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../../../index.html">
              <img class="logo" src="../../../_static/opencv-logo-white.png" alt="Logo"/>
            </a></p>
<div id="searchbox" style="display: none">
      <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" size="18" />
      <input type="submit" value="Search" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
      </p>
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
  <h3><a href="../../../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Neural Networks</a><ul>
<li><a class="reference internal" href="#cvann-mlp-trainparams">CvANN_MLP_TrainParams</a></li>
<li><a class="reference internal" href="#cvann-mlp-trainparams-cvann-mlp-trainparams">CvANN_MLP_TrainParams::CvANN_MLP_TrainParams</a></li>
<li><a class="reference internal" href="#cvann-mlp">CvANN_MLP</a></li>
<li><a class="reference internal" href="#cvann-mlp-cvann-mlp">CvANN_MLP::CvANN_MLP</a></li>
<li><a class="reference internal" href="#cvann-mlp-create">CvANN_MLP::create</a></li>
<li><a class="reference internal" href="#cvann-mlp-train">CvANN_MLP::train</a></li>
<li><a class="reference internal" href="#cvann-mlp-predict">CvANN_MLP::predict</a></li>
<li><a class="reference internal" href="#cvann-mlp-get-layer-count">CvANN_MLP::get_layer_count</a></li>
<li><a class="reference internal" href="#cvann-mlp-get-layer-sizes">CvANN_MLP::get_layer_sizes</a></li>
<li><a class="reference internal" href="#cvann-mlp-get-weights">CvANN_MLP::get_weights</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="expectation_maximization.html"
                        title="previous chapter">Expectation Maximization</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="mldata.html"
                        title="next chapter">MLData</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../../../_sources/modules/ml/doc/neural_networks.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="mldata.html" title="MLData"
             >next</a> |</li>
        <li class="right" >
          <a href="expectation_maximization.html" title="Expectation Maximization"
             >previous</a> |</li>
        <li><a href="../../../index.html">OpenCV 2.4.13.7 documentation</a> &raquo;</li>
          <li><a href="../../refman.html" >OpenCV API Reference</a> &raquo;</li>
          <li><a href="ml.html" >ml. Machine Learning</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2011-2014, opencv dev team.
      Last updated on Jul 12, 2018.
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.3.6.
    </div>
  </body>
</html>